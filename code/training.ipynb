{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NRycs5xe-iQl","executionInfo":{"status":"ok","timestamp":1719973587872,"user_tz":-420,"elapsed":23804,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"fb1d4387-eb7b-48df-dff4-cc85b0ade32d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/PPL')\n","from PIL import Image\n","import os\n","from trocr.src.main import *"],"metadata":{"id":"Y_hHIUzg-5Me","executionInfo":{"status":"ok","timestamp":1719973599143,"user_tz":-420,"elapsed":11275,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Day 1"],"metadata":{"id":"kzG2lqS0atmR"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":727,"referenced_widgets":["375e0ec956d441cebd791750cd2a5651","4f4d3f9cd7f54e6aa185965f2c75cb80","750825f565874d4c838c6ef5774d7f7d","ffee772ce2e94321a6fce38f7d574f4b","d4bf4548b05545c4aa700b165912ff09","32ece0fadefa47fc9d8971e27a461c52","b8e429e19540490990af7f71d03c6887","1ba2cd171a834ab599cc3522bf5e199b","c9883a884f2a4084a46e560c546c2e16","d1b615f64f86419793fcaef2953d19ab","2985999870dd4b87ac68ada65b051907","b36ebf5d807f4a7e8f94abdb130b9b4e","7395531976724632bca7c22e9fb0651b","9c5fdd2d8d714cbba92063caf2390ac6","3c9849b306c347ccbdfa2515dd1614a0","9447568140cb4ded833fca812045fb38","10961110c91e4ee7ab7ef7795b6ef502","7f7b274ca877432e8ac6ff8ca2723b33","af0832f488c24f38908ad9ad71a7a8b7","cb02232a2b814724b62134ef80794e0e","6c6d5703ec5b4fe79e31814206130a85","c3e7879dc8984ff4988e457145b6fd9a","4f9292d170314ababd923a5d26b0f65d","d0f43229012a413ab7ff09f9e8294651","673a013eae174a89819222684fbe7546","c9598d8e950847d1ac8d847e316866c3","b92347860d51416f88e24750cd2c2fef","4eabfd1cef664e98bf8060bb13b1bf43","564f58fabae84feabd23c74007078b10","805ae7fdb82440a9a4503eed6297fe18","dc3e034f5c104b9d95b24719635a110b","b134f0c878124f5e921a2f6226c73b8d","127bf9c5bce6419a9e9aba860097808d","42e2b54f7f984eb3b68ef9bd889df7c5","19676238d69a40f2b92455304d99e056","a3bb000ae9a5484196c9c634d4d6105b","f5cfb7462e534593b70ff55d6455e9ea","e7532716d481439f90540b08fa8dd977","f3c3fc9015a54a3eae5bfb3eb0278ec1","2121f2865d154f13b6ddba5704c39607","8dc2dce9926e4d96a7ad01bcd49d0d0b","ab753f406b6f4bbf8bd74b264d56949f","5a727dd7a6cd4153933a663af53b8b16","625073abeb364229a53ec6e108fa348a","05f3f35042fa4f15824188e3328ffdce","de6947f19f00429d960a24a300d18ac6","63a0acb1318e4d79aff0eafff72c2571","6693163788c149f2ba721d52ff56bcee","9d3912afe9344697add2dd1f3f0c7599","1479ebf21ea74808af8f50548e315d05","bb565ee6b74a41b2ba6dc29f46cfee12","13a4805611ac4795b6d30bf969f2a203","1c7da75a9e8f4be0a61bdb8516a62dbb","88befa6e566c407aa077aa5becc646f6","10947c8ba4bc4ac38a6687fcd624ea2f","98029c0aa3ff47bc82df5733d89ab85a","1db473b29224481da69b16cdbd11f593","d28e74d0decc49aaa910d5377fa3898f","321b5f2e8bbc4565946bd6887e039d80","b5c18f4e37fb4ca9b1610fc90f3749a4","bd03f5f041a04dde946fc0b41a6364ac","756502b63a074bea97cf5d62e79788fd","624a5d61f93e474d85460c58b7c45f42","e390c4446ac140d19e4f301b0b441c37","ca5a0b9333e64e7499bb6cc33de6f22f","e0e81790572546cea6321f3bbfbc36d7","9cfd1f22e80b4963b4523dca292b84b9","1ab39036bef548f798f50beab16eb2b9","3a8a004dff894bf2a976bb026052659a","3985400d872b475cae4bf7caa7d37582","3fbd33214d194b3bbece17b5083529cd","0992685a59d2430d92e7da244045beae","3c0724c6644a4ffdb834ac5bcae130b4","2d51a15ba8b24e4b9136fa87cd7fe97e","5b6400a1d20e4ce1a47addf4cbaac557","79a7e6b6ebde428cb415a230301cb1c7","d336aef199094629ad320a71ccebc076","f89b8aaccd4f4aa59ee025bc65d657b7","204e21aef1f24ac39c66962d51b2afb1","b0524c08a3154e58a9bd5de2127838dc","8fb667a010fa4bc39365a27529bf56a9","4da84f7f113d4364bb455a9065b5fa56","419486956dcc4f209dbbafd570db540f","e6cb18888b9345858c11c20334f5fdb6","1e9b44c8c07b44738348dc3a9bae25c8","d08fd1d6538a4dac9ddafdcfd95c389f","2e5291ee47674a3c8ce76dc14fff9cfe","c6a59060cc8c4a8c83a1cf10c29ab2d9"]},"id":"vIf5jUbb-LO9","executionInfo":{"status":"ok","timestamp":1719881763893,"user_tz":-420,"elapsed":29732,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"7fc802fa-9a33-426a-9b59-8cedb5edf941"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375e0ec956d441cebd791750cd2a5651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36ebf5d807f4a7e8f94abdb130b9b4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9292d170314ababd923a5d26b0f65d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42e2b54f7f984eb3b68ef9bd889df7c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05f3f35042fa4f15824188e3328ffdce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/4.17k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98029c0aa3ff47bc82df5733d89ab85a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cfd1f22e80b4963b4523dca292b84b9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f89b8aaccd4f4aa59ee025bc65d657b7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model from huggingface (microsoft/trocr-base-handwritten)\n","Using device cuda.\n","Predicting batch 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Prediction for /content/drive/MyDrive/PPL/trocr/data/20160504_0112_25849_2_tg_7_5.png:\n","Predict: \" angry him to earn quit into drivers. San with soft that set.'but had shown\n","Confidence Scores: 0.1358686089515686\n","\n","Prediction for /content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 115458.png:\n","Predict: Licensee of McDonald's\n","Confidence Scores: 5.55591395823285e-05\n","\n","Prediction for /content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 122655.png:\n","Predict: How you benefit - spreads.\n","Confidence Scores: 0.003285082057118416\n","\n"]}],"source":["# load images\n","image_names = [\"/content/drive/MyDrive/PPL/trocr/data/20160504_0112_25849_2_tg_7_5.png\",\"/content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 115458.png\", \"/content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 122655.png\"]\n","images = [Image.open(img_name) for img_name in image_names]\n","# directly predict on Pillow Images or on file names\n","model = TrocrPredictor(use_local_model=False)\n","predictions = model.predict_images(images)\n","predictions = list(predictions)\n","# predictions = model.predict_for_image_paths(image_names)\n","# print results\n","for i, file_name in enumerate(image_names):\n","    print(f'Prediction for {file_name}:\\nPredict: {predictions[i][0]}\\nConfidence Scores: {predictions[i][1]}\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGkycnGM-LO-","executionInfo":{"status":"ok","timestamp":1719884757705,"user_tz":-420,"elapsed":2993835,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"b221a973-7e3b-4dc3-880b-a92b51dcb6f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 5097 samples from /content/drive/MyDrive/PPL/trocr/train\n","Loaded 1161 samples from /content/drive/MyDrive/PPL/trocr/val\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model from huggingface (microsoft/trocr-base-handwritten)\n","Using device cuda.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Batch 1: 16.70631980895996 loss\n","Epoch 1, Batch 2: 13.673359870910645 loss\n","Epoch 1, Batch 3: 11.661042213439941 loss\n","Epoch 1, Batch 4: 9.845170021057129 loss\n","Epoch 1, Batch 5: 8.969782829284668 loss\n","Epoch 1, Batch 6: 7.070890426635742 loss\n","Epoch 1, Batch 7: 6.678384780883789 loss\n","Epoch 1, Batch 8: 5.217596054077148 loss\n","Epoch 1, Batch 9: 4.720924377441406 loss\n","Epoch 1, Batch 10: 4.418208122253418 loss\n","Epoch 1, Batch 11: 4.759006023406982 loss\n","Epoch 1, Batch 12: 4.038406848907471 loss\n","Epoch 1, Batch 13: 4.493661403656006 loss\n","Epoch 1, Batch 14: 3.1485962867736816 loss\n","Epoch 1, Batch 15: 3.6796164512634277 loss\n","Epoch 1, Batch 16: 3.686552047729492 loss\n","Epoch 1, Batch 17: 3.657273292541504 loss\n","Epoch 1, Batch 18: 3.3211216926574707 loss\n","Epoch 1, Batch 19: 3.135953187942505 loss\n","Epoch 1, Batch 20: 2.824141263961792 loss\n","Epoch 1, Batch 21: 2.924804210662842 loss\n","Epoch 1, Batch 22: 2.29622745513916 loss\n","Epoch 1, Batch 23: 2.8526790142059326 loss\n","Epoch 1, Batch 24: 3.1989758014678955 loss\n","Epoch 1, Batch 25: 3.271063804626465 loss\n","Epoch 1, Batch 26: 2.8838748931884766 loss\n","Epoch 1, Batch 27: 2.8040318489074707 loss\n","Epoch 1, Batch 28: 2.579587936401367 loss\n","Epoch 1, Batch 29: 2.4843153953552246 loss\n","Epoch 1, Batch 30: 2.7582993507385254 loss\n","Epoch 1, Batch 31: 2.3709638118743896 loss\n","Epoch 1, Batch 32: 2.3454062938690186 loss\n","Epoch 1, Batch 33: 2.660982131958008 loss\n","Epoch 1, Batch 34: 2.141848564147949 loss\n","Epoch 1, Batch 35: 2.273998260498047 loss\n","Epoch 1, Batch 36: 2.564707040786743 loss\n","Epoch 1, Batch 37: 2.3943445682525635 loss\n","Epoch 1, Batch 38: 2.501953363418579 loss\n","Epoch 1, Batch 39: 1.8900597095489502 loss\n","Epoch 1, Batch 40: 2.061774253845215 loss\n","Epoch 1, Batch 41: 2.198178291320801 loss\n","Epoch 1, Batch 42: 2.4876577854156494 loss\n","Epoch 1, Batch 43: 2.2930691242218018 loss\n","Epoch 1, Batch 44: 2.003751039505005 loss\n","Epoch 1, Batch 45: 2.224684000015259 loss\n","Epoch 1, Batch 46: 2.235887289047241 loss\n","Epoch 1, Batch 47: 2.069261074066162 loss\n","Epoch 1, Batch 48: 1.9521970748901367 loss\n","Epoch 1, Batch 49: 1.9208489656448364 loss\n","Epoch 1, Batch 50: 2.343069553375244 loss\n","Epoch 1, Batch 51: 2.186353921890259 loss\n","Epoch 1, Batch 52: 2.269824743270874 loss\n","Epoch 1, Batch 53: 1.9390943050384521 loss\n","Epoch 1, Batch 54: 1.7751458883285522 loss\n","Epoch 1, Batch 55: 2.0866782665252686 loss\n","Epoch 1, Batch 56: 2.2137374877929688 loss\n","Epoch 1, Batch 57: 2.0194039344787598 loss\n","Epoch 1, Batch 58: 1.9138834476470947 loss\n","Epoch 1, Batch 59: 2.055846691131592 loss\n","Epoch 1, Batch 60: 1.7452199459075928 loss\n","Epoch 1, Batch 61: 1.7828842401504517 loss\n","Epoch 1, Batch 62: 2.1105799674987793 loss\n","Epoch 1, Batch 63: 1.8354473114013672 loss\n","Epoch 1, Batch 64: 1.514388084411621 loss\n","Epoch 1, Batch 65: 1.5154608488082886 loss\n","Epoch 1, Batch 66: 1.823006510734558 loss\n","Epoch 1, Batch 67: 1.8441380262374878 loss\n","Epoch 1, Batch 68: 1.639269471168518 loss\n","Epoch 1, Batch 69: 1.9929261207580566 loss\n","Epoch 1, Batch 70: 1.8686844110488892 loss\n","Epoch 1, Batch 71: 1.9767334461212158 loss\n","Epoch 1, Batch 72: 1.9082354307174683 loss\n","Epoch 1, Batch 73: 1.7620964050292969 loss\n","Epoch 1, Batch 74: 1.6761623620986938 loss\n","Epoch 1, Batch 75: 1.6663142442703247 loss\n","Epoch 1, Batch 76: 1.86808180809021 loss\n","Epoch 1, Batch 77: 1.9391576051712036 loss\n","Epoch 1, Batch 78: 1.7070305347442627 loss\n","Epoch 1, Batch 79: 1.754518747329712 loss\n","Epoch 1, Batch 80: 2.0775294303894043 loss\n","Epoch 1, Batch 81: 1.5943498611450195 loss\n","Epoch 1, Batch 82: 1.6641160249710083 loss\n","Epoch 1, Batch 83: 1.7015266418457031 loss\n","Epoch 1, Batch 84: 1.8237978219985962 loss\n","Epoch 1, Batch 85: 1.6319738626480103 loss\n","Epoch 1, Batch 86: 1.9384301900863647 loss\n","Epoch 1, Batch 87: 1.8055239915847778 loss\n","Epoch 1, Batch 88: 1.8934721946716309 loss\n","Epoch 1, Batch 89: 1.465075969696045 loss\n","Epoch 1, Batch 90: 1.8717657327651978 loss\n","Epoch 1, Batch 91: 1.54085111618042 loss\n","Epoch 1, Batch 92: 1.705424189567566 loss\n","Epoch 1, Batch 93: 1.5960921049118042 loss\n","Epoch 1, Batch 94: 1.65538489818573 loss\n","Epoch 1, Batch 95: 1.9135286808013916 loss\n","Epoch 1, Batch 96: 1.5551306009292603 loss\n","Epoch 1, Batch 97: 1.7146855592727661 loss\n","Epoch 1, Batch 98: 1.4936649799346924 loss\n","Epoch 1, Batch 99: 1.5674877166748047 loss\n","Epoch 1, Batch 100: 1.413529396057129 loss\n","Epoch 1, Batch 101: 1.3348777294158936 loss\n","Epoch 1, Batch 102: 1.5837873220443726 loss\n","Epoch 1, Batch 103: 1.576479196548462 loss\n","Epoch 1, Batch 104: 1.3989051580429077 loss\n","Epoch 1, Batch 105: 1.2420856952667236 loss\n","Epoch 1, Batch 106: 1.11391019821167 loss\n","Epoch 1, Batch 107: 1.2851722240447998 loss\n","Epoch 1, Batch 108: 1.409525990486145 loss\n","Epoch 1, Batch 109: 1.1812543869018555 loss\n","Epoch 1, Batch 110: 1.2783032655715942 loss\n","Epoch 1, Batch 111: 1.6094084978103638 loss\n","Epoch 1, Batch 112: 1.2420974969863892 loss\n","Epoch 1, Batch 113: 1.2607805728912354 loss\n","Epoch 1, Batch 114: 1.33046293258667 loss\n","Epoch 1, Batch 115: 1.6110332012176514 loss\n","Epoch 1, Batch 116: 1.5199394226074219 loss\n","Epoch 1, Batch 117: 1.341881275177002 loss\n","Epoch 1, Batch 118: 1.5190815925598145 loss\n","Epoch 1, Batch 119: 1.370248556137085 loss\n","Epoch 1, Batch 120: 1.211785078048706 loss\n","Epoch 1, Batch 121: 1.0221383571624756 loss\n","Epoch 1, Batch 122: 1.2225372791290283 loss\n","Epoch 1, Batch 123: 1.5417357683181763 loss\n","Epoch 1, Batch 124: 1.4640624523162842 loss\n","Epoch 1, Batch 125: 1.2384655475616455 loss\n","Epoch 1, Batch 126: 1.2256187200546265 loss\n","Epoch 1, Batch 127: 1.1000157594680786 loss\n","Epoch 1, Batch 128: 0.953291118144989 loss\n","Epoch 1, Batch 129: 1.3716585636138916 loss\n","Epoch 1, Batch 130: 0.9777660965919495 loss\n","Epoch 1, Batch 131: 1.458445429801941 loss\n","Epoch 1, Batch 132: 1.2511595487594604 loss\n","Epoch 1, Batch 133: 1.1770107746124268 loss\n","Epoch 1, Batch 134: 1.226728081703186 loss\n","Epoch 1, Batch 135: 1.2143183946609497 loss\n","Epoch 1, Batch 136: 1.3807133436203003 loss\n","Epoch 1, Batch 137: 0.9872402548789978 loss\n","Epoch 1, Batch 138: 1.2974361181259155 loss\n","Epoch 1, Batch 139: 1.3201954364776611 loss\n","Epoch 1, Batch 140: 1.4285173416137695 loss\n","Epoch 1, Batch 141: 1.3611806631088257 loss\n","Epoch 1, Batch 142: 1.1387540102005005 loss\n","Epoch 1, Batch 143: 1.087314248085022 loss\n","Epoch 1, Batch 144: 1.2745214700698853 loss\n","Epoch 1, Batch 145: 0.96621173620224 loss\n","Epoch 1, Batch 146: 0.8654232621192932 loss\n","Epoch 1, Batch 147: 1.0592539310455322 loss\n","Epoch 1, Batch 148: 0.9504545331001282 loss\n","Epoch 1, Batch 149: 1.2315263748168945 loss\n","Epoch 1, Batch 150: 1.3546907901763916 loss\n","Epoch 1, Batch 151: 1.220173954963684 loss\n","Epoch 1, Batch 152: 1.044377088546753 loss\n","Epoch 1, Batch 153: 1.01619553565979 loss\n","Epoch 1, Batch 154: 1.0716568231582642 loss\n","Epoch 1, Batch 155: 1.1624679565429688 loss\n","Epoch 1, Batch 156: 0.9955089688301086 loss\n","Epoch 1, Batch 157: 0.8722833395004272 loss\n","Epoch 1, Batch 158: 1.052765130996704 loss\n","Epoch 1, Batch 159: 1.1623518466949463 loss\n","Epoch 1, Batch 160: 1.0177961587905884 loss\n","Epoch 1, Batch 161: 0.8357992172241211 loss\n","Epoch 1, Batch 162: 1.1394219398498535 loss\n","Epoch 1, Batch 163: 0.9826332926750183 loss\n","Epoch 1, Batch 164: 0.8657858371734619 loss\n","Epoch 1, Batch 165: 1.2634116411209106 loss\n","Epoch 1, Batch 166: 1.0086145401000977 loss\n","Epoch 1, Batch 167: 0.6504449844360352 loss\n","Epoch 1, Batch 168: 1.0429106950759888 loss\n","Epoch 1, Batch 169: 0.9555636048316956 loss\n","Epoch 1, Batch 170: 0.9466057419776917 loss\n","Epoch 1, Batch 171: 0.7996659874916077 loss\n","Epoch 1, Batch 172: 1.0906734466552734 loss\n","Epoch 1, Batch 173: 1.08995521068573 loss\n","Epoch 1, Batch 174: 1.0649906396865845 loss\n","Epoch 1, Batch 175: 0.9924007654190063 loss\n","Epoch 1, Batch 176: 0.9379769563674927 loss\n","Epoch 1, Batch 177: 0.9303292632102966 loss\n","Epoch 1, Batch 178: 0.9200633764266968 loss\n","Epoch 1, Batch 179: 0.7640814185142517 loss\n","Epoch 1, Batch 180: 0.9586676955223083 loss\n","Epoch 1, Batch 181: 0.8843620419502258 loss\n","Epoch 1, Batch 182: 0.9721934795379639 loss\n","Epoch 1, Batch 183: 0.9287207126617432 loss\n","Epoch 1, Batch 184: 1.0295692682266235 loss\n","Epoch 1, Batch 185: 1.000108242034912 loss\n","Epoch 1, Batch 186: 0.9961297512054443 loss\n","Epoch 1, Batch 187: 1.0800518989562988 loss\n","Epoch 1, Batch 188: 0.8681433200836182 loss\n","Epoch 1, Batch 189: 0.8948319554328918 loss\n","Epoch 1, Batch 190: 0.936901330947876 loss\n","Epoch 1, Batch 191: 1.0647410154342651 loss\n","Epoch 1, Batch 192: 0.8048579692840576 loss\n","Epoch 1, Batch 193: 0.8365737199783325 loss\n","Epoch 1, Batch 194: 1.003034234046936 loss\n","Epoch 1, Batch 195: 0.8038122057914734 loss\n","Epoch 1, Batch 196: 0.8539074063301086 loss\n","Epoch 1, Batch 197: 0.6265450716018677 loss\n","Epoch 1, Batch 198: 0.8464767932891846 loss\n","Epoch 1, Batch 199: 0.8396291732788086 loss\n","Epoch 1, Batch 200: 0.7939954996109009 loss\n","Epoch 1, Batch 201: 0.9643364548683167 loss\n","Epoch 1, Batch 202: 0.7668002843856812 loss\n","Epoch 1, Batch 203: 0.8682093620300293 loss\n","Epoch 1, Batch 204: 0.7008875012397766 loss\n","Epoch 1, Batch 205: 1.109057903289795 loss\n","Epoch 1, Batch 206: 0.8375101089477539 loss\n","Epoch 1, Batch 207: 0.7690849304199219 loss\n","Epoch 1, Batch 208: 0.8115930557250977 loss\n","Epoch 1, Batch 209: 0.8084489107131958 loss\n","Epoch 1, Batch 210: 0.813405454158783 loss\n","Epoch 1, Batch 211: 0.781130850315094 loss\n","Epoch 1, Batch 212: 0.7350672483444214 loss\n","Epoch 1, Batch 213: 0.8032084703445435 loss\n","Epoch 1, Batch 214: 0.9182318449020386 loss\n","Epoch 1, Batch 215: 0.7525755763053894 loss\n","Epoch 1, Batch 216: 0.8038662672042847 loss\n","Epoch 1, Batch 217: 0.6805226802825928 loss\n","Epoch 1, Batch 218: 0.8226117491722107 loss\n","Epoch 1, Batch 219: 0.8714910745620728 loss\n","Epoch 1, Batch 220: 0.7822307348251343 loss\n","Epoch 1, Batch 221: 0.8674892783164978 loss\n","Epoch 1, Batch 222: 0.6522445678710938 loss\n","Epoch 1, Batch 223: 0.7259910106658936 loss\n","Epoch 1, Batch 224: 0.6962472796440125 loss\n","Epoch 1, Batch 225: 0.7381194829940796 loss\n","Epoch 1, Batch 226: 0.7037906050682068 loss\n","Epoch 1, Batch 227: 0.7490849494934082 loss\n","Epoch 1, Batch 228: 0.6783539652824402 loss\n","Epoch 1, Batch 229: 0.6808124780654907 loss\n","Epoch 1, Batch 230: 0.7166278958320618 loss\n","Epoch 1, Batch 231: 0.7750255465507507 loss\n","Epoch 1, Batch 232: 0.6742807030677795 loss\n","Epoch 1, Batch 233: 0.8062897324562073 loss\n","Epoch 1, Batch 234: 0.6586870551109314 loss\n","Epoch 1, Batch 235: 0.8054980039596558 loss\n","Epoch 1, Batch 236: 0.9524374604225159 loss\n","Epoch 1, Batch 237: 0.6714090704917908 loss\n","Epoch 1, Batch 238: 0.7611377835273743 loss\n","Epoch 1, Batch 239: 0.7047994136810303 loss\n","Epoch 1, Batch 240: 0.754081130027771 loss\n","Epoch 1, Batch 241: 0.8099327683448792 loss\n","Epoch 1, Batch 242: 0.9447706341743469 loss\n","Epoch 1, Batch 243: 0.8051337003707886 loss\n","Epoch 1, Batch 244: 0.8535297513008118 loss\n","Epoch 1, Batch 245: 0.963603138923645 loss\n","Epoch 1, Batch 246: 0.909125804901123 loss\n","Epoch 1, Batch 247: 0.654687225818634 loss\n","Epoch 1, Batch 248: 0.833674967288971 loss\n","Epoch 1, Batch 249: 0.7290791273117065 loss\n","Epoch 1, Batch 250: 0.615352213382721 loss\n","Epoch 1, Batch 251: 0.7677323222160339 loss\n","Epoch 1, Batch 252: 0.6193253993988037 loss\n","Epoch 1, Batch 253: 0.6919675469398499 loss\n","Epoch 1, Batch 254: 0.612522304058075 loss\n","Epoch 1, Batch 255: 0.6309060454368591 loss\n","Epoch 1, Batch 256: 0.757786214351654 loss\n","Epoch 1, Batch 257: 0.7933582067489624 loss\n","Epoch 1, Batch 258: 0.727660596370697 loss\n","Epoch 1, Batch 259: 0.6719545125961304 loss\n","Epoch 1, Batch 260: 0.6598427891731262 loss\n","Epoch 1, Batch 261: 0.8513199090957642 loss\n","Epoch 1, Batch 262: 0.6719362139701843 loss\n","Epoch 1, Batch 263: 0.698762059211731 loss\n","Epoch 1, Batch 264: 0.6171640157699585 loss\n","Epoch 1, Batch 265: 0.8606034517288208 loss\n","Epoch 1, Batch 266: 0.698807418346405 loss\n","Epoch 1, Batch 267: 0.5771580338478088 loss\n","Epoch 1, Batch 268: 0.6220319271087646 loss\n","Epoch 1, Batch 269: 0.6592520475387573 loss\n","Epoch 1, Batch 270: 0.7557944655418396 loss\n","Epoch 1, Batch 271: 0.8069925308227539 loss\n","Epoch 1, Batch 272: 0.7844682931900024 loss\n","Epoch 1, Batch 273: 0.6078745722770691 loss\n","Epoch 1, Batch 274: 0.7776156663894653 loss\n","Epoch 1, Batch 275: 0.6678035855293274 loss\n","Epoch 1, Batch 276: 0.5754172801971436 loss\n","Epoch 1, Batch 277: 0.6028084754943848 loss\n","Epoch 1, Batch 278: 0.586002767086029 loss\n","Epoch 1, Batch 279: 0.762444019317627 loss\n","Epoch 1, Batch 280: 0.7165508270263672 loss\n","Epoch 1, Batch 281: 0.5651687979698181 loss\n","Epoch 1, Batch 282: 0.6224369406700134 loss\n","Epoch 1, Batch 283: 0.5617741346359253 loss\n","Epoch 1, Batch 284: 0.6700689196586609 loss\n","Epoch 1, Batch 285: 0.782008945941925 loss\n","Epoch 1, Batch 286: 0.49263083934783936 loss\n","Epoch 1, Batch 287: 0.8400989174842834 loss\n","Epoch 1, Batch 288: 0.8167151808738708 loss\n","Epoch 1, Batch 289: 0.7110652923583984 loss\n","Epoch 1, Batch 290: 0.6771260499954224 loss\n","Epoch 1, Batch 291: 0.5707655549049377 loss\n","Epoch 1, Batch 292: 0.5427069067955017 loss\n","Epoch 1, Batch 293: 0.5934987664222717 loss\n","Epoch 1, Batch 294: 0.5403184294700623 loss\n","Epoch 1, Batch 295: 0.7095374464988708 loss\n","Epoch 1, Batch 296: 0.6382193565368652 loss\n","Epoch 1, Batch 297: 0.6820951104164124 loss\n","Epoch 1, Batch 298: 0.6163623929023743 loss\n","Epoch 1, Batch 299: 0.6138430237770081 loss\n","Epoch 1, Batch 300: 0.666434645652771 loss\n","Epoch 1, Batch 301: 0.6877337694168091 loss\n","Epoch 1, Batch 302: 0.5811650156974792 loss\n","Epoch 1, Batch 303: 0.7102782130241394 loss\n","Epoch 1, Batch 304: 0.49924400448799133 loss\n","Epoch 1, Batch 305: 0.6556605100631714 loss\n","Epoch 1, Batch 306: 0.7308517098426819 loss\n","Epoch 1, Batch 307: 0.5422731637954712 loss\n","Epoch 1, Batch 308: 0.7113198041915894 loss\n","Epoch 1, Batch 309: 0.7400819659233093 loss\n","Epoch 1, Batch 310: 0.5844861268997192 loss\n","Epoch 1, Batch 311: 0.5333030819892883 loss\n","Epoch 1, Batch 312: 0.7787066698074341 loss\n","Epoch 1, Batch 313: 0.6023978590965271 loss\n","Epoch 1, Batch 314: 0.585115373134613 loss\n","Epoch 1, Batch 315: 0.6667604446411133 loss\n","Epoch 1, Batch 316: 0.7545028924942017 loss\n","Epoch 1, Batch 317: 0.5562546849250793 loss\n","Epoch 1, Batch 318: 0.6532447934150696 loss\n","Epoch 1, Batch 319: 0.6252366900444031 loss\n","Epoch 1, Batch 320: 0.634073793888092 loss\n","Epoch 1, Batch 321: 0.727504312992096 loss\n","Epoch 1, Batch 322: 0.6146029233932495 loss\n","Epoch 1, Batch 323: 0.46422645449638367 loss\n","Epoch 1, Batch 324: 0.5217242240905762 loss\n","Epoch 1, Batch 325: 0.6002628207206726 loss\n","Epoch 1, Batch 326: 0.5978917479515076 loss\n","Epoch 1, Batch 327: 0.5573105812072754 loss\n","Epoch 1, Batch 328: 0.6645455956459045 loss\n","Epoch 1, Batch 329: 0.633305549621582 loss\n","Epoch 1, Batch 330: 0.5670397281646729 loss\n","Epoch 1, Batch 331: 0.6176554560661316 loss\n","Epoch 1, Batch 332: 0.6203666925430298 loss\n","Epoch 1, Batch 333: 0.6886671781539917 loss\n","Epoch 1, Batch 334: 0.5605359077453613 loss\n","Epoch 1, Batch 335: 0.7718976736068726 loss\n","Epoch 1, Batch 336: 0.6332622766494751 loss\n","Epoch 1, Batch 337: 0.6676914095878601 loss\n","Epoch 1, Batch 338: 0.5300421118736267 loss\n","Epoch 1, Batch 339: 0.5983415842056274 loss\n","Epoch 1, Batch 340: 0.6373111605644226 loss\n","Epoch 1, Batch 341: 0.6158818602561951 loss\n","Epoch 1, Batch 342: 0.7185677886009216 loss\n","Epoch 1, Batch 343: 0.720900297164917 loss\n","Epoch 1, Batch 344: 0.5100519061088562 loss\n","Epoch 1, Batch 345: 0.6073199510574341 loss\n","Epoch 1, Batch 346: 0.6269749402999878 loss\n","Epoch 1, Batch 347: 0.6371355056762695 loss\n","Epoch 1, Batch 348: 0.5504778027534485 loss\n","Epoch 1, Batch 349: 0.3853219151496887 loss\n","Epoch 1, Batch 350: 0.5566704869270325 loss\n","Epoch 1, Batch 351: 0.5760743618011475 loss\n","Epoch 1, Batch 352: 0.6166226863861084 loss\n","Epoch 1, Batch 353: 0.6366771459579468 loss\n","Epoch 1, Batch 354: 0.5699304938316345 loss\n","Epoch 1, Batch 355: 0.6479068994522095 loss\n","Epoch 1, Batch 356: 0.4752591848373413 loss\n","Epoch 1, Batch 357: 0.5393581986427307 loss\n","Epoch 1, Batch 358: 0.5952852964401245 loss\n","Epoch 1, Batch 359: 0.6445789337158203 loss\n","Epoch 1, Batch 360: 0.5313582420349121 loss\n","Epoch 1, Batch 361: 0.695449709892273 loss\n","Epoch 1, Batch 362: 0.7512690424919128 loss\n","Epoch 1, Batch 363: 0.5452229380607605 loss\n","Epoch 1, Batch 364: 0.6205971837043762 loss\n","Epoch 1, Batch 365: 0.5633453726768494 loss\n","Epoch 1, Batch 366: 0.6013818979263306 loss\n","Epoch 1, Batch 367: 0.5509190559387207 loss\n","Epoch 1, Batch 368: 0.568354070186615 loss\n","Epoch 1, Batch 369: 0.5852155089378357 loss\n","Epoch 1, Batch 370: 0.6317487955093384 loss\n","Epoch 1, Batch 371: 0.5431138277053833 loss\n","Epoch 1, Batch 372: 0.5870373845100403 loss\n","Epoch 1, Batch 373: 0.6647139191627502 loss\n","Epoch 1, Batch 374: 0.7021256685256958 loss\n","Epoch 1, Batch 375: 0.7059991955757141 loss\n","Epoch 1, Batch 376: 0.76263427734375 loss\n","Epoch 1, Batch 377: 0.5553308725357056 loss\n","Epoch 1, Batch 378: 0.6224826574325562 loss\n","Epoch 1, Batch 379: 0.6338168978691101 loss\n","Epoch 1, Batch 380: 0.6207026839256287 loss\n","Epoch 1, Batch 381: 0.6199364066123962 loss\n","Epoch 1, Batch 382: 0.5126022696495056 loss\n","Epoch 1, Batch 383: 0.6885252594947815 loss\n","Epoch 1, Batch 384: 0.5898985266685486 loss\n","Epoch 1, Batch 385: 0.6921209096908569 loss\n","Epoch 1, Batch 386: 0.6442583203315735 loss\n","Epoch 1, Batch 387: 0.5040158629417419 loss\n","Epoch 1, Batch 388: 0.5857664942741394 loss\n","Epoch 1, Batch 389: 0.42923399806022644 loss\n","Epoch 1, Batch 390: 0.41897714138031006 loss\n","Epoch 1, Batch 391: 0.547793447971344 loss\n","Epoch 1, Batch 392: 0.550106942653656 loss\n","Epoch 1, Batch 393: 0.6128124594688416 loss\n","Epoch 1, Batch 394: 0.7665821313858032 loss\n","Epoch 1, Batch 395: 0.5839943885803223 loss\n","Epoch 1, Batch 396: 0.6006525158882141 loss\n","Epoch 1, Batch 397: 0.6163392663002014 loss\n","Epoch 1, Batch 398: 0.5871362686157227 loss\n","Epoch 1, Batch 399: 0.581356942653656 loss\n","Epoch 1, Batch 400: 0.44571349024772644 loss\n","Epoch 1, Batch 401: 0.6210237145423889 loss\n","Epoch 1, Batch 402: 0.393486350774765 loss\n","Epoch 1, Batch 403: 0.547082245349884 loss\n","Epoch 1, Batch 404: 0.4677563011646271 loss\n","Epoch 1, Batch 405: 0.3294162154197693 loss\n","Epoch 1, Batch 406: 0.5482746362686157 loss\n","Epoch 1, Batch 407: 0.5364859104156494 loss\n","Epoch 1, Batch 408: 0.6699634790420532 loss\n","Epoch 1, Batch 409: 0.5790172815322876 loss\n","Epoch 1, Batch 410: 0.4138752520084381 loss\n","Epoch 1, Batch 411: 0.4709900915622711 loss\n","Epoch 1, Batch 412: 0.4386967420578003 loss\n","Epoch 1, Batch 413: 0.4608052372932434 loss\n","Epoch 1, Batch 414: 0.5204584002494812 loss\n","Epoch 1, Batch 415: 0.5309851169586182 loss\n","Epoch 1, Batch 416: 0.560183584690094 loss\n","Epoch 1, Batch 417: 0.4362803101539612 loss\n","Epoch 1, Batch 418: 0.6249909996986389 loss\n","Epoch 1, Batch 419: 0.6248356699943542 loss\n","Epoch 1, Batch 420: 0.5311432480812073 loss\n","Epoch 1, Batch 421: 0.5294855833053589 loss\n","Epoch 1, Batch 422: 0.508647620677948 loss\n","Epoch 1, Batch 423: 0.6313172578811646 loss\n","Epoch 1, Batch 424: 0.5417677164077759 loss\n","Epoch 1, Batch 425: 0.5554901361465454 loss\n","Epoch 1, Batch 426: 0.5763218998908997 loss\n","Epoch 1, Batch 427: 0.4910273849964142 loss\n","Epoch 1, Batch 428: 0.5742884874343872 loss\n","Epoch 1, Batch 429: 0.6258991956710815 loss\n","Epoch 1, Batch 430: 0.5931351780891418 loss\n","Epoch 1, Batch 431: 0.48251399397850037 loss\n","Epoch 1, Batch 432: 0.44818636775016785 loss\n","Epoch 1, Batch 433: 0.5428262948989868 loss\n","Epoch 1, Batch 434: 0.6177889704704285 loss\n","Epoch 1, Batch 435: 0.6572734713554382 loss\n","Epoch 1, Batch 436: 0.5628249049186707 loss\n","Epoch 1, Batch 437: 0.5162824392318726 loss\n","Epoch 1, Batch 438: 0.8884077668190002 loss\n","Epoch 1, Batch 439: 0.5378788113594055 loss\n","Epoch 1, Batch 440: 0.5995923280715942 loss\n","Epoch 1, Batch 441: 0.6191310882568359 loss\n","Epoch 1, Batch 442: 0.5106351375579834 loss\n","Epoch 1, Batch 443: 0.5537229776382446 loss\n","Epoch 1, Batch 444: 0.7024509906768799 loss\n","Epoch 1, Batch 445: 0.4805406630039215 loss\n","Epoch 1, Batch 446: 0.4355957806110382 loss\n","Epoch 1, Batch 447: 0.5951889157295227 loss\n","Epoch 1, Batch 448: 0.5160313248634338 loss\n","Epoch 1, Batch 449: 0.5180237889289856 loss\n","Epoch 1, Batch 450: 0.4694744646549225 loss\n","Epoch 1, Batch 451: 0.5229356288909912 loss\n","Epoch 1, Batch 452: 0.5534889101982117 loss\n","Epoch 1, Batch 453: 0.611257016658783 loss\n","Epoch 1, Batch 454: 0.5225856304168701 loss\n","Epoch 1, Batch 455: 0.6155881881713867 loss\n","Epoch 1, Batch 456: 0.39929449558258057 loss\n","Epoch 1, Batch 457: 0.42853617668151855 loss\n","Epoch 1, Batch 458: 0.5142632722854614 loss\n","Epoch 1, Batch 459: 0.5213468670845032 loss\n","Epoch 1, Batch 460: 0.3819516897201538 loss\n","Epoch 1, Batch 461: 0.5400722622871399 loss\n","Epoch 1, Batch 462: 0.4596607983112335 loss\n","Epoch 1, Batch 463: 0.5520155429840088 loss\n","Epoch 1, Batch 464: 0.5778086185455322 loss\n","Epoch 1, Batch 465: 0.6021254062652588 loss\n","Epoch 1, Batch 466: 0.5008703470230103 loss\n","Epoch 1, Batch 467: 0.46696901321411133 loss\n","Epoch 1, Batch 468: 0.5475115776062012 loss\n","Epoch 1, Batch 469: 0.5549269318580627 loss\n","Epoch 1, Batch 470: 0.42769894003868103 loss\n","Epoch 1, Batch 471: 0.4610401690006256 loss\n","Epoch 1, Batch 472: 0.5316014289855957 loss\n","Epoch 1, Batch 473: 0.5079619884490967 loss\n","Epoch 1, Batch 474: 0.4459976553916931 loss\n","Epoch 1, Batch 475: 0.4560001790523529 loss\n","Epoch 1, Batch 476: 0.48717933893203735 loss\n","Epoch 1, Batch 477: 0.4352433979511261 loss\n","Epoch 1, Batch 478: 0.5202569365501404 loss\n","Epoch 1, Batch 479: 0.44394823908805847 loss\n","Epoch 1, Batch 480: 0.5507989525794983 loss\n","Epoch 1, Batch 481: 0.6327210068702698 loss\n","Epoch 1, Batch 482: 0.5755172967910767 loss\n","Epoch 1, Batch 483: 0.43263572454452515 loss\n","Epoch 1, Batch 484: 0.5351766347885132 loss\n","Epoch 1, Batch 485: 0.5428256988525391 loss\n","Epoch 1, Batch 486: 0.5412954092025757 loss\n","Epoch 1, Batch 487: 0.48307082056999207 loss\n","Epoch 1, Batch 488: 0.5658347010612488 loss\n","Epoch 1, Batch 489: 0.4657929837703705 loss\n","Epoch 1, Batch 490: 0.4934590458869934 loss\n","Epoch 1, Batch 491: 0.4277268350124359 loss\n","Epoch 1, Batch 492: 0.5443492531776428 loss\n","Epoch 1, Batch 493: 0.5631884932518005 loss\n","Epoch 1, Batch 494: 0.6787278056144714 loss\n","Epoch 1, Batch 495: 0.6700124740600586 loss\n","Epoch 1, Batch 496: 0.4479907155036926 loss\n","Epoch 1, Batch 497: 0.48725199699401855 loss\n","Epoch 1, Batch 498: 0.4530620276927948 loss\n","Epoch 1, Batch 499: 0.5797832608222961 loss\n","Epoch 1, Batch 500: 0.45259109139442444 loss\n","Epoch 1, Batch 501: 0.4526146650314331 loss\n","Epoch 1, Batch 502: 0.5383102893829346 loss\n","Epoch 1, Batch 503: 0.4978255331516266 loss\n","Epoch 1, Batch 504: 0.5192022323608398 loss\n","Epoch 1, Batch 505: 0.4833546280860901 loss\n","Epoch 1, Batch 506: 0.531366229057312 loss\n","Epoch 1, Batch 507: 0.4253578782081604 loss\n","Epoch 1, Batch 508: 0.5033619403839111 loss\n","Epoch 1, Batch 509: 0.39810821413993835 loss\n","Epoch 1, Batch 510: 0.6076303124427795 loss\n","Epoch 1, Batch 511: 0.5739841461181641 loss\n","Epoch 1, Batch 512: 0.620868980884552 loss\n","Epoch 1, Batch 513: 0.3807254135608673 loss\n","Epoch 1, Batch 514: 0.4719419777393341 loss\n","Epoch 1, Batch 515: 0.35559889674186707 loss\n","Epoch 1, Batch 516: 0.5629748106002808 loss\n","Epoch 1, Batch 517: 0.3443836271762848 loss\n","Epoch 1, Batch 518: 0.4640277922153473 loss\n","Epoch 1, Batch 519: 0.49607598781585693 loss\n","Epoch 1, Batch 520: 0.416026771068573 loss\n","Epoch 1, Batch 521: 0.6049998998641968 loss\n","Epoch 1, Batch 522: 0.516643226146698 loss\n","Epoch 1, Batch 523: 0.5478948950767517 loss\n","Epoch 1, Batch 524: 0.40398067235946655 loss\n","Epoch 1, Batch 525: 0.40900808572769165 loss\n","Epoch 1, Batch 526: 0.3702109754085541 loss\n","Epoch 1, Batch 527: 0.4297882318496704 loss\n","Epoch 1, Batch 528: 0.433790385723114 loss\n","Epoch 1, Batch 529: 0.4052402675151825 loss\n","Epoch 1, Batch 530: 0.48662954568862915 loss\n","Epoch 1, Batch 531: 0.5262584090232849 loss\n","Epoch 1, Batch 532: 0.4502151608467102 loss\n","Epoch 1, Batch 533: 0.4450645446777344 loss\n","Epoch 1, Batch 534: 0.6405935883522034 loss\n","Epoch 1, Batch 535: 0.38832807540893555 loss\n","Epoch 1, Batch 536: 0.39640012383461 loss\n","Epoch 1, Batch 537: 0.4997142255306244 loss\n","Epoch 1, Batch 538: 0.4318736493587494 loss\n","Epoch 1, Batch 539: 0.5773683190345764 loss\n","Epoch 1, Batch 540: 0.5810101628303528 loss\n","Epoch 1, Batch 541: 0.47979119420051575 loss\n","Epoch 1, Batch 542: 0.65509033203125 loss\n","Epoch 1, Batch 543: 0.4946228563785553 loss\n","Epoch 1, Batch 544: 0.5273802280426025 loss\n","Epoch 1, Batch 545: 0.4772426187992096 loss\n","Epoch 1, Batch 546: 0.4996259808540344 loss\n","Epoch 1, Batch 547: 0.48236778378486633 loss\n","Epoch 1, Batch 548: 0.47098883986473083 loss\n","Epoch 1, Batch 549: 0.4866984486579895 loss\n","Epoch 1, Batch 550: 0.4126742482185364 loss\n","Epoch 1, Batch 551: 0.6415137648582458 loss\n","Epoch 1, Batch 552: 0.41213512420654297 loss\n","Epoch 1, Batch 553: 0.5109375715255737 loss\n","Epoch 1, Batch 554: 0.5393537878990173 loss\n","Epoch 1, Batch 555: 0.42471611499786377 loss\n","Epoch 1, Batch 556: 0.4766402840614319 loss\n","Epoch 1, Batch 557: 0.5179556012153625 loss\n","Epoch 1, Batch 558: 0.4704383313655853 loss\n","Epoch 1, Batch 559: 0.3812742829322815 loss\n","Epoch 1, Batch 560: 0.5580913424491882 loss\n","Epoch 1, Batch 561: 0.46235883235931396 loss\n","Epoch 1, Batch 562: 0.5690268278121948 loss\n","Epoch 1, Batch 563: 0.4277411699295044 loss\n","Epoch 1, Batch 564: 0.5193103551864624 loss\n","Epoch 1, Batch 565: 0.4857730269432068 loss\n","Epoch 1, Batch 566: 0.32191646099090576 loss\n","Epoch 1, Batch 567: 0.5521875619888306 loss\n","Epoch 1, Batch 568: 0.434376984834671 loss\n","Epoch 1, Batch 569: 0.4152676463127136 loss\n","Epoch 1, Batch 570: 0.39444103837013245 loss\n","Epoch 1, Batch 571: 0.4340679943561554 loss\n","Epoch 1, Batch 572: 0.6008126735687256 loss\n","Epoch 1, Batch 573: 0.6210578680038452 loss\n","Epoch 1, Batch 574: 0.5487442016601562 loss\n","Epoch 1, Batch 575: 0.48367729783058167 loss\n","Epoch 1, Batch 576: 0.4794313311576843 loss\n","Epoch 1, Batch 577: 0.4599238634109497 loss\n","Epoch 1, Batch 578: 0.3896431624889374 loss\n","Epoch 1, Batch 579: 0.4129320979118347 loss\n","Epoch 1, Batch 580: 0.3661242723464966 loss\n","Epoch 1, Batch 581: 0.4993726909160614 loss\n","Epoch 1, Batch 582: 0.4626135528087616 loss\n","Epoch 1, Batch 583: 0.32410189509391785 loss\n","Epoch 1, Batch 584: 0.40285724401474 loss\n","Epoch 1, Batch 585: 0.5328584313392639 loss\n","Epoch 1, Batch 586: 0.4229223430156708 loss\n","Epoch 1, Batch 587: 0.4051758050918579 loss\n","Epoch 1, Batch 588: 0.38206690549850464 loss\n","Epoch 1, Batch 589: 0.4333246946334839 loss\n","Epoch 1, Batch 590: 0.3420906662940979 loss\n","Epoch 1, Batch 591: 0.44433701038360596 loss\n","Epoch 1, Batch 592: 0.4440084993839264 loss\n","Epoch 1, Batch 593: 0.351698637008667 loss\n","Epoch 1, Batch 594: 0.5431566834449768 loss\n","Epoch 1, Batch 595: 0.42153072357177734 loss\n","Epoch 1, Batch 596: 0.49489346146583557 loss\n","Epoch 1, Batch 597: 0.48517295718193054 loss\n","Epoch 1, Batch 598: 0.4878550171852112 loss\n","Epoch 1, Batch 599: 0.6178035140037537 loss\n","Epoch 1, Batch 600: 0.4550687074661255 loss\n","Epoch 1, Batch 601: 0.4973205029964447 loss\n","Epoch 1, Batch 602: 0.5778957009315491 loss\n","Epoch 1, Batch 603: 0.43279337882995605 loss\n","Epoch 1, Batch 604: 0.5091581344604492 loss\n","Epoch 1, Batch 605: 0.3674648404121399 loss\n","Epoch 1, Batch 606: 0.4878391921520233 loss\n","Epoch 1, Batch 607: 0.45459920167922974 loss\n","Epoch 1, Batch 608: 0.4824742078781128 loss\n","Epoch 1, Batch 609: 0.36009925603866577 loss\n","Epoch 1, Batch 610: 0.5304182767868042 loss\n","Epoch 1, Batch 611: 0.42305901646614075 loss\n","Epoch 1, Batch 612: 0.42466098070144653 loss\n","Epoch 1, Batch 613: 0.44374653697013855 loss\n","Epoch 1, Batch 614: 0.5245553255081177 loss\n","Epoch 1, Batch 615: 0.5024194121360779 loss\n","Epoch 1, Batch 616: 0.38165798783302307 loss\n","Epoch 1, Batch 617: 0.43233522772789 loss\n","Epoch 1, Batch 618: 0.4661976397037506 loss\n","Epoch 1, Batch 619: 0.31009602546691895 loss\n","Epoch 1, Batch 620: 0.45446187257766724 loss\n","Epoch 1, Batch 621: 0.43353086709976196 loss\n","Epoch 1, Batch 622: 0.5354210734367371 loss\n","Epoch 1, Batch 623: 0.554641842842102 loss\n","Epoch 1, Batch 624: 0.4321739673614502 loss\n","Epoch 1, Batch 625: 0.4243307113647461 loss\n","Epoch 1, Batch 626: 0.4158821702003479 loss\n","Epoch 1, Batch 627: 0.37501171231269836 loss\n","Epoch 1, Batch 628: 0.48304492235183716 loss\n","Epoch 1, Batch 629: 0.5039049983024597 loss\n","Epoch 1, Batch 630: 0.3890928030014038 loss\n","Epoch 1, Batch 631: 0.5350092649459839 loss\n","Epoch 1, Batch 632: 0.4730476140975952 loss\n","Epoch 1, Batch 633: 0.5106783509254456 loss\n","Epoch 1, Batch 634: 0.5006449222564697 loss\n","Epoch 1, Batch 635: 0.5434808135032654 loss\n","Epoch 1, Batch 636: 0.55613112449646 loss\n","Epoch 1, Batch 637: 0.43650826811790466 loss\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Batch 638: 0.6153466105461121 loss\n","Predicting batch 1\n","Predicting batch 2\n","Predicting batch 3\n","Predicting batch 4\n","Predicting batch 5\n","Predicting batch 6\n","Predicting batch 7\n","Predicting batch 8\n","Predicting batch 9\n","Predicting batch 10\n","Predicting batch 11\n","Predicting batch 12\n","Predicting batch 13\n","Predicting batch 14\n","Predicting batch 15\n","Predicting batch 16\n","Predicting batch 17\n","Predicting batch 18\n","Predicting batch 19\n","Predicting batch 20\n","Predicting batch 21\n","Predicting batch 22\n","Predicting batch 23\n","Predicting batch 24\n","Predicting batch 25\n","Predicting batch 26\n","Predicting batch 27\n","Predicting batch 28\n","Predicting batch 29\n","Predicting batch 30\n","Predicting batch 31\n","Predicting batch 32\n","Predicting batch 33\n","Predicting batch 34\n","Predicting batch 35\n","Predicting batch 36\n","Predicting batch 37\n","Predicting batch 38\n","Predicting batch 39\n","Predicting batch 40\n","Predicting batch 41\n","Predicting batch 42\n","Predicting batch 43\n","Predicting batch 44\n","Predicting batch 45\n","Predicting batch 46\n","Predicting batch 47\n","Predicting batch 48\n","Predicting batch 49\n","Predicting batch 50\n","Predicting batch 51\n","Predicting batch 52\n","Predicting batch 53\n","Predicting batch 54\n","Predicting batch 55\n","Predicting batch 56\n","Predicting batch 57\n","Predicting batch 58\n","Predicting batch 59\n","Predicting batch 60\n","Predicting batch 61\n","Predicting batch 62\n","Predicting batch 63\n","Predicting batch 64\n","Predicting batch 65\n","Predicting batch 66\n","Predicting batch 67\n","Predicting batch 68\n","Predicting batch 69\n","Predicting batch 70\n","Predicting batch 71\n","Predicting batch 72\n","Predicting batch 73\n","Predicting batch 74\n","Predicting batch 75\n","Predicting batch 76\n","Predicting batch 77\n","Predicting batch 78\n","Predicting batch 79\n","Predicting batch 80\n","Predicting batch 81\n","Predicting batch 82\n","Predicting batch 83\n","Predicting batch 84\n","Predicting batch 85\n","Predicting batch 86\n","Predicting batch 87\n","Predicting batch 88\n","Predicting batch 89\n","Predicting batch 90\n","Predicting batch 91\n","Predicting batch 92\n","Predicting batch 93\n","Predicting batch 94\n","Predicting batch 95\n","Predicting batch 96\n","Predicting batch 97\n","Predicting batch 98\n","Predicting batch 99\n","Predicting batch 100\n","Predicting batch 101\n","Predicting batch 102\n","Predicting batch 103\n","Predicting batch 104\n","Predicting batch 105\n","Predicting batch 106\n","Predicting batch 107\n","Predicting batch 108\n","Predicting batch 109\n","Predicting batch 110\n","Predicting batch 111\n","Predicting batch 112\n","Predicting batch 113\n","Predicting batch 114\n","Predicting batch 115\n","Predicting batch 116\n","Predicting batch 117\n","Predicting batch 118\n","Predicting batch 119\n","Predicting batch 120\n","Predicting batch 121\n","Predicting batch 122\n","Predicting batch 123\n","Predicting batch 124\n","Predicting batch 125\n","Predicting batch 126\n","Predicting batch 127\n","Predicting batch 128\n","Predicting batch 129\n","Predicting batch 130\n","Predicting batch 131\n","Predicting batch 132\n","Predicting batch 133\n","Predicting batch 134\n","Predicting batch 135\n","Predicting batch 136\n","Predicting batch 137\n","Predicting batch 138\n","Predicting batch 139\n","Predicting batch 140\n","Predicting batch 141\n","Predicting batch 142\n","Predicting batch 143\n","Predicting batch 144\n","Predicting batch 145\n","Predicting batch 146\n","\n","---- Epoch 1 ----\n","Accuracy: 0.0\n","\n","\n","Epoch 2, Batch 1: 0.46750572323799133 loss\n","Epoch 2, Batch 2: 0.3088732957839966 loss\n","Epoch 2, Batch 3: 0.3795781433582306 loss\n","Epoch 2, Batch 4: 0.4109945595264435 loss\n","Epoch 2, Batch 5: 0.42900076508522034 loss\n","Epoch 2, Batch 6: 0.4004666209220886 loss\n","Epoch 2, Batch 7: 0.429973840713501 loss\n","Epoch 2, Batch 8: 0.37806856632232666 loss\n","Epoch 2, Batch 9: 0.5731492638587952 loss\n","Epoch 2, Batch 10: 0.4254075586795807 loss\n","Epoch 2, Batch 11: 0.3813985586166382 loss\n","Epoch 2, Batch 12: 0.3534528911113739 loss\n","Epoch 2, Batch 13: 0.4416074752807617 loss\n","Epoch 2, Batch 14: 0.45410746335983276 loss\n","Epoch 2, Batch 15: 0.421208918094635 loss\n","Epoch 2, Batch 16: 0.5305122137069702 loss\n","Epoch 2, Batch 17: 0.42395511269569397 loss\n","Epoch 2, Batch 18: 0.24286526441574097 loss\n","Epoch 2, Batch 19: 0.348399817943573 loss\n","Epoch 2, Batch 20: 0.32942304015159607 loss\n","Epoch 2, Batch 21: 0.5934802889823914 loss\n","Epoch 2, Batch 22: 0.2761893570423126 loss\n","Epoch 2, Batch 23: 0.4214058816432953 loss\n","Epoch 2, Batch 24: 0.3450029790401459 loss\n","Epoch 2, Batch 25: 0.319035142660141 loss\n","Epoch 2, Batch 26: 0.437617689371109 loss\n","Epoch 2, Batch 27: 0.38762184977531433 loss\n","Epoch 2, Batch 28: 0.476859986782074 loss\n","Epoch 2, Batch 29: 0.3125348687171936 loss\n","Epoch 2, Batch 30: 0.41783562302589417 loss\n","Epoch 2, Batch 31: 0.3739510178565979 loss\n","Epoch 2, Batch 32: 0.42641139030456543 loss\n","Epoch 2, Batch 33: 0.24934493005275726 loss\n","Epoch 2, Batch 34: 0.29993727803230286 loss\n","Epoch 2, Batch 35: 0.3739534616470337 loss\n","Epoch 2, Batch 36: 0.3589235842227936 loss\n","Epoch 2, Batch 37: 0.36361077427864075 loss\n","Epoch 2, Batch 38: 0.31374695897102356 loss\n","Epoch 2, Batch 39: 0.33755117654800415 loss\n","Epoch 2, Batch 40: 0.3735685348510742 loss\n","Epoch 2, Batch 41: 0.35382261872291565 loss\n","Epoch 2, Batch 42: 0.33062073588371277 loss\n","Epoch 2, Batch 43: 0.4242379367351532 loss\n","Epoch 2, Batch 44: 0.26653239130973816 loss\n","Epoch 2, Batch 45: 0.30489301681518555 loss\n","Epoch 2, Batch 46: 0.320848286151886 loss\n","Epoch 2, Batch 47: 0.5030269026756287 loss\n","Epoch 2, Batch 48: 0.4321041703224182 loss\n","Epoch 2, Batch 49: 0.3004663586616516 loss\n","Epoch 2, Batch 50: 0.39232972264289856 loss\n","Epoch 2, Batch 51: 0.3627179265022278 loss\n","Epoch 2, Batch 52: 0.3841088116168976 loss\n","Epoch 2, Batch 53: 0.3177337944507599 loss\n","Epoch 2, Batch 54: 0.273753821849823 loss\n","Epoch 2, Batch 55: 0.39784884452819824 loss\n","Epoch 2, Batch 56: 0.40581798553466797 loss\n","Epoch 2, Batch 57: 0.3791852295398712 loss\n","Epoch 2, Batch 58: 0.34181904792785645 loss\n","Epoch 2, Batch 59: 0.40660229325294495 loss\n","Epoch 2, Batch 60: 0.310136616230011 loss\n","Epoch 2, Batch 61: 0.3396455645561218 loss\n","Epoch 2, Batch 62: 0.3756861388683319 loss\n","Epoch 2, Batch 63: 0.3714599311351776 loss\n","Epoch 2, Batch 64: 0.44903114438056946 loss\n","Epoch 2, Batch 65: 0.34731921553611755 loss\n","Epoch 2, Batch 66: 0.27811625599861145 loss\n","Epoch 2, Batch 67: 0.3037472367286682 loss\n","Epoch 2, Batch 68: 0.30144721269607544 loss\n","Epoch 2, Batch 69: 0.3584745526313782 loss\n","Epoch 2, Batch 70: 0.5216419696807861 loss\n","Epoch 2, Batch 71: 0.4138167202472687 loss\n","Epoch 2, Batch 72: 0.44689249992370605 loss\n","Epoch 2, Batch 73: 0.4875354468822479 loss\n","Epoch 2, Batch 74: 0.34492921829223633 loss\n","Epoch 2, Batch 75: 0.35116782784461975 loss\n","Epoch 2, Batch 76: 0.35159486532211304 loss\n","Epoch 2, Batch 77: 0.27386462688446045 loss\n","Epoch 2, Batch 78: 0.3635126054286957 loss\n","Epoch 2, Batch 79: 0.456360399723053 loss\n","Epoch 2, Batch 80: 0.3464699387550354 loss\n","Epoch 2, Batch 81: 0.3111925721168518 loss\n","Epoch 2, Batch 82: 0.46558475494384766 loss\n","Epoch 2, Batch 83: 0.3404701352119446 loss\n","Epoch 2, Batch 84: 0.4331308603286743 loss\n","Epoch 2, Batch 85: 0.3526543378829956 loss\n","Epoch 2, Batch 86: 0.3571680784225464 loss\n","Epoch 2, Batch 87: 0.2822904586791992 loss\n","Epoch 2, Batch 88: 0.4286856949329376 loss\n","Epoch 2, Batch 89: 0.4703289866447449 loss\n","Epoch 2, Batch 90: 0.40128329396247864 loss\n","Epoch 2, Batch 91: 0.49173712730407715 loss\n","Epoch 2, Batch 92: 0.3368540108203888 loss\n","Epoch 2, Batch 93: 0.32200542092323303 loss\n","Epoch 2, Batch 94: 0.3954949975013733 loss\n","Epoch 2, Batch 95: 0.4147287607192993 loss\n","Epoch 2, Batch 96: 0.295003205537796 loss\n","Epoch 2, Batch 97: 0.27477505803108215 loss\n","Epoch 2, Batch 98: 0.38366031646728516 loss\n","Epoch 2, Batch 99: 0.4723908007144928 loss\n","Epoch 2, Batch 100: 0.3290129601955414 loss\n","Epoch 2, Batch 101: 0.2550585865974426 loss\n","Epoch 2, Batch 102: 0.30305883288383484 loss\n","Epoch 2, Batch 103: 0.35784584283828735 loss\n","Epoch 2, Batch 104: 0.32119566202163696 loss\n","Epoch 2, Batch 105: 0.36378753185272217 loss\n","Epoch 2, Batch 106: 0.3412473797798157 loss\n","Epoch 2, Batch 107: 0.37314048409461975 loss\n","Epoch 2, Batch 108: 0.32314014434814453 loss\n","Epoch 2, Batch 109: 0.25974327325820923 loss\n","Epoch 2, Batch 110: 0.3785736560821533 loss\n","Epoch 2, Batch 111: 0.33691972494125366 loss\n","Epoch 2, Batch 112: 0.44422733783721924 loss\n","Epoch 2, Batch 113: 0.35404521226882935 loss\n","Epoch 2, Batch 114: 0.2797546982765198 loss\n","Epoch 2, Batch 115: 0.3787715435028076 loss\n","Epoch 2, Batch 116: 0.3541540205478668 loss\n","Epoch 2, Batch 117: 0.4054073989391327 loss\n","Epoch 2, Batch 118: 0.33790212869644165 loss\n","Epoch 2, Batch 119: 0.37199917435646057 loss\n","Epoch 2, Batch 120: 0.3859139382839203 loss\n","Epoch 2, Batch 121: 0.26058998703956604 loss\n","Epoch 2, Batch 122: 0.35454559326171875 loss\n","Epoch 2, Batch 123: 0.4240560531616211 loss\n","Epoch 2, Batch 124: 0.36693087220191956 loss\n","Epoch 2, Batch 125: 0.3139178156852722 loss\n","Epoch 2, Batch 126: 0.44489577412605286 loss\n","Epoch 2, Batch 127: 0.3693844974040985 loss\n","Epoch 2, Batch 128: 0.38289564847946167 loss\n","Epoch 2, Batch 129: 0.3426488935947418 loss\n","Epoch 2, Batch 130: 0.42336544394493103 loss\n","Epoch 2, Batch 131: 0.2978229820728302 loss\n","Epoch 2, Batch 132: 0.6961249113082886 loss\n","Epoch 2, Batch 133: 0.4725656509399414 loss\n","Epoch 2, Batch 134: 0.2747551500797272 loss\n","Epoch 2, Batch 135: 0.41126182675361633 loss\n","Epoch 2, Batch 136: 0.3640556335449219 loss\n","Epoch 2, Batch 137: 0.305915892124176 loss\n","Epoch 2, Batch 138: 0.4299921989440918 loss\n","Epoch 2, Batch 139: 0.36593279242515564 loss\n","Epoch 2, Batch 140: 0.3456540107727051 loss\n","Epoch 2, Batch 141: 0.42789262533187866 loss\n","Epoch 2, Batch 142: 0.3980206251144409 loss\n","Epoch 2, Batch 143: 0.35716408491134644 loss\n","Epoch 2, Batch 144: 0.3363440930843353 loss\n","Epoch 2, Batch 145: 0.28507885336875916 loss\n","Epoch 2, Batch 146: 0.4317677319049835 loss\n","Epoch 2, Batch 147: 0.3181772828102112 loss\n","Epoch 2, Batch 148: 0.3967166244983673 loss\n","Epoch 2, Batch 149: 0.4327487647533417 loss\n","Epoch 2, Batch 150: 0.29943129420280457 loss\n","Epoch 2, Batch 151: 0.4057150185108185 loss\n","Epoch 2, Batch 152: 0.3419186472892761 loss\n","Epoch 2, Batch 153: 0.3693680763244629 loss\n","Epoch 2, Batch 154: 0.40956911444664 loss\n","Epoch 2, Batch 155: 0.3580324053764343 loss\n","Epoch 2, Batch 156: 0.39407896995544434 loss\n","Epoch 2, Batch 157: 0.41518649458885193 loss\n","Epoch 2, Batch 158: 0.33661022782325745 loss\n","Epoch 2, Batch 159: 0.4136072099208832 loss\n","Epoch 2, Batch 160: 0.2669832110404968 loss\n","Epoch 2, Batch 161: 0.2876492738723755 loss\n","Epoch 2, Batch 162: 0.46021854877471924 loss\n","Epoch 2, Batch 163: 0.3709586560726166 loss\n","Epoch 2, Batch 164: 0.26773202419281006 loss\n","Epoch 2, Batch 165: 0.29358384013175964 loss\n","Epoch 2, Batch 166: 0.2909938395023346 loss\n","Epoch 2, Batch 167: 0.28494754433631897 loss\n","Epoch 2, Batch 168: 0.3408825695514679 loss\n","Epoch 2, Batch 169: 0.35268738865852356 loss\n","Epoch 2, Batch 170: 0.2691836357116699 loss\n","Epoch 2, Batch 171: 0.31075534224510193 loss\n","Epoch 2, Batch 172: 0.4265557825565338 loss\n","Epoch 2, Batch 173: 0.32829511165618896 loss\n","Epoch 2, Batch 174: 0.3555927872657776 loss\n","Epoch 2, Batch 175: 0.2723599970340729 loss\n","Epoch 2, Batch 176: 0.37469708919525146 loss\n","Epoch 2, Batch 177: 0.33635684847831726 loss\n","Epoch 2, Batch 178: 0.3023257851600647 loss\n","Epoch 2, Batch 179: 0.3829570412635803 loss\n","Epoch 2, Batch 180: 0.3211650252342224 loss\n","Epoch 2, Batch 181: 0.35516834259033203 loss\n","Epoch 2, Batch 182: 0.3715549111366272 loss\n","Epoch 2, Batch 183: 0.3163445293903351 loss\n","Epoch 2, Batch 184: 0.35570934414863586 loss\n","Epoch 2, Batch 185: 0.31035086512565613 loss\n","Epoch 2, Batch 186: 0.2572539448738098 loss\n","Epoch 2, Batch 187: 0.32723453640937805 loss\n","Epoch 2, Batch 188: 0.3552975356578827 loss\n","Epoch 2, Batch 189: 0.29027652740478516 loss\n","Epoch 2, Batch 190: 0.29617342352867126 loss\n","Epoch 2, Batch 191: 0.3888254463672638 loss\n","Epoch 2, Batch 192: 0.3668632209300995 loss\n","Epoch 2, Batch 193: 0.3804890215396881 loss\n","Epoch 2, Batch 194: 0.4151113033294678 loss\n","Epoch 2, Batch 195: 0.3116745054721832 loss\n","Epoch 2, Batch 196: 0.3756968677043915 loss\n","Epoch 2, Batch 197: 0.3838415741920471 loss\n","Epoch 2, Batch 198: 0.42552971839904785 loss\n","Epoch 2, Batch 199: 0.22596682608127594 loss\n","Epoch 2, Batch 200: 0.4236593544483185 loss\n","Epoch 2, Batch 201: 0.43271201848983765 loss\n","Epoch 2, Batch 202: 0.3962708115577698 loss\n","Epoch 2, Batch 203: 0.25214195251464844 loss\n","Epoch 2, Batch 204: 0.3476408123970032 loss\n","Epoch 2, Batch 205: 0.2822815477848053 loss\n","Epoch 2, Batch 206: 0.3412381410598755 loss\n","Epoch 2, Batch 207: 0.37004950642585754 loss\n","Epoch 2, Batch 208: 0.30667680501937866 loss\n","Epoch 2, Batch 209: 0.296370267868042 loss\n","Epoch 2, Batch 210: 0.40669235587120056 loss\n","Epoch 2, Batch 211: 0.33880260586738586 loss\n","Epoch 2, Batch 212: 0.3800254166126251 loss\n","Epoch 2, Batch 213: 0.25069519877433777 loss\n","Epoch 2, Batch 214: 0.3080526292324066 loss\n","Epoch 2, Batch 215: 0.344933420419693 loss\n","Epoch 2, Batch 216: 0.3991737961769104 loss\n","Epoch 2, Batch 217: 0.35832729935646057 loss\n","Epoch 2, Batch 218: 0.3083699345588684 loss\n","Epoch 2, Batch 219: 0.3027542531490326 loss\n","Epoch 2, Batch 220: 0.4349942207336426 loss\n","Epoch 2, Batch 221: 0.343843549489975 loss\n","Epoch 2, Batch 222: 0.3992772102355957 loss\n","Epoch 2, Batch 223: 0.303174763917923 loss\n","Epoch 2, Batch 224: 0.31343236565589905 loss\n","Epoch 2, Batch 225: 0.3205512464046478 loss\n","Epoch 2, Batch 226: 0.2758614122867584 loss\n","Epoch 2, Batch 227: 0.34190768003463745 loss\n","Epoch 2, Batch 228: 0.34906280040740967 loss\n","Epoch 2, Batch 229: 0.356362909078598 loss\n","Epoch 2, Batch 230: 0.3309037685394287 loss\n","Epoch 2, Batch 231: 0.3598332107067108 loss\n","Epoch 2, Batch 232: 0.33350956439971924 loss\n","Epoch 2, Batch 233: 0.3273632228374481 loss\n","Epoch 2, Batch 234: 0.31841468811035156 loss\n","Epoch 2, Batch 235: 0.3356150984764099 loss\n","Epoch 2, Batch 236: 0.31520378589630127 loss\n","Epoch 2, Batch 237: 0.3159904181957245 loss\n","Epoch 2, Batch 238: 0.2961152195930481 loss\n","Epoch 2, Batch 239: 0.31955546140670776 loss\n","Epoch 2, Batch 240: 0.3622514307498932 loss\n","Epoch 2, Batch 241: 0.506374180316925 loss\n","Epoch 2, Batch 242: 0.3849770724773407 loss\n","Epoch 2, Batch 243: 0.2945724427700043 loss\n","Epoch 2, Batch 244: 0.20683114230632782 loss\n","Epoch 2, Batch 245: 0.3845834732055664 loss\n","Epoch 2, Batch 246: 0.33815690875053406 loss\n","Epoch 2, Batch 247: 0.26356860995292664 loss\n","Epoch 2, Batch 248: 0.31921127438545227 loss\n","Epoch 2, Batch 249: 0.3575626611709595 loss\n","Epoch 2, Batch 250: 0.2836458683013916 loss\n","Epoch 2, Batch 251: 0.32652783393859863 loss\n","Epoch 2, Batch 252: 0.23320284485816956 loss\n","Epoch 2, Batch 253: 0.42701053619384766 loss\n","Epoch 2, Batch 254: 0.3473915457725525 loss\n","Epoch 2, Batch 255: 0.2962227165699005 loss\n","Epoch 2, Batch 256: 0.31950220465660095 loss\n","Epoch 2, Batch 257: 0.30386674404144287 loss\n","Epoch 2, Batch 258: 0.38829171657562256 loss\n","Epoch 2, Batch 259: 0.2998546361923218 loss\n","Epoch 2, Batch 260: 0.30188456177711487 loss\n","Epoch 2, Batch 261: 0.3467210531234741 loss\n","Epoch 2, Batch 262: 0.3659818768501282 loss\n","Epoch 2, Batch 263: 0.2864426374435425 loss\n","Epoch 2, Batch 264: 0.47909337282180786 loss\n","Epoch 2, Batch 265: 0.27475905418395996 loss\n","Epoch 2, Batch 266: 0.32394835352897644 loss\n","Epoch 2, Batch 267: 0.34074291586875916 loss\n","Epoch 2, Batch 268: 0.27208587527275085 loss\n","Epoch 2, Batch 269: 0.2634618878364563 loss\n","Epoch 2, Batch 270: 0.31115931272506714 loss\n","Epoch 2, Batch 271: 0.3280000686645508 loss\n","Epoch 2, Batch 272: 0.29976189136505127 loss\n","Epoch 2, Batch 273: 0.28257986903190613 loss\n","Epoch 2, Batch 274: 0.29581764340400696 loss\n","Epoch 2, Batch 275: 0.3671192526817322 loss\n","Epoch 2, Batch 276: 0.3483390212059021 loss\n","Epoch 2, Batch 277: 0.34142518043518066 loss\n","Epoch 2, Batch 278: 0.30108821392059326 loss\n","Epoch 2, Batch 279: 0.2685508131980896 loss\n","Epoch 2, Batch 280: 0.30778977274894714 loss\n","Epoch 2, Batch 281: 0.42332935333251953 loss\n","Epoch 2, Batch 282: 0.3181616961956024 loss\n","Epoch 2, Batch 283: 0.4450494349002838 loss\n","Epoch 2, Batch 284: 0.34649500250816345 loss\n","Epoch 2, Batch 285: 0.31171444058418274 loss\n","Epoch 2, Batch 286: 0.4326919913291931 loss\n","Epoch 2, Batch 287: 0.30889955163002014 loss\n","Epoch 2, Batch 288: 0.3427613377571106 loss\n","Epoch 2, Batch 289: 0.292948454618454 loss\n","Epoch 2, Batch 290: 0.34697994589805603 loss\n","Epoch 2, Batch 291: 0.32767122983932495 loss\n","Epoch 2, Batch 292: 0.3391171395778656 loss\n","Epoch 2, Batch 293: 0.328553169965744 loss\n","Epoch 2, Batch 294: 0.3366113603115082 loss\n","Epoch 2, Batch 295: 0.32981669902801514 loss\n","Epoch 2, Batch 296: 0.42375868558883667 loss\n","Epoch 2, Batch 297: 0.28899019956588745 loss\n","Epoch 2, Batch 298: 0.3707718551158905 loss\n","Epoch 2, Batch 299: 0.3006640672683716 loss\n","Epoch 2, Batch 300: 0.31446558237075806 loss\n","Epoch 2, Batch 301: 0.3651621341705322 loss\n","Epoch 2, Batch 302: 0.28055018186569214 loss\n","Epoch 2, Batch 303: 0.4953584671020508 loss\n","Epoch 2, Batch 304: 0.3078456223011017 loss\n","Epoch 2, Batch 305: 0.24143919348716736 loss\n","Epoch 2, Batch 306: 0.5889421701431274 loss\n","Epoch 2, Batch 307: 0.3676968514919281 loss\n","Epoch 2, Batch 308: 0.24904263019561768 loss\n","Epoch 2, Batch 309: 0.40271517634391785 loss\n","Epoch 2, Batch 310: 0.34493401646614075 loss\n","Epoch 2, Batch 311: 0.41816794872283936 loss\n","Epoch 2, Batch 312: 0.22715355455875397 loss\n","Epoch 2, Batch 313: 0.3689383864402771 loss\n","Epoch 2, Batch 314: 0.32635343074798584 loss\n","Epoch 2, Batch 315: 0.3740939199924469 loss\n","Epoch 2, Batch 316: 0.34847915172576904 loss\n","Epoch 2, Batch 317: 0.38955119252204895 loss\n","Epoch 2, Batch 318: 0.42680492997169495 loss\n","Epoch 2, Batch 319: 0.2566494643688202 loss\n","Epoch 2, Batch 320: 0.2532402575016022 loss\n","Epoch 2, Batch 321: 0.30255186557769775 loss\n","Epoch 2, Batch 322: 0.30127206444740295 loss\n","Epoch 2, Batch 323: 0.25791677832603455 loss\n","Epoch 2, Batch 324: 0.2896272540092468 loss\n","Epoch 2, Batch 325: 0.2562111020088196 loss\n","Epoch 2, Batch 326: 0.36480551958084106 loss\n","Epoch 2, Batch 327: 0.33736294507980347 loss\n","Epoch 2, Batch 328: 0.28339406847953796 loss\n","Epoch 2, Batch 329: 0.2984342575073242 loss\n","Epoch 2, Batch 330: 0.36457210779190063 loss\n","Epoch 2, Batch 331: 0.275288462638855 loss\n","Epoch 2, Batch 332: 0.3467242419719696 loss\n","Epoch 2, Batch 333: 0.3053053617477417 loss\n","Epoch 2, Batch 334: 0.21459513902664185 loss\n","Epoch 2, Batch 335: 0.336437851190567 loss\n","Epoch 2, Batch 336: 0.31247198581695557 loss\n","Epoch 2, Batch 337: 0.3451351821422577 loss\n","Epoch 2, Batch 338: 0.39882203936576843 loss\n","Epoch 2, Batch 339: 0.2548850178718567 loss\n","Epoch 2, Batch 340: 0.3509369492530823 loss\n","Epoch 2, Batch 341: 0.40234294533729553 loss\n","Epoch 2, Batch 342: 0.3229319751262665 loss\n","Epoch 2, Batch 343: 0.35066935420036316 loss\n","Epoch 2, Batch 344: 0.40028145909309387 loss\n","Epoch 2, Batch 345: 0.22562377154827118 loss\n","Epoch 2, Batch 346: 0.3885555863380432 loss\n","Epoch 2, Batch 347: 0.35718992352485657 loss\n","Epoch 2, Batch 348: 0.3275456130504608 loss\n","Epoch 2, Batch 349: 0.3661085367202759 loss\n","Epoch 2, Batch 350: 0.312165766954422 loss\n","Epoch 2, Batch 351: 0.34036341309547424 loss\n","Epoch 2, Batch 352: 0.25501489639282227 loss\n","Epoch 2, Batch 353: 0.2858637571334839 loss\n","Epoch 2, Batch 354: 0.26008549332618713 loss\n","Epoch 2, Batch 355: 0.2574581801891327 loss\n","Epoch 2, Batch 356: 0.32831907272338867 loss\n","Epoch 2, Batch 357: 0.336321085691452 loss\n","Epoch 2, Batch 358: 0.27064821124076843 loss\n","Epoch 2, Batch 359: 0.3850969672203064 loss\n","Epoch 2, Batch 360: 0.3171843886375427 loss\n","Epoch 2, Batch 361: 0.3264865279197693 loss\n","Epoch 2, Batch 362: 0.31853654980659485 loss\n","Epoch 2, Batch 363: 0.3272237181663513 loss\n","Epoch 2, Batch 364: 0.30301374197006226 loss\n","Epoch 2, Batch 365: 0.26279306411743164 loss\n","Epoch 2, Batch 366: 0.24236483871936798 loss\n","Epoch 2, Batch 367: 0.2900145947933197 loss\n","Epoch 2, Batch 368: 0.2795594334602356 loss\n","Epoch 2, Batch 369: 0.35438141226768494 loss\n","Epoch 2, Batch 370: 0.28253549337387085 loss\n","Epoch 2, Batch 371: 0.37349361181259155 loss\n","Epoch 2, Batch 372: 0.3258187174797058 loss\n","Epoch 2, Batch 373: 0.2618613541126251 loss\n","Epoch 2, Batch 374: 0.32096368074417114 loss\n","Epoch 2, Batch 375: 0.25827932357788086 loss\n","Epoch 2, Batch 376: 0.3087098002433777 loss\n","Epoch 2, Batch 377: 0.26103100180625916 loss\n","Epoch 2, Batch 378: 0.1909209042787552 loss\n","Epoch 2, Batch 379: 0.3508536219596863 loss\n","Epoch 2, Batch 380: 0.4524909257888794 loss\n","Epoch 2, Batch 381: 0.3291686177253723 loss\n","Epoch 2, Batch 382: 0.29320135712623596 loss\n","Epoch 2, Batch 383: 0.32798296213150024 loss\n","Epoch 2, Batch 384: 0.2727569043636322 loss\n","Epoch 2, Batch 385: 0.38444480299949646 loss\n","Epoch 2, Batch 386: 0.25508689880371094 loss\n","Epoch 2, Batch 387: 0.3231811821460724 loss\n","Epoch 2, Batch 388: 0.26628348231315613 loss\n","Epoch 2, Batch 389: 0.24547818303108215 loss\n","Epoch 2, Batch 390: 0.3142837882041931 loss\n","Epoch 2, Batch 391: 0.3503473699092865 loss\n","Epoch 2, Batch 392: 0.2668265998363495 loss\n","Epoch 2, Batch 393: 0.383187860250473 loss\n","Epoch 2, Batch 394: 0.31131479144096375 loss\n","Epoch 2, Batch 395: 0.3486795425415039 loss\n","Epoch 2, Batch 396: 0.2646254897117615 loss\n","Epoch 2, Batch 397: 0.27366864681243896 loss\n","Epoch 2, Batch 398: 0.2514941692352295 loss\n","Epoch 2, Batch 399: 0.3089744746685028 loss\n","Epoch 2, Batch 400: 0.3226308822631836 loss\n","Epoch 2, Batch 401: 0.3280278444290161 loss\n","Epoch 2, Batch 402: 0.3277764618396759 loss\n","Epoch 2, Batch 403: 0.34557196497917175 loss\n","Epoch 2, Batch 404: 0.33299416303634644 loss\n","Epoch 2, Batch 405: 0.35313326120376587 loss\n","Epoch 2, Batch 406: 0.38676971197128296 loss\n","Epoch 2, Batch 407: 0.2975718677043915 loss\n","Epoch 2, Batch 408: 0.2281145453453064 loss\n","Epoch 2, Batch 409: 0.3756954073905945 loss\n","Epoch 2, Batch 410: 0.23837222158908844 loss\n","Epoch 2, Batch 411: 0.2804214060306549 loss\n","Epoch 2, Batch 412: 0.4023589491844177 loss\n","Epoch 2, Batch 413: 0.2032202035188675 loss\n","Epoch 2, Batch 414: 0.26508283615112305 loss\n","Epoch 2, Batch 415: 0.26623308658599854 loss\n","Epoch 2, Batch 416: 0.291509211063385 loss\n","Epoch 2, Batch 417: 0.3834784924983978 loss\n","Epoch 2, Batch 418: 0.3022235333919525 loss\n","Epoch 2, Batch 419: 0.4131978154182434 loss\n","Epoch 2, Batch 420: 0.34431299567222595 loss\n","Epoch 2, Batch 421: 0.29484930634498596 loss\n","Epoch 2, Batch 422: 0.3517259359359741 loss\n","Epoch 2, Batch 423: 0.3282383680343628 loss\n","Epoch 2, Batch 424: 0.33839693665504456 loss\n","Epoch 2, Batch 425: 0.23086103796958923 loss\n","Epoch 2, Batch 426: 0.2796371877193451 loss\n","Epoch 2, Batch 427: 0.34478333592414856 loss\n","Epoch 2, Batch 428: 0.26816704869270325 loss\n","Epoch 2, Batch 429: 0.3025357127189636 loss\n","Epoch 2, Batch 430: 0.23080246150493622 loss\n","Epoch 2, Batch 431: 0.17747709155082703 loss\n","Epoch 2, Batch 432: 0.278292715549469 loss\n","Epoch 2, Batch 433: 0.2644632160663605 loss\n","Epoch 2, Batch 434: 0.24053752422332764 loss\n","Epoch 2, Batch 435: 0.2986448407173157 loss\n","Epoch 2, Batch 436: 0.3473972678184509 loss\n","Epoch 2, Batch 437: 0.28935590386390686 loss\n","Epoch 2, Batch 438: 0.3396316170692444 loss\n","Epoch 2, Batch 439: 0.3477725386619568 loss\n","Epoch 2, Batch 440: 0.2545161545276642 loss\n","Epoch 2, Batch 441: 0.2746458053588867 loss\n","Epoch 2, Batch 442: 0.2654842734336853 loss\n","Epoch 2, Batch 443: 0.29089683294296265 loss\n","Epoch 2, Batch 444: 0.35403648018836975 loss\n","Epoch 2, Batch 445: 0.41936126351356506 loss\n","Epoch 2, Batch 446: 0.24449780583381653 loss\n","Epoch 2, Batch 447: 0.2695035934448242 loss\n","Epoch 2, Batch 448: 0.3498399555683136 loss\n","Epoch 2, Batch 449: 0.25138452649116516 loss\n","Epoch 2, Batch 450: 0.280922532081604 loss\n","Epoch 2, Batch 451: 0.282464861869812 loss\n","Epoch 2, Batch 452: 0.40826648473739624 loss\n","Epoch 2, Batch 453: 0.31675371527671814 loss\n","Epoch 2, Batch 454: 0.3280866742134094 loss\n","Epoch 2, Batch 455: 0.3700001537799835 loss\n","Epoch 2, Batch 456: 0.27413639426231384 loss\n","Epoch 2, Batch 457: 0.3116834759712219 loss\n","Epoch 2, Batch 458: 0.38953930139541626 loss\n","Epoch 2, Batch 459: 0.25801217555999756 loss\n","Epoch 2, Batch 460: 0.3372572362422943 loss\n","Epoch 2, Batch 461: 0.19087253510951996 loss\n","Epoch 2, Batch 462: 0.23377566039562225 loss\n","Epoch 2, Batch 463: 0.2681829333305359 loss\n","Epoch 2, Batch 464: 0.32232558727264404 loss\n","Epoch 2, Batch 465: 0.27160099148750305 loss\n","Epoch 2, Batch 466: 0.4796394109725952 loss\n","Epoch 2, Batch 467: 0.2875499427318573 loss\n","Epoch 2, Batch 468: 0.33146315813064575 loss\n","Epoch 2, Batch 469: 0.2887971103191376 loss\n","Epoch 2, Batch 470: 0.37642794847488403 loss\n","Epoch 2, Batch 471: 0.26163095235824585 loss\n","Epoch 2, Batch 472: 0.35122406482696533 loss\n","Epoch 2, Batch 473: 0.3309352695941925 loss\n","Epoch 2, Batch 474: 0.33841168880462646 loss\n","Epoch 2, Batch 475: 0.3622215986251831 loss\n","Epoch 2, Batch 476: 0.3936430513858795 loss\n","Epoch 2, Batch 477: 0.23703044652938843 loss\n","Epoch 2, Batch 478: 0.411167711019516 loss\n","Epoch 2, Batch 479: 0.2695346176624298 loss\n","Epoch 2, Batch 480: 0.28504276275634766 loss\n","Epoch 2, Batch 481: 0.3049514591693878 loss\n","Epoch 2, Batch 482: 0.220272958278656 loss\n","Epoch 2, Batch 483: 0.30057933926582336 loss\n","Epoch 2, Batch 484: 0.24782921373844147 loss\n","Epoch 2, Batch 485: 0.33260294795036316 loss\n","Epoch 2, Batch 486: 0.25425949692726135 loss\n","Epoch 2, Batch 487: 0.27357447147369385 loss\n","Epoch 2, Batch 488: 0.33245179057121277 loss\n","Epoch 2, Batch 489: 0.18398642539978027 loss\n","Epoch 2, Batch 490: 0.3398398756980896 loss\n","Epoch 2, Batch 491: 0.2915193736553192 loss\n","Epoch 2, Batch 492: 0.33129099011421204 loss\n","Epoch 2, Batch 493: 0.398311585187912 loss\n","Epoch 2, Batch 494: 0.322713702917099 loss\n","Epoch 2, Batch 495: 0.30223795771598816 loss\n","Epoch 2, Batch 496: 0.3110966682434082 loss\n","Epoch 2, Batch 497: 0.31838536262512207 loss\n","Epoch 2, Batch 498: 0.25592342019081116 loss\n","Epoch 2, Batch 499: 0.34562209248542786 loss\n","Epoch 2, Batch 500: 0.39330363273620605 loss\n","Epoch 2, Batch 501: 0.40075793862342834 loss\n","Epoch 2, Batch 502: 0.23142923414707184 loss\n","Epoch 2, Batch 503: 0.2142583578824997 loss\n","Epoch 2, Batch 504: 0.3431937098503113 loss\n","Epoch 2, Batch 505: 0.22725389897823334 loss\n","Epoch 2, Batch 506: 0.24497860670089722 loss\n","Epoch 2, Batch 507: 0.3574916124343872 loss\n","Epoch 2, Batch 508: 0.3110765516757965 loss\n","Epoch 2, Batch 509: 0.25633493065834045 loss\n","Epoch 2, Batch 510: 0.2818848192691803 loss\n","Epoch 2, Batch 511: 0.3658042550086975 loss\n","Epoch 2, Batch 512: 0.3837417960166931 loss\n","Epoch 2, Batch 513: 0.32466819882392883 loss\n","Epoch 2, Batch 514: 0.29854124784469604 loss\n","Epoch 2, Batch 515: 0.27499350905418396 loss\n","Epoch 2, Batch 516: 0.31796640157699585 loss\n","Epoch 2, Batch 517: 0.30673089623451233 loss\n","Epoch 2, Batch 518: 0.3149871230125427 loss\n","Epoch 2, Batch 519: 0.1723232865333557 loss\n","Epoch 2, Batch 520: 0.26222744584083557 loss\n","Epoch 2, Batch 521: 0.25436604022979736 loss\n","Epoch 2, Batch 522: 0.26210126280784607 loss\n","Epoch 2, Batch 523: 0.2649401128292084 loss\n","Epoch 2, Batch 524: 0.36165279150009155 loss\n","Epoch 2, Batch 525: 0.34406527876853943 loss\n","Epoch 2, Batch 526: 0.21515022218227386 loss\n","Epoch 2, Batch 527: 0.24346938729286194 loss\n","Epoch 2, Batch 528: 0.24474279582500458 loss\n","Epoch 2, Batch 529: 0.2246984839439392 loss\n","Epoch 2, Batch 530: 0.3163148760795593 loss\n","Epoch 2, Batch 531: 0.29571202397346497 loss\n","Epoch 2, Batch 532: 0.35733625292778015 loss\n","Epoch 2, Batch 533: 0.19803138077259064 loss\n","Epoch 2, Batch 534: 0.3294764757156372 loss\n","Epoch 2, Batch 535: 0.3110957741737366 loss\n","Epoch 2, Batch 536: 0.2591645121574402 loss\n","Epoch 2, Batch 537: 0.27644363045692444 loss\n","Epoch 2, Batch 538: 0.24678188562393188 loss\n","Epoch 2, Batch 539: 0.21878588199615479 loss\n","Epoch 2, Batch 540: 0.2778451144695282 loss\n","Epoch 2, Batch 541: 0.32496941089630127 loss\n","Epoch 2, Batch 542: 0.32602378726005554 loss\n","Epoch 2, Batch 543: 0.26963162422180176 loss\n","Epoch 2, Batch 544: 0.29817289113998413 loss\n","Epoch 2, Batch 545: 0.22955866158008575 loss\n","Epoch 2, Batch 546: 0.3527299761772156 loss\n","Epoch 2, Batch 547: 0.3296172022819519 loss\n","Epoch 2, Batch 548: 0.3302115201950073 loss\n","Epoch 2, Batch 549: 0.21758972108364105 loss\n","Epoch 2, Batch 550: 0.21720193326473236 loss\n","Epoch 2, Batch 551: 0.2324945032596588 loss\n","Epoch 2, Batch 552: 0.30319422483444214 loss\n","Epoch 2, Batch 553: 0.30378061532974243 loss\n","Epoch 2, Batch 554: 0.29015421867370605 loss\n","Epoch 2, Batch 555: 0.24444082379341125 loss\n","Epoch 2, Batch 556: 0.3179243206977844 loss\n","Epoch 2, Batch 557: 0.2595171332359314 loss\n","Epoch 2, Batch 558: 0.26139596104621887 loss\n","Epoch 2, Batch 559: 0.3397044539451599 loss\n","Epoch 2, Batch 560: 0.29984796047210693 loss\n","Epoch 2, Batch 561: 0.32806751132011414 loss\n","Epoch 2, Batch 562: 0.22905918955802917 loss\n","Epoch 2, Batch 563: 0.30715492367744446 loss\n","Epoch 2, Batch 564: 0.28782224655151367 loss\n","Epoch 2, Batch 565: 0.2734760046005249 loss\n","Epoch 2, Batch 566: 0.20001789927482605 loss\n","Epoch 2, Batch 567: 0.32437238097190857 loss\n","Epoch 2, Batch 568: 0.28165218234062195 loss\n","Epoch 2, Batch 569: 0.2440384030342102 loss\n","Epoch 2, Batch 570: 0.25760284066200256 loss\n","Epoch 2, Batch 571: 0.25961920619010925 loss\n","Epoch 2, Batch 572: 0.2877884805202484 loss\n","Epoch 2, Batch 573: 0.3858395218849182 loss\n","Epoch 2, Batch 574: 0.23740935325622559 loss\n","Epoch 2, Batch 575: 0.30746322870254517 loss\n","Epoch 2, Batch 576: 0.3402351438999176 loss\n","Epoch 2, Batch 577: 0.25639960169792175 loss\n","Epoch 2, Batch 578: 0.21755604445934296 loss\n","Epoch 2, Batch 579: 0.2584206461906433 loss\n","Epoch 2, Batch 580: 0.31680741906166077 loss\n","Epoch 2, Batch 581: 0.33880162239074707 loss\n","Epoch 2, Batch 582: 0.34911811351776123 loss\n","Epoch 2, Batch 583: 0.24482707679271698 loss\n","Epoch 2, Batch 584: 0.17107437551021576 loss\n","Epoch 2, Batch 585: 0.44290652871131897 loss\n","Epoch 2, Batch 586: 0.2641972303390503 loss\n","Epoch 2, Batch 587: 0.21962426602840424 loss\n","Epoch 2, Batch 588: 0.2467425912618637 loss\n","Epoch 2, Batch 589: 0.20543943345546722 loss\n","Epoch 2, Batch 590: 0.2951417863368988 loss\n","Epoch 2, Batch 591: 0.31910356879234314 loss\n","Epoch 2, Batch 592: 0.2997151017189026 loss\n","Epoch 2, Batch 593: 0.3169609606266022 loss\n","Epoch 2, Batch 594: 0.3502402603626251 loss\n","Epoch 2, Batch 595: 0.35887596011161804 loss\n","Epoch 2, Batch 596: 0.28141728043556213 loss\n","Epoch 2, Batch 597: 0.2981434464454651 loss\n","Epoch 2, Batch 598: 0.39340949058532715 loss\n","Epoch 2, Batch 599: 0.27550193667411804 loss\n","Epoch 2, Batch 600: 0.1986028105020523 loss\n","Epoch 2, Batch 601: 0.29338914155960083 loss\n","Epoch 2, Batch 602: 0.35191377997398376 loss\n","Epoch 2, Batch 603: 0.37297332286834717 loss\n","Epoch 2, Batch 604: 0.2971479594707489 loss\n","Epoch 2, Batch 605: 0.2775034010410309 loss\n","Epoch 2, Batch 606: 0.30615630745887756 loss\n","Epoch 2, Batch 607: 0.230935737490654 loss\n","Epoch 2, Batch 608: 0.2923853397369385 loss\n","Epoch 2, Batch 609: 0.29606112837791443 loss\n","Epoch 2, Batch 610: 0.2803485095500946 loss\n","Epoch 2, Batch 611: 0.27957144379615784 loss\n","Epoch 2, Batch 612: 0.28363844752311707 loss\n","Epoch 2, Batch 613: 0.5156822204589844 loss\n","Epoch 2, Batch 614: 0.2884412407875061 loss\n","Epoch 2, Batch 615: 0.3793594241142273 loss\n","Epoch 2, Batch 616: 0.2532438337802887 loss\n","Epoch 2, Batch 617: 0.2935987710952759 loss\n","Epoch 2, Batch 618: 0.27091744542121887 loss\n","Epoch 2, Batch 619: 0.25514471530914307 loss\n","Epoch 2, Batch 620: 0.2964220643043518 loss\n","Epoch 2, Batch 621: 0.25793009996414185 loss\n","Epoch 2, Batch 622: 0.37915900349617004 loss\n","Epoch 2, Batch 623: 0.4024542272090912 loss\n","Epoch 2, Batch 624: 0.29545438289642334 loss\n","Epoch 2, Batch 625: 0.1788083016872406 loss\n","Epoch 2, Batch 626: 0.29551559686660767 loss\n","Epoch 2, Batch 627: 0.3426600396633148 loss\n","Epoch 2, Batch 628: 0.2889348566532135 loss\n","Epoch 2, Batch 629: 0.22169478237628937 loss\n","Epoch 2, Batch 630: 0.27680492401123047 loss\n","Epoch 2, Batch 631: 0.3397656977176666 loss\n","Epoch 2, Batch 632: 0.3863730728626251 loss\n","Epoch 2, Batch 633: 0.35550326108932495 loss\n","Epoch 2, Batch 634: 0.3467152416706085 loss\n","Epoch 2, Batch 635: 0.23738417029380798 loss\n","Epoch 2, Batch 636: 0.3270188271999359 loss\n","Epoch 2, Batch 637: 0.3285282850265503 loss\n","Epoch 2, Batch 638: 0.6034948825836182 loss\n","Predicting batch 1\n","Predicting batch 2\n","Predicting batch 3\n","Predicting batch 4\n","Predicting batch 5\n","Predicting batch 6\n","Predicting batch 7\n","Predicting batch 8\n","Predicting batch 9\n","Predicting batch 10\n","Predicting batch 11\n","Predicting batch 12\n","Predicting batch 13\n","Predicting batch 14\n","Predicting batch 15\n","Predicting batch 16\n","Predicting batch 17\n","Predicting batch 18\n","Predicting batch 19\n","Predicting batch 20\n","Predicting batch 21\n","Predicting batch 22\n","Predicting batch 23\n","Predicting batch 24\n","Predicting batch 25\n","Predicting batch 26\n","Predicting batch 27\n","Predicting batch 28\n","Predicting batch 29\n","Predicting batch 30\n","Predicting batch 31\n","Predicting batch 32\n","Predicting batch 33\n","Predicting batch 34\n","Predicting batch 35\n","Predicting batch 36\n","Predicting batch 37\n","Predicting batch 38\n","Predicting batch 39\n","Predicting batch 40\n","Predicting batch 41\n","Predicting batch 42\n","Predicting batch 43\n","Predicting batch 44\n","Predicting batch 45\n","Predicting batch 46\n","Predicting batch 47\n","Predicting batch 48\n","Predicting batch 49\n","Predicting batch 50\n","Predicting batch 51\n","Predicting batch 52\n","Predicting batch 53\n","Predicting batch 54\n","Predicting batch 55\n","Predicting batch 56\n","Predicting batch 57\n","Predicting batch 58\n","Predicting batch 59\n","Predicting batch 60\n","Predicting batch 61\n","Predicting batch 62\n","Predicting batch 63\n","Predicting batch 64\n","Predicting batch 65\n","Predicting batch 66\n","Predicting batch 67\n","Predicting batch 68\n","Predicting batch 69\n","Predicting batch 70\n","Predicting batch 71\n","Predicting batch 72\n","Predicting batch 73\n","Predicting batch 74\n","Predicting batch 75\n","Predicting batch 76\n","Predicting batch 77\n","Predicting batch 78\n","Predicting batch 79\n","Predicting batch 80\n","Predicting batch 81\n","Predicting batch 82\n","Predicting batch 83\n","Predicting batch 84\n","Predicting batch 85\n","Predicting batch 86\n","Predicting batch 87\n","Predicting batch 88\n","Predicting batch 89\n","Predicting batch 90\n","Predicting batch 91\n","Predicting batch 92\n","Predicting batch 93\n","Predicting batch 94\n","Predicting batch 95\n","Predicting batch 96\n","Predicting batch 97\n","Predicting batch 98\n","Predicting batch 99\n","Predicting batch 100\n","Predicting batch 101\n","Predicting batch 102\n","Predicting batch 103\n","Predicting batch 104\n","Predicting batch 105\n","Predicting batch 106\n","Predicting batch 107\n","Predicting batch 108\n","Predicting batch 109\n","Predicting batch 110\n","Predicting batch 111\n","Predicting batch 112\n","Predicting batch 113\n","Predicting batch 114\n","Predicting batch 115\n","Predicting batch 116\n","Predicting batch 117\n","Predicting batch 118\n","Predicting batch 119\n","Predicting batch 120\n","Predicting batch 121\n","Predicting batch 122\n","Predicting batch 123\n","Predicting batch 124\n","Predicting batch 125\n","Predicting batch 126\n","Predicting batch 127\n","Predicting batch 128\n","Predicting batch 129\n","Predicting batch 130\n","Predicting batch 131\n","Predicting batch 132\n","Predicting batch 133\n","Predicting batch 134\n","Predicting batch 135\n","Predicting batch 136\n","Predicting batch 137\n","Predicting batch 138\n","Predicting batch 139\n","Predicting batch 140\n","Predicting batch 141\n","Predicting batch 142\n","Predicting batch 143\n","Predicting batch 144\n","Predicting batch 145\n","Predicting batch 146\n","\n","---- Epoch 2 ----\n","Accuracy: 0.0\n","\n","\n","Saving model to /content/drive/MyDrive/PPL/trocr/model...\n"]}],"source":["main_train(use_local_model=False)"]},{"cell_type":"code","source":["# load images\n","image_names = [\"/content/drive/MyDrive/PPL/trocr/data/20160504_0112_25849_2_tg_7_5.png\",\"/content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 115458.png\", \"/content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 122655.png\"]\n","images = [Image.open(img_name) for img_name in image_names]\n","# directly predict on Pillow Images or on file names\n","model = TrocrPredictor(use_local_model=True)\n","predictions = model.predict_images(images)\n","predictions = list(predictions)\n","# predictions = model.predict_for_image_paths(image_names)\n","# print results\n","for i, file_name in enumerate(image_names):\n","    print(f'Prediction for {file_name}:\\nPredict: {predictions[i][0]}\\nConfidence Scores: {predictions[i][1]}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S53BZITO7Sk8","executionInfo":{"status":"ok","timestamp":1719884769931,"user_tz":-420,"elapsed":12231,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"72d6e95a-80da-48bb-e764-e0cb046ce486"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded local model from /content/drive/MyDrive/PPL/trocr/model\n","Using device cuda.\n","Predicting batch 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Prediction for /content/drive/MyDrive/PPL/trocr/data/20160504_0112_25849_2_tg_7_5.png:\n","Predict: nguy hiểm vì cua giất\n","Confidence Scores: 0.8155369162559509\n","\n","Prediction for /content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 115458.png:\n","Predict: ILICENSEEE OF MCDONALD?S\n","Confidence Scores: 0.27113205194473267\n","\n","Prediction for /content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 122655.png:\n","Predict: How You Benefit # Spreads\n","Confidence Scores: 0.650229811668396\n","\n"]}]},{"cell_type":"code","source":["main_train(use_local_model=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43ifJ6xEIHV3","executionInfo":{"status":"ok","timestamp":1719887844732,"user_tz":-420,"elapsed":2948887,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"b63a5864-1620-4c38-ee1d-56979602d235"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 5097 samples from /content/drive/MyDrive/PPL/trocr/train\n","Loaded 1161 samples from /content/drive/MyDrive/PPL/trocr/val\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded local model from /content/drive/MyDrive/PPL/trocr/model\n","Using device cuda.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Batch 1: 0.325440376996994 loss\n","Epoch 1, Batch 2: 0.35447636246681213 loss\n","Epoch 1, Batch 3: 0.43975505232810974 loss\n","Epoch 1, Batch 4: 0.41113150119781494 loss\n","Epoch 1, Batch 5: 0.29509639739990234 loss\n","Epoch 1, Batch 6: 0.3646048605442047 loss\n","Epoch 1, Batch 7: 0.36063694953918457 loss\n","Epoch 1, Batch 8: 0.3480566442012787 loss\n","Epoch 1, Batch 9: 0.32526150345802307 loss\n","Epoch 1, Batch 10: 0.5145785212516785 loss\n","Epoch 1, Batch 11: 0.3626912534236908 loss\n","Epoch 1, Batch 12: 0.5134511590003967 loss\n","Epoch 1, Batch 13: 0.24454553425312042 loss\n","Epoch 1, Batch 14: 0.2250242829322815 loss\n","Epoch 1, Batch 15: 0.40955811738967896 loss\n","Epoch 1, Batch 16: 0.3639061450958252 loss\n","Epoch 1, Batch 17: 0.34319767355918884 loss\n","Epoch 1, Batch 18: 0.2761509418487549 loss\n","Epoch 1, Batch 19: 0.39166519045829773 loss\n","Epoch 1, Batch 20: 0.41190028190612793 loss\n","Epoch 1, Batch 21: 0.45793595910072327 loss\n","Epoch 1, Batch 22: 0.39946913719177246 loss\n","Epoch 1, Batch 23: 0.353910893201828 loss\n","Epoch 1, Batch 24: 0.4403533339500427 loss\n","Epoch 1, Batch 25: 0.36225491762161255 loss\n","Epoch 1, Batch 26: 0.522053062915802 loss\n","Epoch 1, Batch 27: 0.41733241081237793 loss\n","Epoch 1, Batch 28: 0.3576078712940216 loss\n","Epoch 1, Batch 29: 0.37928545475006104 loss\n","Epoch 1, Batch 30: 0.3534974157810211 loss\n","Epoch 1, Batch 31: 0.46637213230133057 loss\n","Epoch 1, Batch 32: 0.36737754940986633 loss\n","Epoch 1, Batch 33: 0.2684378921985626 loss\n","Epoch 1, Batch 34: 0.5519226789474487 loss\n","Epoch 1, Batch 35: 0.3949672281742096 loss\n","Epoch 1, Batch 36: 0.3864414691925049 loss\n","Epoch 1, Batch 37: 0.32036319375038147 loss\n","Epoch 1, Batch 38: 0.32797685265541077 loss\n","Epoch 1, Batch 39: 0.35783499479293823 loss\n","Epoch 1, Batch 40: 0.3960026800632477 loss\n","Epoch 1, Batch 41: 0.3221525549888611 loss\n","Epoch 1, Batch 42: 0.3256145715713501 loss\n","Epoch 1, Batch 43: 0.3572428822517395 loss\n","Epoch 1, Batch 44: 0.31295737624168396 loss\n","Epoch 1, Batch 45: 0.41455212235450745 loss\n","Epoch 1, Batch 46: 0.32322368025779724 loss\n","Epoch 1, Batch 47: 0.3939429521560669 loss\n","Epoch 1, Batch 48: 0.3684217035770416 loss\n","Epoch 1, Batch 49: 0.3790065050125122 loss\n","Epoch 1, Batch 50: 0.33107224106788635 loss\n","Epoch 1, Batch 51: 0.33381137251853943 loss\n","Epoch 1, Batch 52: 0.38889461755752563 loss\n","Epoch 1, Batch 53: 0.3095748722553253 loss\n","Epoch 1, Batch 54: 0.4233751893043518 loss\n","Epoch 1, Batch 55: 0.3486110270023346 loss\n","Epoch 1, Batch 56: 0.38204389810562134 loss\n","Epoch 1, Batch 57: 0.3091777563095093 loss\n","Epoch 1, Batch 58: 0.33188167214393616 loss\n","Epoch 1, Batch 59: 0.45408061146736145 loss\n","Epoch 1, Batch 60: 0.349663645029068 loss\n","Epoch 1, Batch 61: 0.2977919280529022 loss\n","Epoch 1, Batch 62: 0.3482590317726135 loss\n","Epoch 1, Batch 63: 0.378682404756546 loss\n","Epoch 1, Batch 64: 0.25561395287513733 loss\n","Epoch 1, Batch 65: 0.41732314229011536 loss\n","Epoch 1, Batch 66: 0.19916294515132904 loss\n","Epoch 1, Batch 67: 0.26176339387893677 loss\n","Epoch 1, Batch 68: 0.36631083488464355 loss\n","Epoch 1, Batch 69: 0.43598228693008423 loss\n","Epoch 1, Batch 70: 0.28891557455062866 loss\n","Epoch 1, Batch 71: 0.2264130711555481 loss\n","Epoch 1, Batch 72: 0.29169586300849915 loss\n","Epoch 1, Batch 73: 0.32360681891441345 loss\n","Epoch 1, Batch 74: 0.4003554582595825 loss\n","Epoch 1, Batch 75: 0.3431932330131531 loss\n","Epoch 1, Batch 76: 0.24918773770332336 loss\n","Epoch 1, Batch 77: 0.31561920046806335 loss\n","Epoch 1, Batch 78: 0.2971316874027252 loss\n","Epoch 1, Batch 79: 0.26463785767555237 loss\n","Epoch 1, Batch 80: 0.32210102677345276 loss\n","Epoch 1, Batch 81: 0.2545141577720642 loss\n","Epoch 1, Batch 82: 0.292656272649765 loss\n","Epoch 1, Batch 83: 0.3433579206466675 loss\n","Epoch 1, Batch 84: 0.3322712779045105 loss\n","Epoch 1, Batch 85: 0.2586127817630768 loss\n","Epoch 1, Batch 86: 0.3073011040687561 loss\n","Epoch 1, Batch 87: 0.38817158341407776 loss\n","Epoch 1, Batch 88: 0.2999403178691864 loss\n","Epoch 1, Batch 89: 0.33780792355537415 loss\n","Epoch 1, Batch 90: 0.28980499505996704 loss\n","Epoch 1, Batch 91: 0.2762249708175659 loss\n","Epoch 1, Batch 92: 0.30603402853012085 loss\n","Epoch 1, Batch 93: 0.31351497769355774 loss\n","Epoch 1, Batch 94: 0.2544289827346802 loss\n","Epoch 1, Batch 95: 0.39321625232696533 loss\n","Epoch 1, Batch 96: 0.3362630009651184 loss\n","Epoch 1, Batch 97: 0.22906696796417236 loss\n","Epoch 1, Batch 98: 0.35237985849380493 loss\n","Epoch 1, Batch 99: 0.33984464406967163 loss\n","Epoch 1, Batch 100: 0.3180582821369171 loss\n","Epoch 1, Batch 101: 0.1672278493642807 loss\n","Epoch 1, Batch 102: 0.2452859729528427 loss\n","Epoch 1, Batch 103: 0.2952895760536194 loss\n","Epoch 1, Batch 104: 0.27635300159454346 loss\n","Epoch 1, Batch 105: 0.3002695143222809 loss\n","Epoch 1, Batch 106: 0.25113120675086975 loss\n","Epoch 1, Batch 107: 0.25280091166496277 loss\n","Epoch 1, Batch 108: 0.2166580706834793 loss\n","Epoch 1, Batch 109: 0.4261504113674164 loss\n","Epoch 1, Batch 110: 0.3785285949707031 loss\n","Epoch 1, Batch 111: 0.2669579088687897 loss\n","Epoch 1, Batch 112: 0.40061452984809875 loss\n","Epoch 1, Batch 113: 0.28549885749816895 loss\n","Epoch 1, Batch 114: 0.2887639105319977 loss\n","Epoch 1, Batch 115: 0.3124692440032959 loss\n","Epoch 1, Batch 116: 0.24301882088184357 loss\n","Epoch 1, Batch 117: 0.3366650342941284 loss\n","Epoch 1, Batch 118: 0.32423102855682373 loss\n","Epoch 1, Batch 119: 0.2906932234764099 loss\n","Epoch 1, Batch 120: 0.30136457085609436 loss\n","Epoch 1, Batch 121: 0.2348262220621109 loss\n","Epoch 1, Batch 122: 0.3495866656303406 loss\n","Epoch 1, Batch 123: 0.2361678183078766 loss\n","Epoch 1, Batch 124: 0.23522236943244934 loss\n","Epoch 1, Batch 125: 0.3490312695503235 loss\n","Epoch 1, Batch 126: 0.3383156359195709 loss\n","Epoch 1, Batch 127: 0.2984497845172882 loss\n","Epoch 1, Batch 128: 0.22353093326091766 loss\n","Epoch 1, Batch 129: 0.30621337890625 loss\n","Epoch 1, Batch 130: 0.270821213722229 loss\n","Epoch 1, Batch 131: 0.3069121241569519 loss\n","Epoch 1, Batch 132: 0.36555564403533936 loss\n","Epoch 1, Batch 133: 0.29948192834854126 loss\n","Epoch 1, Batch 134: 0.40193623304367065 loss\n","Epoch 1, Batch 135: 0.3303596079349518 loss\n","Epoch 1, Batch 136: 0.27129074931144714 loss\n","Epoch 1, Batch 137: 0.3271639943122864 loss\n","Epoch 1, Batch 138: 0.30809879302978516 loss\n","Epoch 1, Batch 139: 0.2847122550010681 loss\n","Epoch 1, Batch 140: 0.2853107750415802 loss\n","Epoch 1, Batch 141: 0.3177359998226166 loss\n","Epoch 1, Batch 142: 0.25608378648757935 loss\n","Epoch 1, Batch 143: 0.26726821064949036 loss\n","Epoch 1, Batch 144: 0.295324444770813 loss\n","Epoch 1, Batch 145: 0.2988506257534027 loss\n","Epoch 1, Batch 146: 0.229849174618721 loss\n","Epoch 1, Batch 147: 0.21095840632915497 loss\n","Epoch 1, Batch 148: 0.28633731603622437 loss\n","Epoch 1, Batch 149: 0.2141711562871933 loss\n","Epoch 1, Batch 150: 0.3882962763309479 loss\n","Epoch 1, Batch 151: 0.3189086318016052 loss\n","Epoch 1, Batch 152: 0.4511781632900238 loss\n","Epoch 1, Batch 153: 0.26973482966423035 loss\n","Epoch 1, Batch 154: 0.41509583592414856 loss\n","Epoch 1, Batch 155: 0.2553204298019409 loss\n","Epoch 1, Batch 156: 0.27634453773498535 loss\n","Epoch 1, Batch 157: 0.2883720099925995 loss\n","Epoch 1, Batch 158: 0.36250028014183044 loss\n","Epoch 1, Batch 159: 0.2675362527370453 loss\n","Epoch 1, Batch 160: 0.3445114493370056 loss\n","Epoch 1, Batch 161: 0.28239789605140686 loss\n","Epoch 1, Batch 162: 0.31395837664604187 loss\n","Epoch 1, Batch 163: 0.26865941286087036 loss\n","Epoch 1, Batch 164: 0.2206539511680603 loss\n","Epoch 1, Batch 165: 0.3113020360469818 loss\n","Epoch 1, Batch 166: 0.28243494033813477 loss\n","Epoch 1, Batch 167: 0.2804853022098541 loss\n","Epoch 1, Batch 168: 0.29746729135513306 loss\n","Epoch 1, Batch 169: 0.28202512860298157 loss\n","Epoch 1, Batch 170: 0.30912622809410095 loss\n","Epoch 1, Batch 171: 0.28159186244010925 loss\n","Epoch 1, Batch 172: 0.26482513546943665 loss\n","Epoch 1, Batch 173: 0.2527956962585449 loss\n","Epoch 1, Batch 174: 0.2467234581708908 loss\n","Epoch 1, Batch 175: 0.49905091524124146 loss\n","Epoch 1, Batch 176: 0.19816090166568756 loss\n","Epoch 1, Batch 177: 0.26777184009552 loss\n","Epoch 1, Batch 178: 0.16527140140533447 loss\n","Epoch 1, Batch 179: 0.2697351574897766 loss\n","Epoch 1, Batch 180: 0.23456013202667236 loss\n","Epoch 1, Batch 181: 0.2496320754289627 loss\n","Epoch 1, Batch 182: 0.2851426601409912 loss\n","Epoch 1, Batch 183: 0.2766181230545044 loss\n","Epoch 1, Batch 184: 0.21618901193141937 loss\n","Epoch 1, Batch 185: 0.3293490707874298 loss\n","Epoch 1, Batch 186: 0.27526599168777466 loss\n","Epoch 1, Batch 187: 0.2794996201992035 loss\n","Epoch 1, Batch 188: 0.3030869662761688 loss\n","Epoch 1, Batch 189: 0.28762444853782654 loss\n","Epoch 1, Batch 190: 0.2605864405632019 loss\n","Epoch 1, Batch 191: 0.3066222071647644 loss\n","Epoch 1, Batch 192: 0.2690816819667816 loss\n","Epoch 1, Batch 193: 0.23090584576129913 loss\n","Epoch 1, Batch 194: 0.29241955280303955 loss\n","Epoch 1, Batch 195: 0.2536225914955139 loss\n","Epoch 1, Batch 196: 0.3856186866760254 loss\n","Epoch 1, Batch 197: 0.19890204071998596 loss\n","Epoch 1, Batch 198: 0.27322930097579956 loss\n","Epoch 1, Batch 199: 0.3347645401954651 loss\n","Epoch 1, Batch 200: 0.32108351588249207 loss\n","Epoch 1, Batch 201: 0.3572840988636017 loss\n","Epoch 1, Batch 202: 0.24250614643096924 loss\n","Epoch 1, Batch 203: 0.3350321054458618 loss\n","Epoch 1, Batch 204: 0.18419554829597473 loss\n","Epoch 1, Batch 205: 0.3183254599571228 loss\n","Epoch 1, Batch 206: 0.31358787417411804 loss\n","Epoch 1, Batch 207: 0.3208726942539215 loss\n","Epoch 1, Batch 208: 0.3657202422618866 loss\n","Epoch 1, Batch 209: 0.23768110573291779 loss\n","Epoch 1, Batch 210: 0.2775053083896637 loss\n","Epoch 1, Batch 211: 0.25066518783569336 loss\n","Epoch 1, Batch 212: 0.28337153792381287 loss\n","Epoch 1, Batch 213: 0.2692714333534241 loss\n","Epoch 1, Batch 214: 0.31255006790161133 loss\n","Epoch 1, Batch 215: 0.21974723041057587 loss\n","Epoch 1, Batch 216: 0.2438969910144806 loss\n","Epoch 1, Batch 217: 0.4150383770465851 loss\n","Epoch 1, Batch 218: 0.32045823335647583 loss\n","Epoch 1, Batch 219: 0.2342500537633896 loss\n","Epoch 1, Batch 220: 0.23491926491260529 loss\n","Epoch 1, Batch 221: 0.3107600510120392 loss\n","Epoch 1, Batch 222: 0.28982579708099365 loss\n","Epoch 1, Batch 223: 0.5751320719718933 loss\n","Epoch 1, Batch 224: 0.3631788492202759 loss\n","Epoch 1, Batch 225: 0.26190200448036194 loss\n","Epoch 1, Batch 226: 0.31267642974853516 loss\n","Epoch 1, Batch 227: 0.1880345195531845 loss\n","Epoch 1, Batch 228: 0.2690567672252655 loss\n","Epoch 1, Batch 229: 0.3640734851360321 loss\n","Epoch 1, Batch 230: 0.2959149479866028 loss\n","Epoch 1, Batch 231: 0.3069198727607727 loss\n","Epoch 1, Batch 232: 0.2722720503807068 loss\n","Epoch 1, Batch 233: 0.18664060533046722 loss\n","Epoch 1, Batch 234: 0.27221402525901794 loss\n","Epoch 1, Batch 235: 0.23988938331604004 loss\n","Epoch 1, Batch 236: 0.2607685327529907 loss\n","Epoch 1, Batch 237: 0.29256346821784973 loss\n","Epoch 1, Batch 238: 0.2462974190711975 loss\n","Epoch 1, Batch 239: 0.16907280683517456 loss\n","Epoch 1, Batch 240: 0.30892035365104675 loss\n","Epoch 1, Batch 241: 0.2948020398616791 loss\n","Epoch 1, Batch 242: 0.284556120634079 loss\n","Epoch 1, Batch 243: 0.37180501222610474 loss\n","Epoch 1, Batch 244: 0.23179739713668823 loss\n","Epoch 1, Batch 245: 0.2736780047416687 loss\n","Epoch 1, Batch 246: 0.37763920426368713 loss\n","Epoch 1, Batch 247: 0.206433966755867 loss\n","Epoch 1, Batch 248: 0.21802610158920288 loss\n","Epoch 1, Batch 249: 0.18006952106952667 loss\n","Epoch 1, Batch 250: 0.15486066043376923 loss\n","Epoch 1, Batch 251: 0.3074173033237457 loss\n","Epoch 1, Batch 252: 0.33116206526756287 loss\n","Epoch 1, Batch 253: 0.21030452847480774 loss\n","Epoch 1, Batch 254: 0.2852252423763275 loss\n","Epoch 1, Batch 255: 0.2229367196559906 loss\n","Epoch 1, Batch 256: 0.19746606051921844 loss\n","Epoch 1, Batch 257: 0.1609146147966385 loss\n","Epoch 1, Batch 258: 0.18991443514823914 loss\n","Epoch 1, Batch 259: 0.27308279275894165 loss\n","Epoch 1, Batch 260: 0.24944022297859192 loss\n","Epoch 1, Batch 261: 0.3739503026008606 loss\n","Epoch 1, Batch 262: 0.2268882691860199 loss\n","Epoch 1, Batch 263: 0.40884625911712646 loss\n","Epoch 1, Batch 264: 0.28450900316238403 loss\n","Epoch 1, Batch 265: 0.19071698188781738 loss\n","Epoch 1, Batch 266: 0.29954972863197327 loss\n","Epoch 1, Batch 267: 0.38667047023773193 loss\n","Epoch 1, Batch 268: 0.2780877947807312 loss\n","Epoch 1, Batch 269: 0.33146804571151733 loss\n","Epoch 1, Batch 270: 0.2287580966949463 loss\n","Epoch 1, Batch 271: 0.28891390562057495 loss\n","Epoch 1, Batch 272: 0.38798680901527405 loss\n","Epoch 1, Batch 273: 0.2415304332971573 loss\n","Epoch 1, Batch 274: 0.312389612197876 loss\n","Epoch 1, Batch 275: 0.27851301431655884 loss\n","Epoch 1, Batch 276: 0.5190852284431458 loss\n","Epoch 1, Batch 277: 0.20004820823669434 loss\n","Epoch 1, Batch 278: 0.193052276968956 loss\n","Epoch 1, Batch 279: 0.28985488414764404 loss\n","Epoch 1, Batch 280: 0.19052056968212128 loss\n","Epoch 1, Batch 281: 0.28765520453453064 loss\n","Epoch 1, Batch 282: 0.2867140471935272 loss\n","Epoch 1, Batch 283: 0.2913493514060974 loss\n","Epoch 1, Batch 284: 0.25758281350135803 loss\n","Epoch 1, Batch 285: 0.18712671101093292 loss\n","Epoch 1, Batch 286: 0.15837372839450836 loss\n","Epoch 1, Batch 287: 0.22912274301052094 loss\n","Epoch 1, Batch 288: 0.31700193881988525 loss\n","Epoch 1, Batch 289: 0.28083354234695435 loss\n","Epoch 1, Batch 290: 0.2429330050945282 loss\n","Epoch 1, Batch 291: 0.26376238465309143 loss\n","Epoch 1, Batch 292: 0.15285103023052216 loss\n","Epoch 1, Batch 293: 0.29258328676223755 loss\n","Epoch 1, Batch 294: 0.18371765315532684 loss\n","Epoch 1, Batch 295: 0.25964686274528503 loss\n","Epoch 1, Batch 296: 0.3519272804260254 loss\n","Epoch 1, Batch 297: 0.24638395011425018 loss\n","Epoch 1, Batch 298: 0.2852039933204651 loss\n","Epoch 1, Batch 299: 0.26392650604248047 loss\n","Epoch 1, Batch 300: 0.3043835759162903 loss\n","Epoch 1, Batch 301: 0.17232158780097961 loss\n","Epoch 1, Batch 302: 0.31125909090042114 loss\n","Epoch 1, Batch 303: 0.23832330107688904 loss\n","Epoch 1, Batch 304: 0.2519413232803345 loss\n","Epoch 1, Batch 305: 0.19499285519123077 loss\n","Epoch 1, Batch 306: 0.23882989585399628 loss\n","Epoch 1, Batch 307: 0.29965007305145264 loss\n","Epoch 1, Batch 308: 0.2533597946166992 loss\n","Epoch 1, Batch 309: 0.19539570808410645 loss\n","Epoch 1, Batch 310: 0.16943897306919098 loss\n","Epoch 1, Batch 311: 0.2528548538684845 loss\n","Epoch 1, Batch 312: 0.41830694675445557 loss\n","Epoch 1, Batch 313: 0.21546725928783417 loss\n","Epoch 1, Batch 314: 0.35149580240249634 loss\n","Epoch 1, Batch 315: 0.23234662413597107 loss\n","Epoch 1, Batch 316: 0.22529643774032593 loss\n","Epoch 1, Batch 317: 0.2905603051185608 loss\n","Epoch 1, Batch 318: 0.15421637892723083 loss\n","Epoch 1, Batch 319: 0.22711725533008575 loss\n","Epoch 1, Batch 320: 0.2364782989025116 loss\n","Epoch 1, Batch 321: 0.22128508985042572 loss\n","Epoch 1, Batch 322: 0.18394656479358673 loss\n","Epoch 1, Batch 323: 0.3468487560749054 loss\n","Epoch 1, Batch 324: 0.18299967050552368 loss\n","Epoch 1, Batch 325: 0.25385674834251404 loss\n","Epoch 1, Batch 326: 0.2131296992301941 loss\n","Epoch 1, Batch 327: 0.32726913690567017 loss\n","Epoch 1, Batch 328: 0.30799776315689087 loss\n","Epoch 1, Batch 329: 0.1476525217294693 loss\n","Epoch 1, Batch 330: 0.21830321848392487 loss\n","Epoch 1, Batch 331: 0.19617202877998352 loss\n","Epoch 1, Batch 332: 0.19602176547050476 loss\n","Epoch 1, Batch 333: 0.19047798216342926 loss\n","Epoch 1, Batch 334: 0.21057049930095673 loss\n","Epoch 1, Batch 335: 0.33368980884552 loss\n","Epoch 1, Batch 336: 0.31302610039711 loss\n","Epoch 1, Batch 337: 0.27386194467544556 loss\n","Epoch 1, Batch 338: 0.1684550940990448 loss\n","Epoch 1, Batch 339: 0.21615400910377502 loss\n","Epoch 1, Batch 340: 0.24585315585136414 loss\n","Epoch 1, Batch 341: 0.23035259544849396 loss\n","Epoch 1, Batch 342: 0.1987169086933136 loss\n","Epoch 1, Batch 343: 0.22768114507198334 loss\n","Epoch 1, Batch 344: 0.3328084647655487 loss\n","Epoch 1, Batch 345: 0.30748870968818665 loss\n","Epoch 1, Batch 346: 0.18019895255565643 loss\n","Epoch 1, Batch 347: 0.348097562789917 loss\n","Epoch 1, Batch 348: 0.25887757539749146 loss\n","Epoch 1, Batch 349: 0.14985500276088715 loss\n","Epoch 1, Batch 350: 0.2925245463848114 loss\n","Epoch 1, Batch 351: 0.2811557948589325 loss\n","Epoch 1, Batch 352: 0.23500454425811768 loss\n","Epoch 1, Batch 353: 0.2729974687099457 loss\n","Epoch 1, Batch 354: 0.2856683135032654 loss\n","Epoch 1, Batch 355: 0.2707769572734833 loss\n","Epoch 1, Batch 356: 0.2584104537963867 loss\n","Epoch 1, Batch 357: 0.2806241810321808 loss\n","Epoch 1, Batch 358: 0.3584604561328888 loss\n","Epoch 1, Batch 359: 0.34389394521713257 loss\n","Epoch 1, Batch 360: 0.2802596986293793 loss\n","Epoch 1, Batch 361: 0.2213439643383026 loss\n","Epoch 1, Batch 362: 0.32988160848617554 loss\n","Epoch 1, Batch 363: 0.24411770701408386 loss\n","Epoch 1, Batch 364: 0.20212838053703308 loss\n","Epoch 1, Batch 365: 0.21390557289123535 loss\n","Epoch 1, Batch 366: 0.2175072282552719 loss\n","Epoch 1, Batch 367: 0.20011912286281586 loss\n","Epoch 1, Batch 368: 0.14336718618869781 loss\n","Epoch 1, Batch 369: 0.32112839818000793 loss\n","Epoch 1, Batch 370: 0.23373927175998688 loss\n","Epoch 1, Batch 371: 0.18468351662158966 loss\n","Epoch 1, Batch 372: 0.2150261104106903 loss\n","Epoch 1, Batch 373: 0.22533172369003296 loss\n","Epoch 1, Batch 374: 0.23809628188610077 loss\n","Epoch 1, Batch 375: 0.20552483201026917 loss\n","Epoch 1, Batch 376: 0.24820677936077118 loss\n","Epoch 1, Batch 377: 0.13711680471897125 loss\n","Epoch 1, Batch 378: 0.22473716735839844 loss\n","Epoch 1, Batch 379: 0.2167612463235855 loss\n","Epoch 1, Batch 380: 0.22553779184818268 loss\n","Epoch 1, Batch 381: 0.28696393966674805 loss\n","Epoch 1, Batch 382: 0.2584151327610016 loss\n","Epoch 1, Batch 383: 0.2688232660293579 loss\n","Epoch 1, Batch 384: 0.2543288767337799 loss\n","Epoch 1, Batch 385: 0.2189749926328659 loss\n","Epoch 1, Batch 386: 0.25872546434402466 loss\n","Epoch 1, Batch 387: 0.27466413378715515 loss\n","Epoch 1, Batch 388: 0.2274101823568344 loss\n","Epoch 1, Batch 389: 0.25246644020080566 loss\n","Epoch 1, Batch 390: 0.22257821261882782 loss\n","Epoch 1, Batch 391: 0.2876233458518982 loss\n","Epoch 1, Batch 392: 0.19674865901470184 loss\n","Epoch 1, Batch 393: 0.22915427386760712 loss\n","Epoch 1, Batch 394: 0.27218863368034363 loss\n","Epoch 1, Batch 395: 0.17749911546707153 loss\n","Epoch 1, Batch 396: 0.174483522772789 loss\n","Epoch 1, Batch 397: 0.2260931432247162 loss\n","Epoch 1, Batch 398: 0.1728883981704712 loss\n","Epoch 1, Batch 399: 0.26847532391548157 loss\n","Epoch 1, Batch 400: 0.24359850585460663 loss\n","Epoch 1, Batch 401: 0.19257986545562744 loss\n","Epoch 1, Batch 402: 0.21733136475086212 loss\n","Epoch 1, Batch 403: 0.17035722732543945 loss\n","Epoch 1, Batch 404: 0.23644493520259857 loss\n","Epoch 1, Batch 405: 0.2174609899520874 loss\n","Epoch 1, Batch 406: 0.2146371304988861 loss\n","Epoch 1, Batch 407: 0.3905943036079407 loss\n","Epoch 1, Batch 408: 0.25456753373146057 loss\n","Epoch 1, Batch 409: 0.28317636251449585 loss\n","Epoch 1, Batch 410: 0.19395315647125244 loss\n","Epoch 1, Batch 411: 0.184353306889534 loss\n","Epoch 1, Batch 412: 0.19628462195396423 loss\n","Epoch 1, Batch 413: 0.28962522745132446 loss\n","Epoch 1, Batch 414: 0.1826193481683731 loss\n","Epoch 1, Batch 415: 0.2076062560081482 loss\n","Epoch 1, Batch 416: 0.22948354482650757 loss\n","Epoch 1, Batch 417: 0.30719152092933655 loss\n","Epoch 1, Batch 418: 0.2069380283355713 loss\n","Epoch 1, Batch 419: 0.1727205514907837 loss\n","Epoch 1, Batch 420: 0.3062920570373535 loss\n","Epoch 1, Batch 421: 0.18285682797431946 loss\n","Epoch 1, Batch 422: 0.2245631366968155 loss\n","Epoch 1, Batch 423: 0.20682725310325623 loss\n","Epoch 1, Batch 424: 0.15771269798278809 loss\n","Epoch 1, Batch 425: 0.35523995757102966 loss\n","Epoch 1, Batch 426: 0.24046050012111664 loss\n","Epoch 1, Batch 427: 0.24099105596542358 loss\n","Epoch 1, Batch 428: 0.3097604513168335 loss\n","Epoch 1, Batch 429: 0.3453672230243683 loss\n","Epoch 1, Batch 430: 0.17085911333560944 loss\n","Epoch 1, Batch 431: 0.16452881693840027 loss\n","Epoch 1, Batch 432: 0.16604185104370117 loss\n","Epoch 1, Batch 433: 0.1952197104692459 loss\n","Epoch 1, Batch 434: 0.303446501493454 loss\n","Epoch 1, Batch 435: 0.19381901621818542 loss\n","Epoch 1, Batch 436: 0.26375284790992737 loss\n","Epoch 1, Batch 437: 0.2151070088148117 loss\n","Epoch 1, Batch 438: 0.32574567198753357 loss\n","Epoch 1, Batch 439: 0.2068568915128708 loss\n","Epoch 1, Batch 440: 0.23223437368869781 loss\n","Epoch 1, Batch 441: 0.21794989705085754 loss\n","Epoch 1, Batch 442: 0.23539340496063232 loss\n","Epoch 1, Batch 443: 0.2299831062555313 loss\n","Epoch 1, Batch 444: 0.09743855893611908 loss\n","Epoch 1, Batch 445: 0.24276234209537506 loss\n","Epoch 1, Batch 446: 0.19674833118915558 loss\n","Epoch 1, Batch 447: 0.26276496052742004 loss\n","Epoch 1, Batch 448: 0.3274494409561157 loss\n","Epoch 1, Batch 449: 0.2164870649576187 loss\n","Epoch 1, Batch 450: 0.21215766668319702 loss\n","Epoch 1, Batch 451: 0.29982075095176697 loss\n","Epoch 1, Batch 452: 0.21667644381523132 loss\n","Epoch 1, Batch 453: 0.21609002351760864 loss\n","Epoch 1, Batch 454: 0.244098499417305 loss\n","Epoch 1, Batch 455: 0.24857676029205322 loss\n","Epoch 1, Batch 456: 0.24111764132976532 loss\n","Epoch 1, Batch 457: 0.1607075184583664 loss\n","Epoch 1, Batch 458: 0.2650074064731598 loss\n","Epoch 1, Batch 459: 0.2774128317832947 loss\n","Epoch 1, Batch 460: 0.26454031467437744 loss\n","Epoch 1, Batch 461: 0.2807179093360901 loss\n","Epoch 1, Batch 462: 0.13633838295936584 loss\n","Epoch 1, Batch 463: 0.17432773113250732 loss\n","Epoch 1, Batch 464: 0.2775733768939972 loss\n","Epoch 1, Batch 465: 0.2078637033700943 loss\n","Epoch 1, Batch 466: 0.23779802024364471 loss\n","Epoch 1, Batch 467: 0.2484026998281479 loss\n","Epoch 1, Batch 468: 0.18620701134204865 loss\n","Epoch 1, Batch 469: 0.1979982703924179 loss\n","Epoch 1, Batch 470: 0.23991425335407257 loss\n","Epoch 1, Batch 471: 0.3953942656517029 loss\n","Epoch 1, Batch 472: 0.1708727777004242 loss\n","Epoch 1, Batch 473: 0.22740767896175385 loss\n","Epoch 1, Batch 474: 0.23578009009361267 loss\n","Epoch 1, Batch 475: 0.2775106430053711 loss\n","Epoch 1, Batch 476: 0.15383164584636688 loss\n","Epoch 1, Batch 477: 0.2394554764032364 loss\n","Epoch 1, Batch 478: 0.2309415489435196 loss\n","Epoch 1, Batch 479: 0.16902431845664978 loss\n","Epoch 1, Batch 480: 0.24473175406455994 loss\n","Epoch 1, Batch 481: 0.1771237850189209 loss\n","Epoch 1, Batch 482: 0.21282529830932617 loss\n","Epoch 1, Batch 483: 0.1730220466852188 loss\n","Epoch 1, Batch 484: 0.3117407560348511 loss\n","Epoch 1, Batch 485: 0.31106895208358765 loss\n","Epoch 1, Batch 486: 0.1984768807888031 loss\n","Epoch 1, Batch 487: 0.19740185141563416 loss\n","Epoch 1, Batch 488: 0.24508872628211975 loss\n","Epoch 1, Batch 489: 0.3329160213470459 loss\n","Epoch 1, Batch 490: 0.2034076750278473 loss\n","Epoch 1, Batch 491: 0.21689562499523163 loss\n","Epoch 1, Batch 492: 0.2721525728702545 loss\n","Epoch 1, Batch 493: 0.27782586216926575 loss\n","Epoch 1, Batch 494: 0.3634682893753052 loss\n","Epoch 1, Batch 495: 0.30330488085746765 loss\n","Epoch 1, Batch 496: 0.17856428027153015 loss\n","Epoch 1, Batch 497: 0.17099232971668243 loss\n","Epoch 1, Batch 498: 0.20647713541984558 loss\n","Epoch 1, Batch 499: 0.2546428442001343 loss\n","Epoch 1, Batch 500: 0.24047161638736725 loss\n","Epoch 1, Batch 501: 0.18944628536701202 loss\n","Epoch 1, Batch 502: 0.20158036053180695 loss\n","Epoch 1, Batch 503: 0.2415243685245514 loss\n","Epoch 1, Batch 504: 0.19745849072933197 loss\n","Epoch 1, Batch 505: 0.2541397213935852 loss\n","Epoch 1, Batch 506: 0.28575703501701355 loss\n","Epoch 1, Batch 507: 0.22042955458164215 loss\n","Epoch 1, Batch 508: 0.2747187316417694 loss\n","Epoch 1, Batch 509: 0.1391419917345047 loss\n","Epoch 1, Batch 510: 0.18593548238277435 loss\n","Epoch 1, Batch 511: 0.29007184505462646 loss\n","Epoch 1, Batch 512: 0.23999904096126556 loss\n","Epoch 1, Batch 513: 0.2279629111289978 loss\n","Epoch 1, Batch 514: 0.26298877596855164 loss\n","Epoch 1, Batch 515: 0.22671057283878326 loss\n","Epoch 1, Batch 516: 0.14169150590896606 loss\n","Epoch 1, Batch 517: 0.16950751841068268 loss\n","Epoch 1, Batch 518: 0.27341771125793457 loss\n","Epoch 1, Batch 519: 0.20614977180957794 loss\n","Epoch 1, Batch 520: 0.3385964035987854 loss\n","Epoch 1, Batch 521: 0.1450694054365158 loss\n","Epoch 1, Batch 522: 0.18746021389961243 loss\n","Epoch 1, Batch 523: 0.2583494186401367 loss\n","Epoch 1, Batch 524: 0.12439655512571335 loss\n","Epoch 1, Batch 525: 0.2557262182235718 loss\n","Epoch 1, Batch 526: 0.1793317049741745 loss\n","Epoch 1, Batch 527: 0.2110651433467865 loss\n","Epoch 1, Batch 528: 0.2815774977207184 loss\n","Epoch 1, Batch 529: 0.24699285626411438 loss\n","Epoch 1, Batch 530: 0.2669278383255005 loss\n","Epoch 1, Batch 531: 0.1982138603925705 loss\n","Epoch 1, Batch 532: 0.179154172539711 loss\n","Epoch 1, Batch 533: 0.1944732367992401 loss\n","Epoch 1, Batch 534: 0.2536965012550354 loss\n","Epoch 1, Batch 535: 0.2360411286354065 loss\n","Epoch 1, Batch 536: 0.1725582331418991 loss\n","Epoch 1, Batch 537: 0.20414794981479645 loss\n","Epoch 1, Batch 538: 0.2117350548505783 loss\n","Epoch 1, Batch 539: 0.22130531072616577 loss\n","Epoch 1, Batch 540: 0.1918676346540451 loss\n","Epoch 1, Batch 541: 0.2592255473136902 loss\n","Epoch 1, Batch 542: 0.29250243306159973 loss\n","Epoch 1, Batch 543: 0.18904896080493927 loss\n","Epoch 1, Batch 544: 0.15776829421520233 loss\n","Epoch 1, Batch 545: 0.18942813575267792 loss\n","Epoch 1, Batch 546: 0.2567932605743408 loss\n","Epoch 1, Batch 547: 0.09990575164556503 loss\n","Epoch 1, Batch 548: 0.36124226450920105 loss\n","Epoch 1, Batch 549: 0.15407049655914307 loss\n","Epoch 1, Batch 550: 0.22797194123268127 loss\n","Epoch 1, Batch 551: 0.24515876173973083 loss\n","Epoch 1, Batch 552: 0.29522812366485596 loss\n","Epoch 1, Batch 553: 0.19786304235458374 loss\n","Epoch 1, Batch 554: 0.22812454402446747 loss\n","Epoch 1, Batch 555: 0.26480454206466675 loss\n","Epoch 1, Batch 556: 0.21044224500656128 loss\n","Epoch 1, Batch 557: 0.23047731816768646 loss\n","Epoch 1, Batch 558: 0.16880381107330322 loss\n","Epoch 1, Batch 559: 0.33550795912742615 loss\n","Epoch 1, Batch 560: 0.23478196561336517 loss\n","Epoch 1, Batch 561: 0.16499261558055878 loss\n","Epoch 1, Batch 562: 0.21141040325164795 loss\n","Epoch 1, Batch 563: 0.17080458998680115 loss\n","Epoch 1, Batch 564: 0.22323212027549744 loss\n","Epoch 1, Batch 565: 0.1947723776102066 loss\n","Epoch 1, Batch 566: 0.21797744929790497 loss\n","Epoch 1, Batch 567: 0.12084491550922394 loss\n","Epoch 1, Batch 568: 0.17556269466876984 loss\n","Epoch 1, Batch 569: 0.1728152632713318 loss\n","Epoch 1, Batch 570: 0.21112029254436493 loss\n","Epoch 1, Batch 571: 0.2638883888721466 loss\n","Epoch 1, Batch 572: 0.18954767286777496 loss\n","Epoch 1, Batch 573: 0.15272270143032074 loss\n","Epoch 1, Batch 574: 0.12792792916297913 loss\n","Epoch 1, Batch 575: 0.20659376680850983 loss\n","Epoch 1, Batch 576: 0.15022049844264984 loss\n","Epoch 1, Batch 577: 0.28280138969421387 loss\n","Epoch 1, Batch 578: 0.25921395421028137 loss\n","Epoch 1, Batch 579: 0.1451188325881958 loss\n","Epoch 1, Batch 580: 0.16338297724723816 loss\n","Epoch 1, Batch 581: 0.18570132553577423 loss\n","Epoch 1, Batch 582: 0.21330410242080688 loss\n","Epoch 1, Batch 583: 0.20598527789115906 loss\n","Epoch 1, Batch 584: 0.18726809322834015 loss\n","Epoch 1, Batch 585: 0.1713414192199707 loss\n","Epoch 1, Batch 586: 0.12261839956045151 loss\n","Epoch 1, Batch 587: 0.16426338255405426 loss\n","Epoch 1, Batch 588: 0.21817634999752045 loss\n","Epoch 1, Batch 589: 0.13317537307739258 loss\n","Epoch 1, Batch 590: 0.23631185293197632 loss\n","Epoch 1, Batch 591: 0.16900183260440826 loss\n","Epoch 1, Batch 592: 0.14212343096733093 loss\n","Epoch 1, Batch 593: 0.16273950040340424 loss\n","Epoch 1, Batch 594: 0.20784786343574524 loss\n","Epoch 1, Batch 595: 0.26992830634117126 loss\n","Epoch 1, Batch 596: 0.20503094792366028 loss\n","Epoch 1, Batch 597: 0.12178120762109756 loss\n","Epoch 1, Batch 598: 0.23824891448020935 loss\n","Epoch 1, Batch 599: 0.3860807716846466 loss\n","Epoch 1, Batch 600: 0.13177213072776794 loss\n","Epoch 1, Batch 601: 0.24502377212047577 loss\n","Epoch 1, Batch 602: 0.29125452041625977 loss\n","Epoch 1, Batch 603: 0.23609520494937897 loss\n","Epoch 1, Batch 604: 0.20924921333789825 loss\n","Epoch 1, Batch 605: 0.2096017748117447 loss\n","Epoch 1, Batch 606: 0.2078395038843155 loss\n","Epoch 1, Batch 607: 0.18697376549243927 loss\n","Epoch 1, Batch 608: 0.28680840134620667 loss\n","Epoch 1, Batch 609: 0.345492422580719 loss\n","Epoch 1, Batch 610: 0.2546883821487427 loss\n","Epoch 1, Batch 611: 0.19794246554374695 loss\n","Epoch 1, Batch 612: 0.18735899031162262 loss\n","Epoch 1, Batch 613: 0.177076518535614 loss\n","Epoch 1, Batch 614: 0.2573586404323578 loss\n","Epoch 1, Batch 615: 0.18789899349212646 loss\n","Epoch 1, Batch 616: 0.24990342557430267 loss\n","Epoch 1, Batch 617: 0.11651413142681122 loss\n","Epoch 1, Batch 618: 0.23327994346618652 loss\n","Epoch 1, Batch 619: 0.1498757153749466 loss\n","Epoch 1, Batch 620: 0.21823035180568695 loss\n","Epoch 1, Batch 621: 0.155996173620224 loss\n","Epoch 1, Batch 622: 0.2831607460975647 loss\n","Epoch 1, Batch 623: 0.30085834860801697 loss\n","Epoch 1, Batch 624: 0.22921647131443024 loss\n","Epoch 1, Batch 625: 0.14872713387012482 loss\n","Epoch 1, Batch 626: 0.2829875648021698 loss\n","Epoch 1, Batch 627: 0.24470727145671844 loss\n","Epoch 1, Batch 628: 0.1485108733177185 loss\n","Epoch 1, Batch 629: 0.2579593062400818 loss\n","Epoch 1, Batch 630: 0.3082590699195862 loss\n","Epoch 1, Batch 631: 0.21393869817256927 loss\n","Epoch 1, Batch 632: 0.1443011611700058 loss\n","Epoch 1, Batch 633: 0.12585009634494781 loss\n","Epoch 1, Batch 634: 0.1687186360359192 loss\n","Epoch 1, Batch 635: 0.39276009798049927 loss\n","Epoch 1, Batch 636: 0.15239116549491882 loss\n","Epoch 1, Batch 637: 0.22845695912837982 loss\n","Epoch 1, Batch 638: 0.25146856904029846 loss\n","Predicting batch 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Predicting batch 2\n","Predicting batch 3\n","Predicting batch 4\n","Predicting batch 5\n","Predicting batch 6\n","Predicting batch 7\n","Predicting batch 8\n","Predicting batch 9\n","Predicting batch 10\n","Predicting batch 11\n","Predicting batch 12\n","Predicting batch 13\n","Predicting batch 14\n","Predicting batch 15\n","Predicting batch 16\n","Predicting batch 17\n","Predicting batch 18\n","Predicting batch 19\n","Predicting batch 20\n","Predicting batch 21\n","Predicting batch 22\n","Predicting batch 23\n","Predicting batch 24\n","Predicting batch 25\n","Predicting batch 26\n","Predicting batch 27\n","Predicting batch 28\n","Predicting batch 29\n","Predicting batch 30\n","Predicting batch 31\n","Predicting batch 32\n","Predicting batch 33\n","Predicting batch 34\n","Predicting batch 35\n","Predicting batch 36\n","Predicting batch 37\n","Predicting batch 38\n","Predicting batch 39\n","Predicting batch 40\n","Predicting batch 41\n","Predicting batch 42\n","Predicting batch 43\n","Predicting batch 44\n","Predicting batch 45\n","Predicting batch 46\n","Predicting batch 47\n","Predicting batch 48\n","Predicting batch 49\n","Predicting batch 50\n","Predicting batch 51\n","Predicting batch 52\n","Predicting batch 53\n","Predicting batch 54\n","Predicting batch 55\n","Predicting batch 56\n","Predicting batch 57\n","Predicting batch 58\n","Predicting batch 59\n","Predicting batch 60\n","Predicting batch 61\n","Predicting batch 62\n","Predicting batch 63\n","Predicting batch 64\n","Predicting batch 65\n","Predicting batch 66\n","Predicting batch 67\n","Predicting batch 68\n","Predicting batch 69\n","Predicting batch 70\n","Predicting batch 71\n","Predicting batch 72\n","Predicting batch 73\n","Predicting batch 74\n","Predicting batch 75\n","Predicting batch 76\n","Predicting batch 77\n","Predicting batch 78\n","Predicting batch 79\n","Predicting batch 80\n","Predicting batch 81\n","Predicting batch 82\n","Predicting batch 83\n","Predicting batch 84\n","Predicting batch 85\n","Predicting batch 86\n","Predicting batch 87\n","Predicting batch 88\n","Predicting batch 89\n","Predicting batch 90\n","Predicting batch 91\n","Predicting batch 92\n","Predicting batch 93\n","Predicting batch 94\n","Predicting batch 95\n","Predicting batch 96\n","Predicting batch 97\n","Predicting batch 98\n","Predicting batch 99\n","Predicting batch 100\n","Predicting batch 101\n","Predicting batch 102\n","Predicting batch 103\n","Predicting batch 104\n","Predicting batch 105\n","Predicting batch 106\n","Predicting batch 107\n","Predicting batch 108\n","Predicting batch 109\n","Predicting batch 110\n","Predicting batch 111\n","Predicting batch 112\n","Predicting batch 113\n","Predicting batch 114\n","Predicting batch 115\n","Predicting batch 116\n","Predicting batch 117\n","Predicting batch 118\n","Predicting batch 119\n","Predicting batch 120\n","Predicting batch 121\n","Predicting batch 122\n","Predicting batch 123\n","Predicting batch 124\n","Predicting batch 125\n","Predicting batch 126\n","Predicting batch 127\n","Predicting batch 128\n","Predicting batch 129\n","Predicting batch 130\n","Predicting batch 131\n","Predicting batch 132\n","Predicting batch 133\n","Predicting batch 134\n","Predicting batch 135\n","Predicting batch 136\n","Predicting batch 137\n","Predicting batch 138\n","Predicting batch 139\n","Predicting batch 140\n","Predicting batch 141\n","Predicting batch 142\n","Predicting batch 143\n","Predicting batch 144\n","Predicting batch 145\n","Predicting batch 146\n","\n","---- Epoch 1 ----\n","Accuracy: 0.002583979328165375\n","\n","\n","Epoch 2, Batch 1: 0.1480989009141922 loss\n","Epoch 2, Batch 2: 0.27017441391944885 loss\n","Epoch 2, Batch 3: 0.1271638572216034 loss\n","Epoch 2, Batch 4: 0.15258997678756714 loss\n","Epoch 2, Batch 5: 0.16624970734119415 loss\n","Epoch 2, Batch 6: 0.1578475683927536 loss\n","Epoch 2, Batch 7: 0.16510187089443207 loss\n","Epoch 2, Batch 8: 0.1416652500629425 loss\n","Epoch 2, Batch 9: 0.15518087148666382 loss\n","Epoch 2, Batch 10: 0.18579190969467163 loss\n","Epoch 2, Batch 11: 0.3022887110710144 loss\n","Epoch 2, Batch 12: 0.18123425543308258 loss\n","Epoch 2, Batch 13: 0.08141887933015823 loss\n","Epoch 2, Batch 14: 0.1984034776687622 loss\n","Epoch 2, Batch 15: 0.13475096225738525 loss\n","Epoch 2, Batch 16: 0.13268740475177765 loss\n","Epoch 2, Batch 17: 0.1505124270915985 loss\n","Epoch 2, Batch 18: 0.14877691864967346 loss\n","Epoch 2, Batch 19: 0.168878436088562 loss\n","Epoch 2, Batch 20: 0.12604495882987976 loss\n","Epoch 2, Batch 21: 0.13727547228336334 loss\n","Epoch 2, Batch 22: 0.17164748907089233 loss\n","Epoch 2, Batch 23: 0.15569442510604858 loss\n","Epoch 2, Batch 24: 0.2432597428560257 loss\n","Epoch 2, Batch 25: 0.167274609208107 loss\n","Epoch 2, Batch 26: 0.1742289513349533 loss\n","Epoch 2, Batch 27: 0.1482113152742386 loss\n","Epoch 2, Batch 28: 0.1186109408736229 loss\n","Epoch 2, Batch 29: 0.15646454691886902 loss\n","Epoch 2, Batch 30: 0.1429307609796524 loss\n","Epoch 2, Batch 31: 0.12559211254119873 loss\n","Epoch 2, Batch 32: 0.11954069882631302 loss\n","Epoch 2, Batch 33: 0.14949367940425873 loss\n","Epoch 2, Batch 34: 0.1730467975139618 loss\n","Epoch 2, Batch 35: 0.1461564004421234 loss\n","Epoch 2, Batch 36: 0.18479642271995544 loss\n","Epoch 2, Batch 37: 0.17145338654518127 loss\n","Epoch 2, Batch 38: 0.16229167580604553 loss\n","Epoch 2, Batch 39: 0.15940150618553162 loss\n","Epoch 2, Batch 40: 0.11351970583200455 loss\n","Epoch 2, Batch 41: 0.1318351775407791 loss\n","Epoch 2, Batch 42: 0.12266649305820465 loss\n","Epoch 2, Batch 43: 0.21622870862483978 loss\n","Epoch 2, Batch 44: 0.2192946821451187 loss\n","Epoch 2, Batch 45: 0.17924362421035767 loss\n","Epoch 2, Batch 46: 0.10850139707326889 loss\n","Epoch 2, Batch 47: 0.16373217105865479 loss\n","Epoch 2, Batch 48: 0.1739964634180069 loss\n","Epoch 2, Batch 49: 0.12266664952039719 loss\n","Epoch 2, Batch 50: 0.229391410946846 loss\n","Epoch 2, Batch 51: 0.14068523049354553 loss\n","Epoch 2, Batch 52: 0.2049635648727417 loss\n","Epoch 2, Batch 53: 0.07855912297964096 loss\n","Epoch 2, Batch 54: 0.1680484414100647 loss\n","Epoch 2, Batch 55: 0.17508764564990997 loss\n","Epoch 2, Batch 56: 0.17212992906570435 loss\n","Epoch 2, Batch 57: 0.18120132386684418 loss\n","Epoch 2, Batch 58: 0.11651010066270828 loss\n","Epoch 2, Batch 59: 0.12318585813045502 loss\n","Epoch 2, Batch 60: 0.24483147263526917 loss\n","Epoch 2, Batch 61: 0.15738922357559204 loss\n","Epoch 2, Batch 62: 0.10547515004873276 loss\n","Epoch 2, Batch 63: 0.18845947086811066 loss\n","Epoch 2, Batch 64: 0.10544529557228088 loss\n","Epoch 2, Batch 65: 0.1424471139907837 loss\n","Epoch 2, Batch 66: 0.2498452365398407 loss\n","Epoch 2, Batch 67: 0.11947789788246155 loss\n","Epoch 2, Batch 68: 0.14107389748096466 loss\n","Epoch 2, Batch 69: 0.17634686827659607 loss\n","Epoch 2, Batch 70: 0.18080955743789673 loss\n","Epoch 2, Batch 71: 0.15792085230350494 loss\n","Epoch 2, Batch 72: 0.24156522750854492 loss\n","Epoch 2, Batch 73: 0.16203971207141876 loss\n","Epoch 2, Batch 74: 0.19392578303813934 loss\n","Epoch 2, Batch 75: 0.09628899395465851 loss\n","Epoch 2, Batch 76: 0.09657534211874008 loss\n","Epoch 2, Batch 77: 0.2969518005847931 loss\n","Epoch 2, Batch 78: 0.11853169649839401 loss\n","Epoch 2, Batch 79: 0.15547946095466614 loss\n","Epoch 2, Batch 80: 0.2125926911830902 loss\n","Epoch 2, Batch 81: 0.28844112157821655 loss\n","Epoch 2, Batch 82: 0.34242284297943115 loss\n","Epoch 2, Batch 83: 0.5168232917785645 loss\n","Epoch 2, Batch 84: 0.1791771948337555 loss\n","Epoch 2, Batch 85: 0.11510390043258667 loss\n","Epoch 2, Batch 86: 0.14624905586242676 loss\n","Epoch 2, Batch 87: 0.17351660132408142 loss\n","Epoch 2, Batch 88: 0.10887724161148071 loss\n","Epoch 2, Batch 89: 0.14111922681331635 loss\n","Epoch 2, Batch 90: 0.11486921459436417 loss\n","Epoch 2, Batch 91: 0.13737207651138306 loss\n","Epoch 2, Batch 92: 0.13777698576450348 loss\n","Epoch 2, Batch 93: 0.3130786418914795 loss\n","Epoch 2, Batch 94: 0.18856559693813324 loss\n","Epoch 2, Batch 95: 0.19631414115428925 loss\n","Epoch 2, Batch 96: 0.1516461819410324 loss\n","Epoch 2, Batch 97: 0.18885254859924316 loss\n","Epoch 2, Batch 98: 0.17037338018417358 loss\n","Epoch 2, Batch 99: 0.23139098286628723 loss\n","Epoch 2, Batch 100: 0.10226014256477356 loss\n","Epoch 2, Batch 101: 0.2093011438846588 loss\n","Epoch 2, Batch 102: 0.15286119282245636 loss\n","Epoch 2, Batch 103: 0.22480890154838562 loss\n","Epoch 2, Batch 104: 0.14747540652751923 loss\n","Epoch 2, Batch 105: 0.2618781328201294 loss\n","Epoch 2, Batch 106: 0.2352173924446106 loss\n","Epoch 2, Batch 107: 0.1592254936695099 loss\n","Epoch 2, Batch 108: 0.1415892243385315 loss\n","Epoch 2, Batch 109: 0.20231494307518005 loss\n","Epoch 2, Batch 110: 0.2268514484167099 loss\n","Epoch 2, Batch 111: 0.16149526834487915 loss\n","Epoch 2, Batch 112: 0.09257437288761139 loss\n","Epoch 2, Batch 113: 0.15887139737606049 loss\n","Epoch 2, Batch 114: 0.15464507043361664 loss\n","Epoch 2, Batch 115: 0.19504988193511963 loss\n","Epoch 2, Batch 116: 0.2959786057472229 loss\n","Epoch 2, Batch 117: 0.18805094063282013 loss\n","Epoch 2, Batch 118: 0.21089856326580048 loss\n","Epoch 2, Batch 119: 0.1293579339981079 loss\n","Epoch 2, Batch 120: 0.13988733291625977 loss\n","Epoch 2, Batch 121: 0.09515837579965591 loss\n","Epoch 2, Batch 122: 0.1406375616788864 loss\n","Epoch 2, Batch 123: 0.20519159734249115 loss\n","Epoch 2, Batch 124: 0.18687760829925537 loss\n","Epoch 2, Batch 125: 0.1919655203819275 loss\n","Epoch 2, Batch 126: 0.13704094290733337 loss\n","Epoch 2, Batch 127: 0.12201854586601257 loss\n","Epoch 2, Batch 128: 0.1705840528011322 loss\n","Epoch 2, Batch 129: 0.18931080400943756 loss\n","Epoch 2, Batch 130: 0.20357614755630493 loss\n","Epoch 2, Batch 131: 0.09338714182376862 loss\n","Epoch 2, Batch 132: 0.10091380029916763 loss\n","Epoch 2, Batch 133: 0.3103751540184021 loss\n","Epoch 2, Batch 134: 0.12581627070903778 loss\n","Epoch 2, Batch 135: 0.09437698870897293 loss\n","Epoch 2, Batch 136: 0.20590512454509735 loss\n","Epoch 2, Batch 137: 0.14775845408439636 loss\n","Epoch 2, Batch 138: 0.1973920464515686 loss\n","Epoch 2, Batch 139: 0.1500122994184494 loss\n","Epoch 2, Batch 140: 0.13706617057323456 loss\n","Epoch 2, Batch 141: 0.14620761573314667 loss\n","Epoch 2, Batch 142: 0.1335941106081009 loss\n","Epoch 2, Batch 143: 0.11891978234052658 loss\n","Epoch 2, Batch 144: 0.1114552766084671 loss\n","Epoch 2, Batch 145: 0.15357542037963867 loss\n","Epoch 2, Batch 146: 0.20881271362304688 loss\n","Epoch 2, Batch 147: 0.1926020085811615 loss\n","Epoch 2, Batch 148: 0.15350930392742157 loss\n","Epoch 2, Batch 149: 0.12340155988931656 loss\n","Epoch 2, Batch 150: 0.1487913876771927 loss\n","Epoch 2, Batch 151: 0.24420525133609772 loss\n","Epoch 2, Batch 152: 0.15217973291873932 loss\n","Epoch 2, Batch 153: 0.19039373099803925 loss\n","Epoch 2, Batch 154: 0.08144643902778625 loss\n","Epoch 2, Batch 155: 0.11088604480028152 loss\n","Epoch 2, Batch 156: 0.1563584953546524 loss\n","Epoch 2, Batch 157: 0.15439166128635406 loss\n","Epoch 2, Batch 158: 0.15578094124794006 loss\n","Epoch 2, Batch 159: 0.1583143174648285 loss\n","Epoch 2, Batch 160: 0.1674651801586151 loss\n","Epoch 2, Batch 161: 0.19274288415908813 loss\n","Epoch 2, Batch 162: 0.14585676789283752 loss\n","Epoch 2, Batch 163: 0.14654488861560822 loss\n","Epoch 2, Batch 164: 0.15589125454425812 loss\n","Epoch 2, Batch 165: 0.18019182980060577 loss\n","Epoch 2, Batch 166: 0.15793031454086304 loss\n","Epoch 2, Batch 167: 0.15643754601478577 loss\n","Epoch 2, Batch 168: 0.12518879771232605 loss\n","Epoch 2, Batch 169: 0.17183420062065125 loss\n","Epoch 2, Batch 170: 0.19821815192699432 loss\n","Epoch 2, Batch 171: 0.1257491111755371 loss\n","Epoch 2, Batch 172: 0.12305798381567001 loss\n","Epoch 2, Batch 173: 0.15433061122894287 loss\n","Epoch 2, Batch 174: 0.17751093208789825 loss\n","Epoch 2, Batch 175: 0.09443240612745285 loss\n","Epoch 2, Batch 176: 0.1824941188097 loss\n","Epoch 2, Batch 177: 0.1887330859899521 loss\n","Epoch 2, Batch 178: 0.13382746279239655 loss\n","Epoch 2, Batch 179: 0.12098758667707443 loss\n","Epoch 2, Batch 180: 0.15158803761005402 loss\n","Epoch 2, Batch 181: 0.1426832526922226 loss\n","Epoch 2, Batch 182: 0.1835838258266449 loss\n","Epoch 2, Batch 183: 0.21272794902324677 loss\n","Epoch 2, Batch 184: 0.15869423747062683 loss\n","Epoch 2, Batch 185: 0.10489977151155472 loss\n","Epoch 2, Batch 186: 0.12080657482147217 loss\n","Epoch 2, Batch 187: 0.08116567134857178 loss\n","Epoch 2, Batch 188: 0.19613611698150635 loss\n","Epoch 2, Batch 189: 0.19639801979064941 loss\n","Epoch 2, Batch 190: 0.13719727098941803 loss\n","Epoch 2, Batch 191: 0.1626477986574173 loss\n","Epoch 2, Batch 192: 0.16126582026481628 loss\n","Epoch 2, Batch 193: 0.09945937991142273 loss\n","Epoch 2, Batch 194: 0.07653200626373291 loss\n","Epoch 2, Batch 195: 0.17462080717086792 loss\n","Epoch 2, Batch 196: 0.05944891273975372 loss\n","Epoch 2, Batch 197: 0.11823932081460953 loss\n","Epoch 2, Batch 198: 0.13362275063991547 loss\n","Epoch 2, Batch 199: 0.1339416801929474 loss\n","Epoch 2, Batch 200: 0.16282133758068085 loss\n","Epoch 2, Batch 201: 0.18258516490459442 loss\n","Epoch 2, Batch 202: 0.14024683833122253 loss\n","Epoch 2, Batch 203: 0.14413200318813324 loss\n","Epoch 2, Batch 204: 0.09536965936422348 loss\n","Epoch 2, Batch 205: 0.23370395600795746 loss\n","Epoch 2, Batch 206: 0.1303611397743225 loss\n","Epoch 2, Batch 207: 0.10130152106285095 loss\n","Epoch 2, Batch 208: 0.07960487902164459 loss\n","Epoch 2, Batch 209: 0.1556296944618225 loss\n","Epoch 2, Batch 210: 0.1812148094177246 loss\n","Epoch 2, Batch 211: 0.14911949634552002 loss\n","Epoch 2, Batch 212: 0.24617081880569458 loss\n","Epoch 2, Batch 213: 0.07994159311056137 loss\n","Epoch 2, Batch 214: 0.20488925278186798 loss\n","Epoch 2, Batch 215: 0.10049087554216385 loss\n","Epoch 2, Batch 216: 0.1490505188703537 loss\n","Epoch 2, Batch 217: 0.11753411591053009 loss\n","Epoch 2, Batch 218: 0.10115568339824677 loss\n","Epoch 2, Batch 219: 0.15261828899383545 loss\n","Epoch 2, Batch 220: 0.08651313185691833 loss\n","Epoch 2, Batch 221: 0.18305201828479767 loss\n","Epoch 2, Batch 222: 0.10068758577108383 loss\n","Epoch 2, Batch 223: 0.14827312529087067 loss\n","Epoch 2, Batch 224: 0.2135702222585678 loss\n","Epoch 2, Batch 225: 0.10207549482584 loss\n","Epoch 2, Batch 226: 0.16993732750415802 loss\n","Epoch 2, Batch 227: 0.13203836977481842 loss\n","Epoch 2, Batch 228: 0.14538083970546722 loss\n","Epoch 2, Batch 229: 0.13533291220664978 loss\n","Epoch 2, Batch 230: 0.1734524369239807 loss\n","Epoch 2, Batch 231: 0.12480079382658005 loss\n","Epoch 2, Batch 232: 0.12369292229413986 loss\n","Epoch 2, Batch 233: 0.1436470001935959 loss\n","Epoch 2, Batch 234: 0.12369704991579056 loss\n","Epoch 2, Batch 235: 0.11107810586690903 loss\n","Epoch 2, Batch 236: 0.1352992057800293 loss\n","Epoch 2, Batch 237: 0.14965948462486267 loss\n","Epoch 2, Batch 238: 0.10699386894702911 loss\n","Epoch 2, Batch 239: 0.1558232307434082 loss\n","Epoch 2, Batch 240: 0.14255709946155548 loss\n","Epoch 2, Batch 241: 0.17029225826263428 loss\n","Epoch 2, Batch 242: 0.12917672097682953 loss\n","Epoch 2, Batch 243: 0.16901937127113342 loss\n","Epoch 2, Batch 244: 0.19206959009170532 loss\n","Epoch 2, Batch 245: 0.10483311116695404 loss\n","Epoch 2, Batch 246: 0.10039025545120239 loss\n","Epoch 2, Batch 247: 0.14520902931690216 loss\n","Epoch 2, Batch 248: 0.10859168320894241 loss\n","Epoch 2, Batch 249: 0.11145634949207306 loss\n","Epoch 2, Batch 250: 0.21397772431373596 loss\n","Epoch 2, Batch 251: 0.14543798565864563 loss\n","Epoch 2, Batch 252: 0.17308181524276733 loss\n","Epoch 2, Batch 253: 0.14426273107528687 loss\n","Epoch 2, Batch 254: 0.1067812442779541 loss\n","Epoch 2, Batch 255: 0.1705988347530365 loss\n","Epoch 2, Batch 256: 0.12817251682281494 loss\n","Epoch 2, Batch 257: 0.1266174018383026 loss\n","Epoch 2, Batch 258: 0.1214640811085701 loss\n","Epoch 2, Batch 259: 0.12130898982286453 loss\n","Epoch 2, Batch 260: 0.15628430247306824 loss\n","Epoch 2, Batch 261: 0.12057413905858994 loss\n","Epoch 2, Batch 262: 0.10715951770544052 loss\n","Epoch 2, Batch 263: 0.12651249766349792 loss\n","Epoch 2, Batch 264: 0.08357342332601547 loss\n","Epoch 2, Batch 265: 0.10286109149456024 loss\n","Epoch 2, Batch 266: 0.08879390358924866 loss\n","Epoch 2, Batch 267: 0.16421444714069366 loss\n","Epoch 2, Batch 268: 0.4959270656108856 loss\n","Epoch 2, Batch 269: 0.11414840817451477 loss\n","Epoch 2, Batch 270: 0.1129581481218338 loss\n","Epoch 2, Batch 271: 0.16025178134441376 loss\n","Epoch 2, Batch 272: 0.14932186901569366 loss\n","Epoch 2, Batch 273: 0.1764613538980484 loss\n","Epoch 2, Batch 274: 0.16106392443180084 loss\n","Epoch 2, Batch 275: 0.13002820312976837 loss\n","Epoch 2, Batch 276: 0.1571905016899109 loss\n","Epoch 2, Batch 277: 0.24012473225593567 loss\n","Epoch 2, Batch 278: 0.10084807127714157 loss\n","Epoch 2, Batch 279: 0.16475661098957062 loss\n","Epoch 2, Batch 280: 0.1620391309261322 loss\n","Epoch 2, Batch 281: 0.1611248403787613 loss\n","Epoch 2, Batch 282: 0.2546079754829407 loss\n","Epoch 2, Batch 283: 0.18033826351165771 loss\n","Epoch 2, Batch 284: 0.16476188600063324 loss\n","Epoch 2, Batch 285: 0.09704294800758362 loss\n","Epoch 2, Batch 286: 0.144429549574852 loss\n","Epoch 2, Batch 287: 0.1557377129793167 loss\n","Epoch 2, Batch 288: 0.20447354018688202 loss\n","Epoch 2, Batch 289: 0.11166206747293472 loss\n","Epoch 2, Batch 290: 0.1562567949295044 loss\n","Epoch 2, Batch 291: 0.1175452470779419 loss\n","Epoch 2, Batch 292: 0.16484375298023224 loss\n","Epoch 2, Batch 293: 0.12809661030769348 loss\n","Epoch 2, Batch 294: 0.13255128264427185 loss\n","Epoch 2, Batch 295: 0.14477168023586273 loss\n","Epoch 2, Batch 296: 0.14881162345409393 loss\n","Epoch 2, Batch 297: 0.20013855397701263 loss\n","Epoch 2, Batch 298: 0.17492398619651794 loss\n","Epoch 2, Batch 299: 0.13266196846961975 loss\n","Epoch 2, Batch 300: 0.10902957618236542 loss\n","Epoch 2, Batch 301: 0.17400068044662476 loss\n","Epoch 2, Batch 302: 0.1809617429971695 loss\n","Epoch 2, Batch 303: 0.1410958170890808 loss\n","Epoch 2, Batch 304: 0.15362077951431274 loss\n","Epoch 2, Batch 305: 0.12773504853248596 loss\n","Epoch 2, Batch 306: 0.1978592872619629 loss\n","Epoch 2, Batch 307: 0.13371019065380096 loss\n","Epoch 2, Batch 308: 0.17323940992355347 loss\n","Epoch 2, Batch 309: 0.08797820657491684 loss\n","Epoch 2, Batch 310: 0.21011927723884583 loss\n","Epoch 2, Batch 311: 0.13011132180690765 loss\n","Epoch 2, Batch 312: 0.09998730570077896 loss\n","Epoch 2, Batch 313: 0.11187777668237686 loss\n","Epoch 2, Batch 314: 0.11941838264465332 loss\n","Epoch 2, Batch 315: 0.15796689689159393 loss\n","Epoch 2, Batch 316: 0.14376892149448395 loss\n","Epoch 2, Batch 317: 0.1551506668329239 loss\n","Epoch 2, Batch 318: 0.14876788854599 loss\n","Epoch 2, Batch 319: 0.14753508567810059 loss\n","Epoch 2, Batch 320: 0.154155895113945 loss\n","Epoch 2, Batch 321: 0.1384693831205368 loss\n","Epoch 2, Batch 322: 0.08421934396028519 loss\n","Epoch 2, Batch 323: 0.16504010558128357 loss\n","Epoch 2, Batch 324: 0.21514204144477844 loss\n","Epoch 2, Batch 325: 0.18052594363689423 loss\n","Epoch 2, Batch 326: 0.1637226641178131 loss\n","Epoch 2, Batch 327: 0.14497137069702148 loss\n","Epoch 2, Batch 328: 0.1337164044380188 loss\n","Epoch 2, Batch 329: 0.18243949115276337 loss\n","Epoch 2, Batch 330: 0.10478193312883377 loss\n","Epoch 2, Batch 331: 0.1346817910671234 loss\n","Epoch 2, Batch 332: 0.21371974050998688 loss\n","Epoch 2, Batch 333: 0.13933630287647247 loss\n","Epoch 2, Batch 334: 0.11537615954875946 loss\n","Epoch 2, Batch 335: 0.07258622348308563 loss\n","Epoch 2, Batch 336: 0.16688355803489685 loss\n","Epoch 2, Batch 337: 0.08966946601867676 loss\n","Epoch 2, Batch 338: 0.14977705478668213 loss\n","Epoch 2, Batch 339: 0.17145319283008575 loss\n","Epoch 2, Batch 340: 0.18949009478092194 loss\n","Epoch 2, Batch 341: 0.1728219836950302 loss\n","Epoch 2, Batch 342: 0.1271256059408188 loss\n","Epoch 2, Batch 343: 0.1598983258008957 loss\n","Epoch 2, Batch 344: 0.14165225625038147 loss\n","Epoch 2, Batch 345: 0.1148366704583168 loss\n","Epoch 2, Batch 346: 0.15806695818901062 loss\n","Epoch 2, Batch 347: 0.09413982927799225 loss\n","Epoch 2, Batch 348: 0.1360328197479248 loss\n","Epoch 2, Batch 349: 0.2101680487394333 loss\n","Epoch 2, Batch 350: 0.1644132286310196 loss\n","Epoch 2, Batch 351: 0.08897901326417923 loss\n","Epoch 2, Batch 352: 0.2169729769229889 loss\n","Epoch 2, Batch 353: 0.2235938161611557 loss\n","Epoch 2, Batch 354: 0.1739189177751541 loss\n","Epoch 2, Batch 355: 0.1674460619688034 loss\n","Epoch 2, Batch 356: 0.1622360795736313 loss\n","Epoch 2, Batch 357: 0.1376587301492691 loss\n","Epoch 2, Batch 358: 0.1106991320848465 loss\n","Epoch 2, Batch 359: 0.08063548058271408 loss\n","Epoch 2, Batch 360: 0.1107201874256134 loss\n","Epoch 2, Batch 361: 0.11120805889368057 loss\n","Epoch 2, Batch 362: 0.1724451333284378 loss\n","Epoch 2, Batch 363: 0.15007634460926056 loss\n","Epoch 2, Batch 364: 0.24437153339385986 loss\n","Epoch 2, Batch 365: 0.14262312650680542 loss\n","Epoch 2, Batch 366: 0.12822967767715454 loss\n","Epoch 2, Batch 367: 0.13245825469493866 loss\n","Epoch 2, Batch 368: 0.13565215468406677 loss\n","Epoch 2, Batch 369: 0.19971175491809845 loss\n","Epoch 2, Batch 370: 0.1441330909729004 loss\n","Epoch 2, Batch 371: 0.1702609658241272 loss\n","Epoch 2, Batch 372: 0.12207254767417908 loss\n","Epoch 2, Batch 373: 0.07859120517969131 loss\n","Epoch 2, Batch 374: 0.20317138731479645 loss\n","Epoch 2, Batch 375: 0.12639038264751434 loss\n","Epoch 2, Batch 376: 0.0712936595082283 loss\n","Epoch 2, Batch 377: 0.135742649435997 loss\n","Epoch 2, Batch 378: 0.1143811047077179 loss\n","Epoch 2, Batch 379: 0.15807174146175385 loss\n","Epoch 2, Batch 380: 0.11726899445056915 loss\n","Epoch 2, Batch 381: 0.11220825463533401 loss\n","Epoch 2, Batch 382: 0.13995148241519928 loss\n","Epoch 2, Batch 383: 0.09667305648326874 loss\n","Epoch 2, Batch 384: 0.11917680501937866 loss\n","Epoch 2, Batch 385: 0.1400858610868454 loss\n","Epoch 2, Batch 386: 0.1426875740289688 loss\n","Epoch 2, Batch 387: 0.17760145664215088 loss\n","Epoch 2, Batch 388: 0.143702432513237 loss\n","Epoch 2, Batch 389: 0.10750556737184525 loss\n","Epoch 2, Batch 390: 0.21690817177295685 loss\n","Epoch 2, Batch 391: 0.1515502631664276 loss\n","Epoch 2, Batch 392: 0.06045526638627052 loss\n","Epoch 2, Batch 393: 0.0890687108039856 loss\n","Epoch 2, Batch 394: 0.14781413972377777 loss\n","Epoch 2, Batch 395: 0.06981997191905975 loss\n","Epoch 2, Batch 396: 0.12307260930538177 loss\n","Epoch 2, Batch 397: 0.16442978382110596 loss\n","Epoch 2, Batch 398: 0.11496499180793762 loss\n","Epoch 2, Batch 399: 0.16608037054538727 loss\n","Epoch 2, Batch 400: 0.12660782039165497 loss\n","Epoch 2, Batch 401: 0.131230428814888 loss\n","Epoch 2, Batch 402: 0.08314234018325806 loss\n","Epoch 2, Batch 403: 0.12304355204105377 loss\n","Epoch 2, Batch 404: 0.1873839944601059 loss\n","Epoch 2, Batch 405: 0.17918597161769867 loss\n","Epoch 2, Batch 406: 0.18123242259025574 loss\n","Epoch 2, Batch 407: 0.1548553705215454 loss\n","Epoch 2, Batch 408: 0.09987348318099976 loss\n","Epoch 2, Batch 409: 0.2022748440504074 loss\n","Epoch 2, Batch 410: 0.1250363439321518 loss\n","Epoch 2, Batch 411: 0.0935172289609909 loss\n","Epoch 2, Batch 412: 0.18003340065479279 loss\n","Epoch 2, Batch 413: 0.15595322847366333 loss\n","Epoch 2, Batch 414: 0.09704816341400146 loss\n","Epoch 2, Batch 415: 0.1277530938386917 loss\n","Epoch 2, Batch 416: 0.12032028287649155 loss\n","Epoch 2, Batch 417: 0.23964866995811462 loss\n","Epoch 2, Batch 418: 0.11424285918474197 loss\n","Epoch 2, Batch 419: 0.1682439148426056 loss\n","Epoch 2, Batch 420: 0.12250611931085587 loss\n","Epoch 2, Batch 421: 0.1418641060590744 loss\n","Epoch 2, Batch 422: 0.1059994027018547 loss\n","Epoch 2, Batch 423: 0.13038095831871033 loss\n","Epoch 2, Batch 424: 0.11661989241838455 loss\n","Epoch 2, Batch 425: 0.14705336093902588 loss\n","Epoch 2, Batch 426: 0.12619806826114655 loss\n","Epoch 2, Batch 427: 0.13623148202896118 loss\n","Epoch 2, Batch 428: 0.16232070326805115 loss\n","Epoch 2, Batch 429: 0.153034046292305 loss\n","Epoch 2, Batch 430: 0.13314589858055115 loss\n","Epoch 2, Batch 431: 0.12909945845603943 loss\n","Epoch 2, Batch 432: 0.1663689911365509 loss\n","Epoch 2, Batch 433: 0.12162593752145767 loss\n","Epoch 2, Batch 434: 0.13016608357429504 loss\n","Epoch 2, Batch 435: 0.09885255992412567 loss\n","Epoch 2, Batch 436: 0.14164894819259644 loss\n","Epoch 2, Batch 437: 0.09376701712608337 loss\n","Epoch 2, Batch 438: 0.18794746696949005 loss\n","Epoch 2, Batch 439: 0.13130776584148407 loss\n","Epoch 2, Batch 440: 0.11938055604696274 loss\n","Epoch 2, Batch 441: 0.17500562965869904 loss\n","Epoch 2, Batch 442: 0.13010211288928986 loss\n","Epoch 2, Batch 443: 0.1125604510307312 loss\n","Epoch 2, Batch 444: 0.07587125897407532 loss\n","Epoch 2, Batch 445: 0.14730368554592133 loss\n","Epoch 2, Batch 446: 0.13329261541366577 loss\n","Epoch 2, Batch 447: 0.08630432933568954 loss\n","Epoch 2, Batch 448: 0.08544614911079407 loss\n","Epoch 2, Batch 449: 0.11899536103010178 loss\n","Epoch 2, Batch 450: 0.1012999638915062 loss\n","Epoch 2, Batch 451: 0.18085505068302155 loss\n","Epoch 2, Batch 452: 0.14584454894065857 loss\n","Epoch 2, Batch 453: 0.22796162962913513 loss\n","Epoch 2, Batch 454: 0.168263241648674 loss\n","Epoch 2, Batch 455: 0.1767350435256958 loss\n","Epoch 2, Batch 456: 0.09528777003288269 loss\n","Epoch 2, Batch 457: 0.12639664113521576 loss\n","Epoch 2, Batch 458: 0.13163027167320251 loss\n","Epoch 2, Batch 459: 0.05810932070016861 loss\n","Epoch 2, Batch 460: 0.13621298968791962 loss\n","Epoch 2, Batch 461: 0.1472553163766861 loss\n","Epoch 2, Batch 462: 0.10734713822603226 loss\n","Epoch 2, Batch 463: 0.13367398083209991 loss\n","Epoch 2, Batch 464: 0.17441003024578094 loss\n","Epoch 2, Batch 465: 0.16539928317070007 loss\n","Epoch 2, Batch 466: 0.13750359416007996 loss\n","Epoch 2, Batch 467: 0.18636362254619598 loss\n","Epoch 2, Batch 468: 0.2246568202972412 loss\n","Epoch 2, Batch 469: 0.16008172929286957 loss\n","Epoch 2, Batch 470: 0.16050997376441956 loss\n","Epoch 2, Batch 471: 0.1812446415424347 loss\n","Epoch 2, Batch 472: 0.11422125995159149 loss\n","Epoch 2, Batch 473: 0.10297942906618118 loss\n","Epoch 2, Batch 474: 0.15464816987514496 loss\n","Epoch 2, Batch 475: 0.12119018286466599 loss\n","Epoch 2, Batch 476: 0.12142843008041382 loss\n","Epoch 2, Batch 477: 0.14670942723751068 loss\n","Epoch 2, Batch 478: 0.18760384619235992 loss\n","Epoch 2, Batch 479: 0.06918082386255264 loss\n","Epoch 2, Batch 480: 0.12072529643774033 loss\n","Epoch 2, Batch 481: 0.2094552218914032 loss\n","Epoch 2, Batch 482: 0.1865597516298294 loss\n","Epoch 2, Batch 483: 0.13347744941711426 loss\n","Epoch 2, Batch 484: 0.1499377340078354 loss\n","Epoch 2, Batch 485: 0.1101113110780716 loss\n","Epoch 2, Batch 486: 0.14020618796348572 loss\n","Epoch 2, Batch 487: 0.11236410588026047 loss\n","Epoch 2, Batch 488: 0.12583298981189728 loss\n","Epoch 2, Batch 489: 0.1787804216146469 loss\n","Epoch 2, Batch 490: 0.13112397491931915 loss\n","Epoch 2, Batch 491: 0.17171792685985565 loss\n","Epoch 2, Batch 492: 0.07851812988519669 loss\n","Epoch 2, Batch 493: 0.12233882397413254 loss\n","Epoch 2, Batch 494: 0.18947888910770416 loss\n","Epoch 2, Batch 495: 0.19775237143039703 loss\n","Epoch 2, Batch 496: 0.1385296881198883 loss\n","Epoch 2, Batch 497: 0.16115964949131012 loss\n","Epoch 2, Batch 498: 0.20274077355861664 loss\n","Epoch 2, Batch 499: 0.14275521039962769 loss\n","Epoch 2, Batch 500: 0.095689557492733 loss\n","Epoch 2, Batch 501: 0.16328828036785126 loss\n","Epoch 2, Batch 502: 0.19175943732261658 loss\n","Epoch 2, Batch 503: 0.15701863169670105 loss\n","Epoch 2, Batch 504: 0.1195540726184845 loss\n","Epoch 2, Batch 505: 0.14508245885372162 loss\n","Epoch 2, Batch 506: 0.12654586136341095 loss\n","Epoch 2, Batch 507: 0.08704032003879547 loss\n","Epoch 2, Batch 508: 0.09982097893953323 loss\n","Epoch 2, Batch 509: 0.12231796234846115 loss\n","Epoch 2, Batch 510: 0.1900082230567932 loss\n","Epoch 2, Batch 511: 0.1475704461336136 loss\n","Epoch 2, Batch 512: 0.12408889085054398 loss\n","Epoch 2, Batch 513: 0.1696699857711792 loss\n","Epoch 2, Batch 514: 0.1485958993434906 loss\n","Epoch 2, Batch 515: 0.09046865999698639 loss\n","Epoch 2, Batch 516: 0.06469443440437317 loss\n","Epoch 2, Batch 517: 0.14917941391468048 loss\n","Epoch 2, Batch 518: 0.30745482444763184 loss\n","Epoch 2, Batch 519: 0.17773115634918213 loss\n","Epoch 2, Batch 520: 0.12891513109207153 loss\n","Epoch 2, Batch 521: 0.15918061137199402 loss\n","Epoch 2, Batch 522: 0.11914876103401184 loss\n","Epoch 2, Batch 523: 0.11658822745084763 loss\n","Epoch 2, Batch 524: 0.10612162947654724 loss\n","Epoch 2, Batch 525: 0.09687525033950806 loss\n","Epoch 2, Batch 526: 0.1341550350189209 loss\n","Epoch 2, Batch 527: 0.10559412837028503 loss\n","Epoch 2, Batch 528: 0.1405652016401291 loss\n","Epoch 2, Batch 529: 0.20507650077342987 loss\n","Epoch 2, Batch 530: 0.1492079794406891 loss\n","Epoch 2, Batch 531: 0.14388427138328552 loss\n","Epoch 2, Batch 532: 0.15112945437431335 loss\n","Epoch 2, Batch 533: 0.13273611664772034 loss\n","Epoch 2, Batch 534: 0.134562686085701 loss\n","Epoch 2, Batch 535: 0.09978693723678589 loss\n","Epoch 2, Batch 536: 0.11816003918647766 loss\n","Epoch 2, Batch 537: 0.12997935712337494 loss\n","Epoch 2, Batch 538: 0.1688193380832672 loss\n","Epoch 2, Batch 539: 0.16102315485477448 loss\n","Epoch 2, Batch 540: 0.10320856422185898 loss\n","Epoch 2, Batch 541: 0.13121803104877472 loss\n","Epoch 2, Batch 542: 0.09087070822715759 loss\n","Epoch 2, Batch 543: 0.1487526297569275 loss\n","Epoch 2, Batch 544: 0.1146058589220047 loss\n","Epoch 2, Batch 545: 0.16119711101055145 loss\n","Epoch 2, Batch 546: 0.188356414437294 loss\n","Epoch 2, Batch 547: 0.11707233637571335 loss\n","Epoch 2, Batch 548: 0.11208146810531616 loss\n","Epoch 2, Batch 549: 0.15062160789966583 loss\n","Epoch 2, Batch 550: 0.12660957872867584 loss\n","Epoch 2, Batch 551: 0.14653280377388 loss\n","Epoch 2, Batch 552: 0.126324862241745 loss\n","Epoch 2, Batch 553: 0.23899751901626587 loss\n","Epoch 2, Batch 554: 0.13725247979164124 loss\n","Epoch 2, Batch 555: 0.06559261679649353 loss\n","Epoch 2, Batch 556: 0.1480940729379654 loss\n","Epoch 2, Batch 557: 0.0933014377951622 loss\n","Epoch 2, Batch 558: 0.20229019224643707 loss\n","Epoch 2, Batch 559: 0.2031126171350479 loss\n","Epoch 2, Batch 560: 0.15123210847377777 loss\n","Epoch 2, Batch 561: 0.11740120500326157 loss\n","Epoch 2, Batch 562: 0.14624503254890442 loss\n","Epoch 2, Batch 563: 0.13521671295166016 loss\n","Epoch 2, Batch 564: 0.09866799414157867 loss\n","Epoch 2, Batch 565: 0.16783565282821655 loss\n","Epoch 2, Batch 566: 0.20883232355117798 loss\n","Epoch 2, Batch 567: 0.10022743791341782 loss\n","Epoch 2, Batch 568: 0.16644245386123657 loss\n","Epoch 2, Batch 569: 0.16672910749912262 loss\n","Epoch 2, Batch 570: 0.11567211151123047 loss\n","Epoch 2, Batch 571: 0.15660721063613892 loss\n","Epoch 2, Batch 572: 0.12979917228221893 loss\n","Epoch 2, Batch 573: 0.15169349312782288 loss\n","Epoch 2, Batch 574: 0.15162162482738495 loss\n","Epoch 2, Batch 575: 0.1301938146352768 loss\n","Epoch 2, Batch 576: 0.10975510627031326 loss\n","Epoch 2, Batch 577: 0.20238585770130157 loss\n","Epoch 2, Batch 578: 0.1902916133403778 loss\n","Epoch 2, Batch 579: 0.16704389452934265 loss\n","Epoch 2, Batch 580: 0.14475394785404205 loss\n","Epoch 2, Batch 581: 0.11109215766191483 loss\n","Epoch 2, Batch 582: 0.07456295937299728 loss\n","Epoch 2, Batch 583: 0.12822271883487701 loss\n","Epoch 2, Batch 584: 0.13194222748279572 loss\n","Epoch 2, Batch 585: 0.20075006783008575 loss\n","Epoch 2, Batch 586: 0.14204706251621246 loss\n","Epoch 2, Batch 587: 0.09037668257951736 loss\n","Epoch 2, Batch 588: 0.1417662799358368 loss\n","Epoch 2, Batch 589: 0.1406073272228241 loss\n","Epoch 2, Batch 590: 0.1714644581079483 loss\n","Epoch 2, Batch 591: 0.11085640639066696 loss\n","Epoch 2, Batch 592: 0.13150368630886078 loss\n","Epoch 2, Batch 593: 0.1439899057149887 loss\n","Epoch 2, Batch 594: 0.18410079181194305 loss\n","Epoch 2, Batch 595: 0.1424616575241089 loss\n","Epoch 2, Batch 596: 0.11513184756040573 loss\n","Epoch 2, Batch 597: 0.15339531004428864 loss\n","Epoch 2, Batch 598: 0.14884482324123383 loss\n","Epoch 2, Batch 599: 0.08321792632341385 loss\n","Epoch 2, Batch 600: 0.16779360175132751 loss\n","Epoch 2, Batch 601: 0.16871468722820282 loss\n","Epoch 2, Batch 602: 0.17180384695529938 loss\n","Epoch 2, Batch 603: 0.15863102674484253 loss\n","Epoch 2, Batch 604: 0.1300315111875534 loss\n","Epoch 2, Batch 605: 0.07968080043792725 loss\n","Epoch 2, Batch 606: 0.12398817390203476 loss\n","Epoch 2, Batch 607: 0.07580551505088806 loss\n","Epoch 2, Batch 608: 0.09555497020483017 loss\n","Epoch 2, Batch 609: 0.10311990976333618 loss\n","Epoch 2, Batch 610: 0.17692683637142181 loss\n","Epoch 2, Batch 611: 0.1461271494626999 loss\n","Epoch 2, Batch 612: 0.16647550463676453 loss\n","Epoch 2, Batch 613: 0.18068650364875793 loss\n","Epoch 2, Batch 614: 0.19239625334739685 loss\n","Epoch 2, Batch 615: 0.21115541458129883 loss\n","Epoch 2, Batch 616: 0.1206609383225441 loss\n","Epoch 2, Batch 617: 0.12537065148353577 loss\n","Epoch 2, Batch 618: 0.13932983577251434 loss\n","Epoch 2, Batch 619: 0.11528875678777695 loss\n","Epoch 2, Batch 620: 0.1124674379825592 loss\n","Epoch 2, Batch 621: 0.09688591212034225 loss\n","Epoch 2, Batch 622: 0.13306429982185364 loss\n","Epoch 2, Batch 623: 0.14593224227428436 loss\n","Epoch 2, Batch 624: 0.16954977810382843 loss\n","Epoch 2, Batch 625: 0.07182507961988449 loss\n","Epoch 2, Batch 626: 0.07174614071846008 loss\n","Epoch 2, Batch 627: 0.15178175270557404 loss\n","Epoch 2, Batch 628: 0.15689420700073242 loss\n","Epoch 2, Batch 629: 0.14823438227176666 loss\n","Epoch 2, Batch 630: 0.0990346297621727 loss\n","Epoch 2, Batch 631: 0.21473674476146698 loss\n","Epoch 2, Batch 632: 0.09028904139995575 loss\n","Epoch 2, Batch 633: 0.07634850591421127 loss\n","Epoch 2, Batch 634: 0.18614451587200165 loss\n","Epoch 2, Batch 635: 0.1577490121126175 loss\n","Epoch 2, Batch 636: 0.1781972497701645 loss\n","Epoch 2, Batch 637: 0.1738695502281189 loss\n","Epoch 2, Batch 638: 0.11835723370313644 loss\n","Predicting batch 1\n","Predicting batch 2\n","Predicting batch 3\n","Predicting batch 4\n","Predicting batch 5\n","Predicting batch 6\n","Predicting batch 7\n","Predicting batch 8\n","Predicting batch 9\n","Predicting batch 10\n","Predicting batch 11\n","Predicting batch 12\n","Predicting batch 13\n","Predicting batch 14\n","Predicting batch 15\n","Predicting batch 16\n","Predicting batch 17\n","Predicting batch 18\n","Predicting batch 19\n","Predicting batch 20\n","Predicting batch 21\n","Predicting batch 22\n","Predicting batch 23\n","Predicting batch 24\n","Predicting batch 25\n","Predicting batch 26\n","Predicting batch 27\n","Predicting batch 28\n","Predicting batch 29\n","Predicting batch 30\n","Predicting batch 31\n","Predicting batch 32\n","Predicting batch 33\n","Predicting batch 34\n","Predicting batch 35\n","Predicting batch 36\n","Predicting batch 37\n","Predicting batch 38\n","Predicting batch 39\n","Predicting batch 40\n","Predicting batch 41\n","Predicting batch 42\n","Predicting batch 43\n","Predicting batch 44\n","Predicting batch 45\n","Predicting batch 46\n","Predicting batch 47\n","Predicting batch 48\n","Predicting batch 49\n","Predicting batch 50\n","Predicting batch 51\n","Predicting batch 52\n","Predicting batch 53\n","Predicting batch 54\n","Predicting batch 55\n","Predicting batch 56\n","Predicting batch 57\n","Predicting batch 58\n","Predicting batch 59\n","Predicting batch 60\n","Predicting batch 61\n","Predicting batch 62\n","Predicting batch 63\n","Predicting batch 64\n","Predicting batch 65\n","Predicting batch 66\n","Predicting batch 67\n","Predicting batch 68\n","Predicting batch 69\n","Predicting batch 70\n","Predicting batch 71\n","Predicting batch 72\n","Predicting batch 73\n","Predicting batch 74\n","Predicting batch 75\n","Predicting batch 76\n","Predicting batch 77\n","Predicting batch 78\n","Predicting batch 79\n","Predicting batch 80\n","Predicting batch 81\n","Predicting batch 82\n","Predicting batch 83\n","Predicting batch 84\n","Predicting batch 85\n","Predicting batch 86\n","Predicting batch 87\n","Predicting batch 88\n","Predicting batch 89\n","Predicting batch 90\n","Predicting batch 91\n","Predicting batch 92\n","Predicting batch 93\n","Predicting batch 94\n","Predicting batch 95\n","Predicting batch 96\n","Predicting batch 97\n","Predicting batch 98\n","Predicting batch 99\n","Predicting batch 100\n","Predicting batch 101\n","Predicting batch 102\n","Predicting batch 103\n","Predicting batch 104\n","Predicting batch 105\n","Predicting batch 106\n","Predicting batch 107\n","Predicting batch 108\n","Predicting batch 109\n","Predicting batch 110\n","Predicting batch 111\n","Predicting batch 112\n","Predicting batch 113\n","Predicting batch 114\n","Predicting batch 115\n","Predicting batch 116\n","Predicting batch 117\n","Predicting batch 118\n","Predicting batch 119\n","Predicting batch 120\n","Predicting batch 121\n","Predicting batch 122\n","Predicting batch 123\n","Predicting batch 124\n","Predicting batch 125\n","Predicting batch 126\n","Predicting batch 127\n","Predicting batch 128\n","Predicting batch 129\n","Predicting batch 130\n","Predicting batch 131\n","Predicting batch 132\n","Predicting batch 133\n","Predicting batch 134\n","Predicting batch 135\n","Predicting batch 136\n","Predicting batch 137\n","Predicting batch 138\n","Predicting batch 139\n","Predicting batch 140\n","Predicting batch 141\n","Predicting batch 142\n","Predicting batch 143\n","Predicting batch 144\n","Predicting batch 145\n","Predicting batch 146\n","\n","---- Epoch 2 ----\n","Accuracy: 0.004306632213608958\n","\n","\n","Saving model to /content/drive/MyDrive/PPL/trocr/model...\n"]}]},{"cell_type":"code","source":["# load images\n","image_names = [\"/content/drive/MyDrive/PPL/trocr/data/20160504_0112_25849_2_tg_7_5.png\",\"/content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 115458.png\", \"/content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 122655.png\"]\n","images = [Image.open(img_name) for img_name in image_names]\n","# directly predict on Pillow Images or on file names\n","model = TrocrPredictor(use_local_model=True)\n","predictions = model.predict_images(images)\n","predictions = list(predictions)\n","# predictions = model.predict_for_image_paths(image_names)\n","# print results\n","for i, file_name in enumerate(image_names):\n","    print(f'Prediction for {file_name}:\\nPredict: {predictions[i][0]}\\nConfidence Scores: {predictions[i][1]}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmGFFlT_IJ10","executionInfo":{"status":"ok","timestamp":1719887856132,"user_tz":-420,"elapsed":11405,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"ba810d68-2614-4154-afd6-06be566fa9f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded local model from /content/drive/MyDrive/PPL/trocr/model\n","Using device cuda.\n","Predicting batch 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Prediction for /content/drive/MyDrive/PPL/trocr/data/20160504_0112_25849_2_tg_7_5.png:\n","Predict: nguy hiểm vì cua giất\n","Confidence Scores: 0.9164368510246277\n","\n","Prediction for /content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 115458.png:\n","Predict: LLICENSEFER OF MCDONALD \"S\n","Confidence Scores: 0.3728163540363312\n","\n","Prediction for /content/drive/MyDrive/PPL/trocr/data/Screenshot 2024-06-29 122655.png:\n","Predict: How You Benefit ệ Spreads\n","Confidence Scores: 0.6101169586181641\n","\n"]}]},{"cell_type":"markdown","source":["# Day 2"],"metadata":{"id":"v3BJH_SfaqUM"}},{"cell_type":"code","source":["# load images\n","image_names = os.listdir(\"/content/drive/MyDrive/PPL/trocr/data\")\n","images = [Image.open(os.path.join(\"/content/drive/MyDrive/PPL/trocr/data\",img_name)) for img_name in image_names]\n","# directly predict on Pillow Images or on file names\n","model = TrocrPredictor(use_local_model=True)\n","predictions = model.predict_images(images)\n","predictions = list(predictions)\n","\n","# print results\n","for i, file_name in enumerate(image_names):\n","    print(f'Prediction for {file_name}:\\nPredict: {predictions[i][0]}\\nConfidence Scores: {predictions[i][1]}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":596,"referenced_widgets":["488555cd3d26401ab65c320e2b7014ae","8df2181811224380a99754353bb907a1","f6fe572efe664eed8ee3d161b01379c1","179f3aae5c29446fa1116ae777594572","4cb219be48044d43ad4acb51b3cd913d","bee0789a6ea84465afe2d09a78106f08","cfd93b6773094b75af797cacd081070e","6a2c8e8bdd92438db9380d610244df1c","bcf0886edb2a4cf4ba77e5e909cd292c","19d9688b2e2a435f9627523554da8bbd","52f81de3c9b14f37baaafe7335223827","2e173f2e8451407cb347689e0d59c4e3","b87f88ac7965456aaa93f51ad74f8431","194e38b050744a7584d5bb0e555c3ba6","26d8265afa7c4311944574228e7fc268","888423c3eb8c4f1ab10eff7eb561259a","f77986a4e47841da81bd0e533be3c0e1","12b7f91dddd64fbcbd3f8e7bcacb06d8","42218c281eb2422a85736f0f306a80bc","16fef1a9ba5942158c362c780152470a","111699e5be0a4e8a97d851d81ce88448","4c9d57f55214478d948f3045be3c8906","8ff9c6c6f5a4498da6ef6036ca1501a7","82a45c556056415dbdaf4e3668d57b2b","a45fc53d041242ef875544fcf3f6e9b2","c5550874936448b2afecab4fba1bf2e7","9e1b8e56d32548a1b446006437f1607e","95d3fa3cad6543049aa941392f5f04e9","0c7bcb5bb7714b7fa9536cf3bedc56a6","2a79869bfa0c48f68a7231be125125fb","4fc3229fc4eb4d3d9d580aef90197ff9","795b51b90d3d4cb19c916893f581efab","47dc047f0581435ea12f5b6b23eb7b94","9464d3e9033a4945a21d2b8d7069c686","ff1371a623a745a3b171bdc5ee6f33cd","1cbd313a8a75471ea6eacff6f98129f7","4ab32c8ace524a43976c792388adfa35","5efb3aeaf1ae415282a85faf832691a8","48d99b7e1c6c4fd2870ac6f410501268","691337026232409a8c0d8a0a30acfe4b","ed651974f2464cd08db22fdebb1f5061","702bd76da265420ba98134c0abbc7ebf","c6ef52f8616f424bae9c22e688e7c261","4e3208b4a50747a388266727d94ddcea","9b66d816f25e43c0819abce1f7e96246","6a2dcd94f0b84ba286d6ae57f8bf9c1e","c14a0dc9de3d4e4c827df1c41541b79b","3b94792a6be147099564d1897807d55e","a5a140b685be48ff86541c307c319569","0cbf0e0ce2ce46d980c64bad212001ff","7f6480d6761941ba8089a5c6fc50293b","b0eb94f83ee149aa93234d7438bfce5a","0b98a0198bb84c4e92d00f2d3417e7e4","1098aab794944885a361f08fd80259c5","0836a42ef2b249a1b7a086fac39f51e3"]},"id":"1wCnqdI9V0kp","executionInfo":{"status":"ok","timestamp":1719973667778,"user_tz":-420,"elapsed":61334,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"eac08e9b-940d-4a46-ad89-70712461226a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"488555cd3d26401ab65c320e2b7014ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e173f2e8451407cb347689e0d59c4e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ff9c6c6f5a4498da6ef6036ca1501a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9464d3e9033a4945a21d2b8d7069c686"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b66d816f25e43c0819abce1f7e96246"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded local model from /content/drive/MyDrive/PPL/trocr/model\n","Using device cuda.\n","Predicting batch 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Prediction for 20160504_0112_25849_2_tg_7_5.png:\n","Predict: nguy hiểm vì cua gắt n\n","Confidence Scores: 0.9746631979942322\n","\n","Prediction for Screenshot 2024-06-29 115458.png:\n","Predict: LLICENSEFER OF MCDONALD'S\n","Confidence Scores: 0.3485439121723175\n","\n","Prediction for Screenshot 2024-06-29 122655.png:\n","Predict: How You Benefit - Spreads\n","Confidence Scores: 0.7601991891860962\n","\n"]}]},{"cell_type":"code","source":["main_train(use_local_model=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkxnotw3V-BP","executionInfo":{"status":"ok","timestamp":1719976510513,"user_tz":-420,"elapsed":2842328,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"537c7f5e-0d5e-4f02-bb34-1fcd0c906e06"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 5097 samples from /content/drive/MyDrive/PPL/trocr/train\n","Loaded 1161 samples from /content/drive/MyDrive/PPL/trocr/val\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded local model from /content/drive/MyDrive/PPL/trocr/model\n","Using device cuda.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Batch 1: 0.07908404618501663 loss\n","Epoch 1, Batch 2: 0.029680822044610977 loss\n","Epoch 1, Batch 3: 0.11495094001293182 loss\n","Epoch 1, Batch 4: 0.04808568209409714 loss\n","Epoch 1, Batch 5: 0.05109766498208046 loss\n","Epoch 1, Batch 6: 0.08801397681236267 loss\n","Epoch 1, Batch 7: 0.07441345602273941 loss\n","Epoch 1, Batch 8: 0.06684799492359161 loss\n","Epoch 1, Batch 9: 0.12479179352521896 loss\n","Epoch 1, Batch 10: 0.07968945801258087 loss\n","Epoch 1, Batch 11: 0.08232007175683975 loss\n","Epoch 1, Batch 12: 0.11989274621009827 loss\n","Epoch 1, Batch 13: 0.14641675353050232 loss\n","Epoch 1, Batch 14: 0.1544179767370224 loss\n","Epoch 1, Batch 15: 0.14409960806369781 loss\n","Epoch 1, Batch 16: 0.0632268562912941 loss\n","Epoch 1, Batch 17: 0.137283593416214 loss\n","Epoch 1, Batch 18: 0.07261066883802414 loss\n","Epoch 1, Batch 19: 0.09291959553956985 loss\n","Epoch 1, Batch 20: 0.0696878433227539 loss\n","Epoch 1, Batch 21: 0.10838446021080017 loss\n","Epoch 1, Batch 22: 0.0962204709649086 loss\n","Epoch 1, Batch 23: 0.09486683458089828 loss\n","Epoch 1, Batch 24: 0.056603480130434036 loss\n","Epoch 1, Batch 25: 0.07905825227499008 loss\n","Epoch 1, Batch 26: 0.11244857311248779 loss\n","Epoch 1, Batch 27: 0.05952727794647217 loss\n","Epoch 1, Batch 28: 0.12293657660484314 loss\n","Epoch 1, Batch 29: 0.06459435820579529 loss\n","Epoch 1, Batch 30: 0.07002703100442886 loss\n","Epoch 1, Batch 31: 0.1252395361661911 loss\n","Epoch 1, Batch 32: 0.08283184468746185 loss\n","Epoch 1, Batch 33: 0.12758859992027283 loss\n","Epoch 1, Batch 34: 0.06266386061906815 loss\n","Epoch 1, Batch 35: 0.06827034801244736 loss\n","Epoch 1, Batch 36: 0.047380030155181885 loss\n","Epoch 1, Batch 37: 0.1504943072795868 loss\n","Epoch 1, Batch 38: 0.12588967382907867 loss\n","Epoch 1, Batch 39: 0.09030482172966003 loss\n","Epoch 1, Batch 40: 0.08989032357931137 loss\n","Epoch 1, Batch 41: 0.13397814333438873 loss\n","Epoch 1, Batch 42: 0.08604394644498825 loss\n","Epoch 1, Batch 43: 0.11366737633943558 loss\n","Epoch 1, Batch 44: 0.0855041891336441 loss\n","Epoch 1, Batch 45: 0.07151675969362259 loss\n","Epoch 1, Batch 46: 0.09465381503105164 loss\n","Epoch 1, Batch 47: 0.04610809311270714 loss\n","Epoch 1, Batch 48: 0.1279715597629547 loss\n","Epoch 1, Batch 49: 0.1562151461839676 loss\n","Epoch 1, Batch 50: 0.10228478163480759 loss\n","Epoch 1, Batch 51: 0.03813248872756958 loss\n","Epoch 1, Batch 52: 0.09006710350513458 loss\n","Epoch 1, Batch 53: 0.05814696103334427 loss\n","Epoch 1, Batch 54: 0.07141789048910141 loss\n","Epoch 1, Batch 55: 0.15254530310630798 loss\n","Epoch 1, Batch 56: 0.0372999906539917 loss\n","Epoch 1, Batch 57: 0.11355774104595184 loss\n","Epoch 1, Batch 58: 0.05888046696782112 loss\n","Epoch 1, Batch 59: 0.09998725354671478 loss\n","Epoch 1, Batch 60: 0.07461120188236237 loss\n","Epoch 1, Batch 61: 0.06439751386642456 loss\n","Epoch 1, Batch 62: 0.06994897872209549 loss\n","Epoch 1, Batch 63: 0.06985773891210556 loss\n","Epoch 1, Batch 64: 0.04563875123858452 loss\n","Epoch 1, Batch 65: 0.0750044509768486 loss\n","Epoch 1, Batch 66: 0.05855037644505501 loss\n","Epoch 1, Batch 67: 0.057142473757267 loss\n","Epoch 1, Batch 68: 0.0849669948220253 loss\n","Epoch 1, Batch 69: 0.08937465399503708 loss\n","Epoch 1, Batch 70: 0.10898486524820328 loss\n","Epoch 1, Batch 71: 0.09563466161489487 loss\n","Epoch 1, Batch 72: 0.08203953504562378 loss\n","Epoch 1, Batch 73: 0.04991816729307175 loss\n","Epoch 1, Batch 74: 0.08570374548435211 loss\n","Epoch 1, Batch 75: 0.07014693319797516 loss\n","Epoch 1, Batch 76: 0.0773465484380722 loss\n","Epoch 1, Batch 77: 0.12411980330944061 loss\n","Epoch 1, Batch 78: 0.10053443163633347 loss\n","Epoch 1, Batch 79: 0.08120497316122055 loss\n","Epoch 1, Batch 80: 0.11498639732599258 loss\n","Epoch 1, Batch 81: 0.08976413309574127 loss\n","Epoch 1, Batch 82: 0.07989490032196045 loss\n","Epoch 1, Batch 83: 0.07519222050905228 loss\n","Epoch 1, Batch 84: 0.04856293648481369 loss\n","Epoch 1, Batch 85: 0.0729861706495285 loss\n","Epoch 1, Batch 86: 0.10576906055212021 loss\n","Epoch 1, Batch 87: 0.11350899934768677 loss\n","Epoch 1, Batch 88: 0.0931035503745079 loss\n","Epoch 1, Batch 89: 0.07078646123409271 loss\n","Epoch 1, Batch 90: 0.33889085054397583 loss\n","Epoch 1, Batch 91: 0.14874619245529175 loss\n","Epoch 1, Batch 92: 0.08772651106119156 loss\n","Epoch 1, Batch 93: 0.10885966569185257 loss\n","Epoch 1, Batch 94: 0.11082090437412262 loss\n","Epoch 1, Batch 95: 0.15335553884506226 loss\n","Epoch 1, Batch 96: 0.06608688086271286 loss\n","Epoch 1, Batch 97: 0.07479546219110489 loss\n","Epoch 1, Batch 98: 0.09954110532999039 loss\n","Epoch 1, Batch 99: 0.10392241179943085 loss\n","Epoch 1, Batch 100: 0.0639030784368515 loss\n","Epoch 1, Batch 101: 0.09851203113794327 loss\n","Epoch 1, Batch 102: 0.07929103821516037 loss\n","Epoch 1, Batch 103: 0.15354369580745697 loss\n","Epoch 1, Batch 104: 0.081214539706707 loss\n","Epoch 1, Batch 105: 0.05074330046772957 loss\n","Epoch 1, Batch 106: 0.0636700987815857 loss\n","Epoch 1, Batch 107: 0.1300082504749298 loss\n","Epoch 1, Batch 108: 0.13949233293533325 loss\n","Epoch 1, Batch 109: 0.09663907438516617 loss\n","Epoch 1, Batch 110: 0.10644735395908356 loss\n","Epoch 1, Batch 111: 0.12102711200714111 loss\n","Epoch 1, Batch 112: 0.10242201387882233 loss\n","Epoch 1, Batch 113: 0.042799148708581924 loss\n","Epoch 1, Batch 114: 0.06078076735138893 loss\n","Epoch 1, Batch 115: 0.12932397425174713 loss\n","Epoch 1, Batch 116: 0.0668952465057373 loss\n","Epoch 1, Batch 117: 0.0838911384344101 loss\n","Epoch 1, Batch 118: 0.061101485043764114 loss\n","Epoch 1, Batch 119: 0.07766260951757431 loss\n","Epoch 1, Batch 120: 0.07754729688167572 loss\n","Epoch 1, Batch 121: 0.10038696974515915 loss\n","Epoch 1, Batch 122: 0.10214679688215256 loss\n","Epoch 1, Batch 123: 0.10841164737939835 loss\n","Epoch 1, Batch 124: 0.08049114048480988 loss\n","Epoch 1, Batch 125: 0.07317982614040375 loss\n","Epoch 1, Batch 126: 0.07397112995386124 loss\n","Epoch 1, Batch 127: 0.07206224650144577 loss\n","Epoch 1, Batch 128: 0.1446545571088791 loss\n","Epoch 1, Batch 129: 0.06238206848502159 loss\n","Epoch 1, Batch 130: 0.08016043156385422 loss\n","Epoch 1, Batch 131: 0.04105149954557419 loss\n","Epoch 1, Batch 132: 0.07882703840732574 loss\n","Epoch 1, Batch 133: 0.07194211333990097 loss\n","Epoch 1, Batch 134: 0.09153974056243896 loss\n","Epoch 1, Batch 135: 0.08664851635694504 loss\n","Epoch 1, Batch 136: 0.10353637486696243 loss\n","Epoch 1, Batch 137: 0.049950722604990005 loss\n","Epoch 1, Batch 138: 0.11710146069526672 loss\n","Epoch 1, Batch 139: 0.0721125453710556 loss\n","Epoch 1, Batch 140: 0.1548530012369156 loss\n","Epoch 1, Batch 141: 0.09216215461492538 loss\n","Epoch 1, Batch 142: 0.15930458903312683 loss\n","Epoch 1, Batch 143: 0.12252628803253174 loss\n","Epoch 1, Batch 144: 0.06700272113084793 loss\n","Epoch 1, Batch 145: 0.15858161449432373 loss\n","Epoch 1, Batch 146: 0.10098167508840561 loss\n","Epoch 1, Batch 147: 0.1033611074090004 loss\n","Epoch 1, Batch 148: 0.0751068964600563 loss\n","Epoch 1, Batch 149: 0.059438422322273254 loss\n","Epoch 1, Batch 150: 0.0850142389535904 loss\n","Epoch 1, Batch 151: 0.052874606102705 loss\n","Epoch 1, Batch 152: 0.06743662059307098 loss\n","Epoch 1, Batch 153: 0.12442707270383835 loss\n","Epoch 1, Batch 154: 0.1375097632408142 loss\n","Epoch 1, Batch 155: 0.09435566514730453 loss\n","Epoch 1, Batch 156: 0.07606227695941925 loss\n","Epoch 1, Batch 157: 0.08478493988513947 loss\n","Epoch 1, Batch 158: 0.07859725505113602 loss\n","Epoch 1, Batch 159: 0.08034071326255798 loss\n","Epoch 1, Batch 160: 0.09172855317592621 loss\n","Epoch 1, Batch 161: 0.0766390934586525 loss\n","Epoch 1, Batch 162: 0.06466366350650787 loss\n","Epoch 1, Batch 163: 0.07003816217184067 loss\n","Epoch 1, Batch 164: 0.12059871107339859 loss\n","Epoch 1, Batch 165: 0.14508558809757233 loss\n","Epoch 1, Batch 166: 0.07935482263565063 loss\n","Epoch 1, Batch 167: 0.12043579667806625 loss\n","Epoch 1, Batch 168: 0.09017828106880188 loss\n","Epoch 1, Batch 169: 0.07789506018161774 loss\n","Epoch 1, Batch 170: 0.056195832788944244 loss\n","Epoch 1, Batch 171: 0.08684192597866058 loss\n","Epoch 1, Batch 172: 0.12522974610328674 loss\n","Epoch 1, Batch 173: 0.11547257751226425 loss\n","Epoch 1, Batch 174: 0.24503804743289948 loss\n","Epoch 1, Batch 175: 0.05468946322798729 loss\n","Epoch 1, Batch 176: 0.06371954083442688 loss\n","Epoch 1, Batch 177: 0.14027085900306702 loss\n","Epoch 1, Batch 178: 0.07286743074655533 loss\n","Epoch 1, Batch 179: 0.0783725306391716 loss\n","Epoch 1, Batch 180: 0.06916078180074692 loss\n","Epoch 1, Batch 181: 0.08229720592498779 loss\n","Epoch 1, Batch 182: 0.05583732947707176 loss\n","Epoch 1, Batch 183: 0.061723075807094574 loss\n","Epoch 1, Batch 184: 0.08384782075881958 loss\n","Epoch 1, Batch 185: 0.08191162347793579 loss\n","Epoch 1, Batch 186: 0.07544458657503128 loss\n","Epoch 1, Batch 187: 0.1253042072057724 loss\n","Epoch 1, Batch 188: 0.07692892104387283 loss\n","Epoch 1, Batch 189: 0.10933668166399002 loss\n","Epoch 1, Batch 190: 0.07762585580348969 loss\n","Epoch 1, Batch 191: 0.08091776072978973 loss\n","Epoch 1, Batch 192: 0.07045868039131165 loss\n","Epoch 1, Batch 193: 0.08928980678319931 loss\n","Epoch 1, Batch 194: 0.1047438234090805 loss\n","Epoch 1, Batch 195: 0.041654717177152634 loss\n","Epoch 1, Batch 196: 0.08772282302379608 loss\n","Epoch 1, Batch 197: 0.059532761573791504 loss\n","Epoch 1, Batch 198: 0.06833901256322861 loss\n","Epoch 1, Batch 199: 0.0674629956483841 loss\n","Epoch 1, Batch 200: 0.07642179727554321 loss\n","Epoch 1, Batch 201: 0.06380501389503479 loss\n","Epoch 1, Batch 202: 0.10879448056221008 loss\n","Epoch 1, Batch 203: 0.0584484301507473 loss\n","Epoch 1, Batch 204: 0.07775759696960449 loss\n","Epoch 1, Batch 205: 0.01994120329618454 loss\n","Epoch 1, Batch 206: 0.08989275246858597 loss\n","Epoch 1, Batch 207: 0.081830695271492 loss\n","Epoch 1, Batch 208: 0.14341135323047638 loss\n","Epoch 1, Batch 209: 0.05962236598134041 loss\n","Epoch 1, Batch 210: 0.10947036743164062 loss\n","Epoch 1, Batch 211: 0.11950132250785828 loss\n","Epoch 1, Batch 212: 0.07888103276491165 loss\n","Epoch 1, Batch 213: 0.09114453196525574 loss\n","Epoch 1, Batch 214: 0.11476179957389832 loss\n","Epoch 1, Batch 215: 0.06950798630714417 loss\n","Epoch 1, Batch 216: 0.10280095040798187 loss\n","Epoch 1, Batch 217: 0.09046520292758942 loss\n","Epoch 1, Batch 218: 0.1866346001625061 loss\n","Epoch 1, Batch 219: 0.0692233219742775 loss\n","Epoch 1, Batch 220: 0.03619971498847008 loss\n","Epoch 1, Batch 221: 0.1071534976363182 loss\n","Epoch 1, Batch 222: 0.10797440260648727 loss\n","Epoch 1, Batch 223: 0.09791486710309982 loss\n","Epoch 1, Batch 224: 0.06162792444229126 loss\n","Epoch 1, Batch 225: 0.10727407783269882 loss\n","Epoch 1, Batch 226: 0.07382837682962418 loss\n","Epoch 1, Batch 227: 0.07961621135473251 loss\n","Epoch 1, Batch 228: 0.09123949706554413 loss\n","Epoch 1, Batch 229: 0.14225590229034424 loss\n","Epoch 1, Batch 230: 0.04945863038301468 loss\n","Epoch 1, Batch 231: 0.08668265491724014 loss\n","Epoch 1, Batch 232: 0.07462230324745178 loss\n","Epoch 1, Batch 233: 0.15564356744289398 loss\n","Epoch 1, Batch 234: 0.11890016496181488 loss\n","Epoch 1, Batch 235: 0.06913930922746658 loss\n","Epoch 1, Batch 236: 0.10853356868028641 loss\n","Epoch 1, Batch 237: 0.05968843027949333 loss\n","Epoch 1, Batch 238: 0.12187781184911728 loss\n","Epoch 1, Batch 239: 0.10753018409013748 loss\n","Epoch 1, Batch 240: 0.08156117796897888 loss\n","Epoch 1, Batch 241: 0.06301268190145493 loss\n","Epoch 1, Batch 242: 0.07119081169366837 loss\n","Epoch 1, Batch 243: 0.06738267093896866 loss\n","Epoch 1, Batch 244: 0.11048505455255508 loss\n","Epoch 1, Batch 245: 0.12296508997678757 loss\n","Epoch 1, Batch 246: 0.10878486931324005 loss\n","Epoch 1, Batch 247: 0.05583981052041054 loss\n","Epoch 1, Batch 248: 0.062082573771476746 loss\n","Epoch 1, Batch 249: 0.11545021831989288 loss\n","Epoch 1, Batch 250: 0.07932241261005402 loss\n","Epoch 1, Batch 251: 0.09682812541723251 loss\n","Epoch 1, Batch 252: 0.05967441573739052 loss\n","Epoch 1, Batch 253: 0.08145696669816971 loss\n","Epoch 1, Batch 254: 0.062454018741846085 loss\n","Epoch 1, Batch 255: 0.1276458352804184 loss\n","Epoch 1, Batch 256: 0.10375215858221054 loss\n","Epoch 1, Batch 257: 0.08261945098638535 loss\n","Epoch 1, Batch 258: 0.03663480654358864 loss\n","Epoch 1, Batch 259: 0.09184340387582779 loss\n","Epoch 1, Batch 260: 0.13209959864616394 loss\n","Epoch 1, Batch 261: 0.08204744756221771 loss\n","Epoch 1, Batch 262: 0.08709133416414261 loss\n","Epoch 1, Batch 263: 0.08012645691633224 loss\n","Epoch 1, Batch 264: 0.07192865759134293 loss\n","Epoch 1, Batch 265: 0.06158314645290375 loss\n","Epoch 1, Batch 266: 0.06858422607183456 loss\n","Epoch 1, Batch 267: 0.07841988652944565 loss\n","Epoch 1, Batch 268: 0.05657295137643814 loss\n","Epoch 1, Batch 269: 0.0454411543905735 loss\n","Epoch 1, Batch 270: 0.08952141553163528 loss\n","Epoch 1, Batch 271: 0.14646251499652863 loss\n","Epoch 1, Batch 272: 0.03891287371516228 loss\n","Epoch 1, Batch 273: 0.09278859198093414 loss\n","Epoch 1, Batch 274: 0.1441369652748108 loss\n","Epoch 1, Batch 275: 0.08752605319023132 loss\n","Epoch 1, Batch 276: 0.06409048289060593 loss\n","Epoch 1, Batch 277: 0.13280324637889862 loss\n","Epoch 1, Batch 278: 0.0657196119427681 loss\n","Epoch 1, Batch 279: 0.06650450080633163 loss\n","Epoch 1, Batch 280: 0.06671560555696487 loss\n","Epoch 1, Batch 281: 0.06489016115665436 loss\n","Epoch 1, Batch 282: 0.07270262390375137 loss\n","Epoch 1, Batch 283: 0.056379202753305435 loss\n","Epoch 1, Batch 284: 0.13151291012763977 loss\n","Epoch 1, Batch 285: 0.13580258190631866 loss\n","Epoch 1, Batch 286: 0.1293807476758957 loss\n","Epoch 1, Batch 287: 0.13261428475379944 loss\n","Epoch 1, Batch 288: 0.06936788558959961 loss\n","Epoch 1, Batch 289: 0.048373036086559296 loss\n","Epoch 1, Batch 290: 0.06429169327020645 loss\n","Epoch 1, Batch 291: 0.07367949187755585 loss\n","Epoch 1, Batch 292: 0.17068317532539368 loss\n","Epoch 1, Batch 293: 0.11752618849277496 loss\n","Epoch 1, Batch 294: 0.0503433458507061 loss\n","Epoch 1, Batch 295: 0.024824855849146843 loss\n","Epoch 1, Batch 296: 0.08234447985887527 loss\n","Epoch 1, Batch 297: 0.12275763601064682 loss\n","Epoch 1, Batch 298: 0.08986135572195053 loss\n","Epoch 1, Batch 299: 0.056193653494119644 loss\n","Epoch 1, Batch 300: 0.12895531952381134 loss\n","Epoch 1, Batch 301: 0.04036744683980942 loss\n","Epoch 1, Batch 302: 0.06687791645526886 loss\n","Epoch 1, Batch 303: 0.10417812317609787 loss\n","Epoch 1, Batch 304: 0.05095387250185013 loss\n","Epoch 1, Batch 305: 0.04532032832503319 loss\n","Epoch 1, Batch 306: 0.07870227843523026 loss\n","Epoch 1, Batch 307: 0.07226910442113876 loss\n","Epoch 1, Batch 308: 0.10549317300319672 loss\n","Epoch 1, Batch 309: 0.07432571798563004 loss\n","Epoch 1, Batch 310: 0.04843373969197273 loss\n","Epoch 1, Batch 311: 0.11138845980167389 loss\n","Epoch 1, Batch 312: 0.09004905074834824 loss\n","Epoch 1, Batch 313: 0.16345666348934174 loss\n","Epoch 1, Batch 314: 0.07834107428789139 loss\n","Epoch 1, Batch 315: 0.05541793629527092 loss\n","Epoch 1, Batch 316: 0.07316087186336517 loss\n","Epoch 1, Batch 317: 0.10073228180408478 loss\n","Epoch 1, Batch 318: 0.2142730951309204 loss\n","Epoch 1, Batch 319: 0.08469456434249878 loss\n","Epoch 1, Batch 320: 0.04441387206315994 loss\n","Epoch 1, Batch 321: 0.07533077895641327 loss\n","Epoch 1, Batch 322: 0.08061574399471283 loss\n","Epoch 1, Batch 323: 0.10813187807798386 loss\n","Epoch 1, Batch 324: 0.07987063378095627 loss\n","Epoch 1, Batch 325: 0.05319208279252052 loss\n","Epoch 1, Batch 326: 0.09706542640924454 loss\n","Epoch 1, Batch 327: 0.10723007470369339 loss\n","Epoch 1, Batch 328: 0.131767138838768 loss\n","Epoch 1, Batch 329: 0.09599339216947556 loss\n","Epoch 1, Batch 330: 0.09462893009185791 loss\n","Epoch 1, Batch 331: 0.07220964133739471 loss\n","Epoch 1, Batch 332: 0.10353370010852814 loss\n","Epoch 1, Batch 333: 0.16131094098091125 loss\n","Epoch 1, Batch 334: 0.1389026790857315 loss\n","Epoch 1, Batch 335: 0.1364099234342575 loss\n","Epoch 1, Batch 336: 0.08109991997480392 loss\n","Epoch 1, Batch 337: 0.0855158343911171 loss\n","Epoch 1, Batch 338: 0.1616014838218689 loss\n","Epoch 1, Batch 339: 0.13604404032230377 loss\n","Epoch 1, Batch 340: 0.11254455149173737 loss\n","Epoch 1, Batch 341: 0.12485883384943008 loss\n","Epoch 1, Batch 342: 0.05812441557645798 loss\n","Epoch 1, Batch 343: 0.10917728394269943 loss\n","Epoch 1, Batch 344: 0.08052590489387512 loss\n","Epoch 1, Batch 345: 0.09116272628307343 loss\n","Epoch 1, Batch 346: 0.06755232810974121 loss\n","Epoch 1, Batch 347: 0.0522729828953743 loss\n","Epoch 1, Batch 348: 0.061365168541669846 loss\n","Epoch 1, Batch 349: 0.09007108956575394 loss\n","Epoch 1, Batch 350: 0.07172723859548569 loss\n","Epoch 1, Batch 351: 0.04824569448828697 loss\n","Epoch 1, Batch 352: 0.09488018602132797 loss\n","Epoch 1, Batch 353: 0.1408984214067459 loss\n","Epoch 1, Batch 354: 0.12659546732902527 loss\n","Epoch 1, Batch 355: 0.15905940532684326 loss\n","Epoch 1, Batch 356: 0.12289741635322571 loss\n","Epoch 1, Batch 357: 0.07501444965600967 loss\n","Epoch 1, Batch 358: 0.06890035420656204 loss\n","Epoch 1, Batch 359: 0.06951013952493668 loss\n","Epoch 1, Batch 360: 0.05883504077792168 loss\n","Epoch 1, Batch 361: 0.06755570322275162 loss\n","Epoch 1, Batch 362: 0.1409911960363388 loss\n","Epoch 1, Batch 363: 0.06515751779079437 loss\n","Epoch 1, Batch 364: 0.059802912175655365 loss\n","Epoch 1, Batch 365: 0.10239136219024658 loss\n","Epoch 1, Batch 366: 0.20933103561401367 loss\n","Epoch 1, Batch 367: 0.0941142588853836 loss\n","Epoch 1, Batch 368: 0.0897398442029953 loss\n","Epoch 1, Batch 369: 0.06304087489843369 loss\n","Epoch 1, Batch 370: 0.06307950615882874 loss\n","Epoch 1, Batch 371: 0.09054730832576752 loss\n","Epoch 1, Batch 372: 0.10783340036869049 loss\n","Epoch 1, Batch 373: 0.07066008448600769 loss\n","Epoch 1, Batch 374: 0.1006905734539032 loss\n","Epoch 1, Batch 375: 0.1040085181593895 loss\n","Epoch 1, Batch 376: 0.06178327649831772 loss\n","Epoch 1, Batch 377: 0.06795960664749146 loss\n","Epoch 1, Batch 378: 0.09497585892677307 loss\n","Epoch 1, Batch 379: 0.03311387822031975 loss\n","Epoch 1, Batch 380: 0.1633443534374237 loss\n","Epoch 1, Batch 381: 0.11519983410835266 loss\n","Epoch 1, Batch 382: 0.10236341506242752 loss\n","Epoch 1, Batch 383: 0.08239900320768356 loss\n","Epoch 1, Batch 384: 0.18631328642368317 loss\n","Epoch 1, Batch 385: 0.12289594113826752 loss\n","Epoch 1, Batch 386: 0.13341766595840454 loss\n","Epoch 1, Batch 387: 0.06628594547510147 loss\n","Epoch 1, Batch 388: 0.05630886182188988 loss\n","Epoch 1, Batch 389: 0.12227845191955566 loss\n","Epoch 1, Batch 390: 0.13777318596839905 loss\n","Epoch 1, Batch 391: 0.14356109499931335 loss\n","Epoch 1, Batch 392: 0.08396181464195251 loss\n","Epoch 1, Batch 393: 0.1158253401517868 loss\n","Epoch 1, Batch 394: 0.12298820912837982 loss\n","Epoch 1, Batch 395: 0.0534205362200737 loss\n","Epoch 1, Batch 396: 0.09537205845117569 loss\n","Epoch 1, Batch 397: 0.07277665287256241 loss\n","Epoch 1, Batch 398: 0.12154676020145416 loss\n","Epoch 1, Batch 399: 0.05602986738085747 loss\n","Epoch 1, Batch 400: 0.060498908162117004 loss\n","Epoch 1, Batch 401: 0.10918675363063812 loss\n","Epoch 1, Batch 402: 0.06314107775688171 loss\n","Epoch 1, Batch 403: 0.08390464633703232 loss\n","Epoch 1, Batch 404: 0.0997031033039093 loss\n","Epoch 1, Batch 405: 0.05937221273779869 loss\n","Epoch 1, Batch 406: 0.06846421957015991 loss\n","Epoch 1, Batch 407: 0.11687681823968887 loss\n","Epoch 1, Batch 408: 0.05790712684392929 loss\n","Epoch 1, Batch 409: 0.06177050620317459 loss\n","Epoch 1, Batch 410: 0.05617520213127136 loss\n","Epoch 1, Batch 411: 0.1056847870349884 loss\n","Epoch 1, Batch 412: 0.09335469454526901 loss\n","Epoch 1, Batch 413: 0.06902774423360825 loss\n","Epoch 1, Batch 414: 0.09488878399133682 loss\n","Epoch 1, Batch 415: 0.07107152789831161 loss\n","Epoch 1, Batch 416: 0.09663758426904678 loss\n","Epoch 1, Batch 417: 0.03894096612930298 loss\n","Epoch 1, Batch 418: 0.05823187157511711 loss\n","Epoch 1, Batch 419: 0.08481056243181229 loss\n","Epoch 1, Batch 420: 0.09069239348173141 loss\n","Epoch 1, Batch 421: 0.043319668620824814 loss\n","Epoch 1, Batch 422: 0.047900862991809845 loss\n","Epoch 1, Batch 423: 0.09183522313833237 loss\n","Epoch 1, Batch 424: 0.1197301372885704 loss\n","Epoch 1, Batch 425: 0.056386493146419525 loss\n","Epoch 1, Batch 426: 0.08052848279476166 loss\n","Epoch 1, Batch 427: 0.07452980428934097 loss\n","Epoch 1, Batch 428: 0.08806785941123962 loss\n","Epoch 1, Batch 429: 0.11393707245588303 loss\n","Epoch 1, Batch 430: 0.07716289907693863 loss\n","Epoch 1, Batch 431: 0.0875675231218338 loss\n","Epoch 1, Batch 432: 0.1202579215168953 loss\n","Epoch 1, Batch 433: 0.06368479132652283 loss\n","Epoch 1, Batch 434: 0.028576316311955452 loss\n","Epoch 1, Batch 435: 0.127362459897995 loss\n","Epoch 1, Batch 436: 0.05539657920598984 loss\n","Epoch 1, Batch 437: 0.05373382568359375 loss\n","Epoch 1, Batch 438: 0.1114342212677002 loss\n","Epoch 1, Batch 439: 0.08730976283550262 loss\n","Epoch 1, Batch 440: 0.07088074833154678 loss\n","Epoch 1, Batch 441: 0.08189324289560318 loss\n","Epoch 1, Batch 442: 0.08308666199445724 loss\n","Epoch 1, Batch 443: 0.06775365024805069 loss\n","Epoch 1, Batch 444: 0.0418403297662735 loss\n","Epoch 1, Batch 445: 0.05692600831389427 loss\n","Epoch 1, Batch 446: 0.08010014146566391 loss\n","Epoch 1, Batch 447: 0.1086151972413063 loss\n","Epoch 1, Batch 448: 0.09588487446308136 loss\n","Epoch 1, Batch 449: 0.062055859714746475 loss\n","Epoch 1, Batch 450: 0.05638225004076958 loss\n","Epoch 1, Batch 451: 0.08014092594385147 loss\n","Epoch 1, Batch 452: 0.09965702146291733 loss\n","Epoch 1, Batch 453: 0.06443364173173904 loss\n","Epoch 1, Batch 454: 0.06332917511463165 loss\n","Epoch 1, Batch 455: 0.0597962960600853 loss\n","Epoch 1, Batch 456: 0.09132368862628937 loss\n","Epoch 1, Batch 457: 0.07904549688100815 loss\n","Epoch 1, Batch 458: 0.07835526764392853 loss\n","Epoch 1, Batch 459: 0.07444757968187332 loss\n","Epoch 1, Batch 460: 0.09484546631574631 loss\n","Epoch 1, Batch 461: 0.0582113042473793 loss\n","Epoch 1, Batch 462: 0.07491588592529297 loss\n","Epoch 1, Batch 463: 0.12590977549552917 loss\n","Epoch 1, Batch 464: 0.0973309576511383 loss\n","Epoch 1, Batch 465: 0.12846657633781433 loss\n","Epoch 1, Batch 466: 0.10214387625455856 loss\n","Epoch 1, Batch 467: 0.10649377107620239 loss\n","Epoch 1, Batch 468: 0.04358416423201561 loss\n","Epoch 1, Batch 469: 0.06678837537765503 loss\n","Epoch 1, Batch 470: 0.054407428950071335 loss\n","Epoch 1, Batch 471: 0.05431090667843819 loss\n","Epoch 1, Batch 472: 0.07201600074768066 loss\n","Epoch 1, Batch 473: 0.12477148324251175 loss\n","Epoch 1, Batch 474: 0.1446952223777771 loss\n","Epoch 1, Batch 475: 0.11806248873472214 loss\n","Epoch 1, Batch 476: 0.05998596176505089 loss\n","Epoch 1, Batch 477: 0.12627921998500824 loss\n","Epoch 1, Batch 478: 0.085512176156044 loss\n","Epoch 1, Batch 479: 0.20091399550437927 loss\n","Epoch 1, Batch 480: 0.06593434512615204 loss\n","Epoch 1, Batch 481: 0.06916292011737823 loss\n","Epoch 1, Batch 482: 0.059744637459516525 loss\n","Epoch 1, Batch 483: 0.09031671285629272 loss\n","Epoch 1, Batch 484: 0.19147424399852753 loss\n","Epoch 1, Batch 485: 0.06553956866264343 loss\n","Epoch 1, Batch 486: 0.14953753352165222 loss\n","Epoch 1, Batch 487: 0.08006647229194641 loss\n","Epoch 1, Batch 488: 0.07617351412773132 loss\n","Epoch 1, Batch 489: 0.10467788577079773 loss\n","Epoch 1, Batch 490: 0.15428262948989868 loss\n","Epoch 1, Batch 491: 0.062437504529953 loss\n","Epoch 1, Batch 492: 0.06830093264579773 loss\n","Epoch 1, Batch 493: 0.0608748197555542 loss\n","Epoch 1, Batch 494: 0.06944943964481354 loss\n","Epoch 1, Batch 495: 0.16281944513320923 loss\n","Epoch 1, Batch 496: 0.10209178924560547 loss\n","Epoch 1, Batch 497: 0.09994067996740341 loss\n","Epoch 1, Batch 498: 0.1005195677280426 loss\n","Epoch 1, Batch 499: 0.08796954154968262 loss\n","Epoch 1, Batch 500: 0.12105850130319595 loss\n","Epoch 1, Batch 501: 0.08444181084632874 loss\n","Epoch 1, Batch 502: 0.12554699182510376 loss\n","Epoch 1, Batch 503: 0.06581329554319382 loss\n","Epoch 1, Batch 504: 0.0924014076590538 loss\n","Epoch 1, Batch 505: 0.09487488120794296 loss\n","Epoch 1, Batch 506: 0.1229754313826561 loss\n","Epoch 1, Batch 507: 0.119745172560215 loss\n","Epoch 1, Batch 508: 0.06967804580926895 loss\n","Epoch 1, Batch 509: 0.091061070561409 loss\n","Epoch 1, Batch 510: 0.10832792520523071 loss\n","Epoch 1, Batch 511: 0.08365395665168762 loss\n","Epoch 1, Batch 512: 0.04424501210451126 loss\n","Epoch 1, Batch 513: 0.05188554897904396 loss\n","Epoch 1, Batch 514: 0.08136022835969925 loss\n","Epoch 1, Batch 515: 0.1036456897854805 loss\n","Epoch 1, Batch 516: 0.09199577569961548 loss\n","Epoch 1, Batch 517: 0.11459311842918396 loss\n","Epoch 1, Batch 518: 0.08793099224567413 loss\n","Epoch 1, Batch 519: 0.057104725390672684 loss\n","Epoch 1, Batch 520: 0.07834767550230026 loss\n","Epoch 1, Batch 521: 0.10088808834552765 loss\n","Epoch 1, Batch 522: 0.05307896062731743 loss\n","Epoch 1, Batch 523: 0.06529485434293747 loss\n","Epoch 1, Batch 524: 0.10895568877458572 loss\n","Epoch 1, Batch 525: 0.11295509338378906 loss\n","Epoch 1, Batch 526: 0.06911920011043549 loss\n","Epoch 1, Batch 527: 0.091075599193573 loss\n","Epoch 1, Batch 528: 0.1736028641462326 loss\n","Epoch 1, Batch 529: 0.07394170016050339 loss\n","Epoch 1, Batch 530: 0.08151081949472427 loss\n","Epoch 1, Batch 531: 0.0645950511097908 loss\n","Epoch 1, Batch 532: 0.05411204323172569 loss\n","Epoch 1, Batch 533: 0.15044502913951874 loss\n","Epoch 1, Batch 534: 0.08421000093221664 loss\n","Epoch 1, Batch 535: 0.03485880792140961 loss\n","Epoch 1, Batch 536: 0.09424716234207153 loss\n","Epoch 1, Batch 537: 0.10352709144353867 loss\n","Epoch 1, Batch 538: 0.2045816034078598 loss\n","Epoch 1, Batch 539: 0.0647580698132515 loss\n","Epoch 1, Batch 540: 0.0934959277510643 loss\n","Epoch 1, Batch 541: 0.11036277562379837 loss\n","Epoch 1, Batch 542: 0.07746351510286331 loss\n","Epoch 1, Batch 543: 0.04931645467877388 loss\n","Epoch 1, Batch 544: 0.09617870301008224 loss\n","Epoch 1, Batch 545: 0.09166096150875092 loss\n","Epoch 1, Batch 546: 0.13214153051376343 loss\n","Epoch 1, Batch 547: 0.08576177060604095 loss\n","Epoch 1, Batch 548: 0.10063144564628601 loss\n","Epoch 1, Batch 549: 0.06812094151973724 loss\n","Epoch 1, Batch 550: 0.08664251863956451 loss\n","Epoch 1, Batch 551: 0.08266755938529968 loss\n","Epoch 1, Batch 552: 0.03810245916247368 loss\n","Epoch 1, Batch 553: 0.1610141098499298 loss\n","Epoch 1, Batch 554: 0.14804747700691223 loss\n","Epoch 1, Batch 555: 0.02756672538816929 loss\n","Epoch 1, Batch 556: 0.058244965970516205 loss\n","Epoch 1, Batch 557: 0.026674466207623482 loss\n","Epoch 1, Batch 558: 0.08932662010192871 loss\n","Epoch 1, Batch 559: 0.07393539696931839 loss\n","Epoch 1, Batch 560: 0.09243250638246536 loss\n","Epoch 1, Batch 561: 0.0425834096968174 loss\n","Epoch 1, Batch 562: 0.08767746388912201 loss\n","Epoch 1, Batch 563: 0.07145056873559952 loss\n","Epoch 1, Batch 564: 0.11058026552200317 loss\n","Epoch 1, Batch 565: 0.1374637335538864 loss\n","Epoch 1, Batch 566: 0.035209644585847855 loss\n","Epoch 1, Batch 567: 0.1048608347773552 loss\n","Epoch 1, Batch 568: 0.1275758296251297 loss\n","Epoch 1, Batch 569: 0.09981750696897507 loss\n","Epoch 1, Batch 570: 0.1055062934756279 loss\n","Epoch 1, Batch 571: 0.08576568961143494 loss\n","Epoch 1, Batch 572: 0.06735412776470184 loss\n","Epoch 1, Batch 573: 0.10464571416378021 loss\n","Epoch 1, Batch 574: 0.11889093369245529 loss\n","Epoch 1, Batch 575: 0.12112028151750565 loss\n","Epoch 1, Batch 576: 0.08364657312631607 loss\n","Epoch 1, Batch 577: 0.0940069705247879 loss\n","Epoch 1, Batch 578: 0.05173445865511894 loss\n","Epoch 1, Batch 579: 0.07859646528959274 loss\n","Epoch 1, Batch 580: 0.10867045074701309 loss\n","Epoch 1, Batch 581: 0.0956466868519783 loss\n","Epoch 1, Batch 582: 0.044232774525880814 loss\n","Epoch 1, Batch 583: 0.11835452914237976 loss\n","Epoch 1, Batch 584: 0.06619873642921448 loss\n","Epoch 1, Batch 585: 0.08369875699281693 loss\n","Epoch 1, Batch 586: 0.17992821335792542 loss\n","Epoch 1, Batch 587: 0.06823223829269409 loss\n","Epoch 1, Batch 588: 0.04172435775399208 loss\n","Epoch 1, Batch 589: 0.07846320420503616 loss\n","Epoch 1, Batch 590: 0.058250125497579575 loss\n","Epoch 1, Batch 591: 0.07203499972820282 loss\n","Epoch 1, Batch 592: 0.07994750142097473 loss\n","Epoch 1, Batch 593: 0.08126222342252731 loss\n","Epoch 1, Batch 594: 0.0966360792517662 loss\n","Epoch 1, Batch 595: 0.06882923096418381 loss\n","Epoch 1, Batch 596: 0.06311263889074326 loss\n","Epoch 1, Batch 597: 0.06701301038265228 loss\n","Epoch 1, Batch 598: 0.0650690346956253 loss\n","Epoch 1, Batch 599: 0.033601585775613785 loss\n","Epoch 1, Batch 600: 0.0949210450053215 loss\n","Epoch 1, Batch 601: 0.16179919242858887 loss\n","Epoch 1, Batch 602: 0.06488808989524841 loss\n","Epoch 1, Batch 603: 0.04087328538298607 loss\n","Epoch 1, Batch 604: 0.09779386967420578 loss\n","Epoch 1, Batch 605: 0.07715204358100891 loss\n","Epoch 1, Batch 606: 0.0770983025431633 loss\n","Epoch 1, Batch 607: 0.0656106099486351 loss\n","Epoch 1, Batch 608: 0.13875296711921692 loss\n","Epoch 1, Batch 609: 0.1592794805765152 loss\n","Epoch 1, Batch 610: 0.08466800302267075 loss\n","Epoch 1, Batch 611: 0.11729489266872406 loss\n","Epoch 1, Batch 612: 0.08591615408658981 loss\n","Epoch 1, Batch 613: 0.0632086917757988 loss\n","Epoch 1, Batch 614: 0.13333362340927124 loss\n","Epoch 1, Batch 615: 0.04967375099658966 loss\n","Epoch 1, Batch 616: 0.07831671088933945 loss\n","Epoch 1, Batch 617: 0.10926810652017593 loss\n","Epoch 1, Batch 618: 0.08003151416778564 loss\n","Epoch 1, Batch 619: 0.06199033930897713 loss\n","Epoch 1, Batch 620: 0.06820853799581528 loss\n","Epoch 1, Batch 621: 0.05954248830676079 loss\n","Epoch 1, Batch 622: 0.11452065408229828 loss\n","Epoch 1, Batch 623: 0.12288443744182587 loss\n","Epoch 1, Batch 624: 0.08798535913228989 loss\n","Epoch 1, Batch 625: 0.0929589793086052 loss\n","Epoch 1, Batch 626: 0.044133976101875305 loss\n","Epoch 1, Batch 627: 0.07026264816522598 loss\n","Epoch 1, Batch 628: 0.10319532454013824 loss\n","Epoch 1, Batch 629: 0.03232719376683235 loss\n","Epoch 1, Batch 630: 0.11463568359613419 loss\n","Epoch 1, Batch 631: 0.030691515654325485 loss\n","Epoch 1, Batch 632: 0.06564341485500336 loss\n","Epoch 1, Batch 633: 0.10202312469482422 loss\n","Epoch 1, Batch 634: 0.0896710529923439 loss\n","Epoch 1, Batch 635: 0.07598449289798737 loss\n","Epoch 1, Batch 636: 0.07149466127157211 loss\n","Epoch 1, Batch 637: 0.12415917217731476 loss\n","Epoch 1, Batch 638: 0.005146850366145372 loss\n","Predicting batch 1\n","Predicting batch 2\n","Predicting batch 3\n","Predicting batch 4\n","Predicting batch 5\n","Predicting batch 6\n","Predicting batch 7\n","Predicting batch 8\n","Predicting batch 9\n","Predicting batch 10\n","Predicting batch 11\n","Predicting batch 12\n","Predicting batch 13\n","Predicting batch 14\n","Predicting batch 15\n","Predicting batch 16\n","Predicting batch 17\n","Predicting batch 18\n","Predicting batch 19\n","Predicting batch 20\n","Predicting batch 21\n","Predicting batch 22\n","Predicting batch 23\n","Predicting batch 24\n","Predicting batch 25\n","Predicting batch 26\n","Predicting batch 27\n","Predicting batch 28\n","Predicting batch 29\n","Predicting batch 30\n","Predicting batch 31\n","Predicting batch 32\n","Predicting batch 33\n","Predicting batch 34\n","Predicting batch 35\n","Predicting batch 36\n","Predicting batch 37\n","Predicting batch 38\n","Predicting batch 39\n","Predicting batch 40\n","Predicting batch 41\n","Predicting batch 42\n","Predicting batch 43\n","Predicting batch 44\n","Predicting batch 45\n","Predicting batch 46\n","Predicting batch 47\n","Predicting batch 48\n","Predicting batch 49\n","Predicting batch 50\n","Predicting batch 51\n","Predicting batch 52\n","Predicting batch 53\n","Predicting batch 54\n","Predicting batch 55\n","Predicting batch 56\n","Predicting batch 57\n","Predicting batch 58\n","Predicting batch 59\n","Predicting batch 60\n","Predicting batch 61\n","Predicting batch 62\n","Predicting batch 63\n","Predicting batch 64\n","Predicting batch 65\n","Predicting batch 66\n","Predicting batch 67\n","Predicting batch 68\n","Predicting batch 69\n","Predicting batch 70\n","Predicting batch 71\n","Predicting batch 72\n","Predicting batch 73\n","Predicting batch 74\n","Predicting batch 75\n","Predicting batch 76\n","Predicting batch 77\n","Predicting batch 78\n","Predicting batch 79\n","Predicting batch 80\n","Predicting batch 81\n","Predicting batch 82\n","Predicting batch 83\n","Predicting batch 84\n","Predicting batch 85\n","Predicting batch 86\n","Predicting batch 87\n","Predicting batch 88\n","Predicting batch 89\n","Predicting batch 90\n","Predicting batch 91\n","Predicting batch 92\n","Predicting batch 93\n","Predicting batch 94\n","Predicting batch 95\n","Predicting batch 96\n","Predicting batch 97\n","Predicting batch 98\n","Predicting batch 99\n","Predicting batch 100\n","Predicting batch 101\n","Predicting batch 102\n","Predicting batch 103\n","Predicting batch 104\n","Predicting batch 105\n","Predicting batch 106\n","Predicting batch 107\n","Predicting batch 108\n","Predicting batch 109\n","Predicting batch 110\n","Predicting batch 111\n","Predicting batch 112\n","Predicting batch 113\n","Predicting batch 114\n","Predicting batch 115\n","Predicting batch 116\n","Predicting batch 117\n","Predicting batch 118\n","Predicting batch 119\n","Predicting batch 120\n","Predicting batch 121\n","Predicting batch 122\n","Predicting batch 123\n","Predicting batch 124\n","Predicting batch 125\n","Predicting batch 126\n","Predicting batch 127\n","Predicting batch 128\n","Predicting batch 129\n","Predicting batch 130\n","Predicting batch 131\n","Predicting batch 132\n","Predicting batch 133\n","Predicting batch 134\n","Predicting batch 135\n","Predicting batch 136\n","Predicting batch 137\n","Predicting batch 138\n","Predicting batch 139\n","Predicting batch 140\n","Predicting batch 141\n","Predicting batch 142\n","Predicting batch 143\n","Predicting batch 144\n","Predicting batch 145\n","Predicting batch 146\n","\n","---- Epoch 1 ----\n","Accuracy: 0.012919896640826873\n","\n","\n","Epoch 2, Batch 1: 0.0510517917573452 loss\n","Epoch 2, Batch 2: 0.0357755571603775 loss\n","Epoch 2, Batch 3: 0.05112721025943756 loss\n","Epoch 2, Batch 4: 0.052353888750076294 loss\n","Epoch 2, Batch 5: 0.039695724844932556 loss\n","Epoch 2, Batch 6: 0.05698983371257782 loss\n","Epoch 2, Batch 7: 0.05628687143325806 loss\n","Epoch 2, Batch 8: 0.06926785409450531 loss\n","Epoch 2, Batch 9: 0.03467639908194542 loss\n","Epoch 2, Batch 10: 0.03831970691680908 loss\n","Epoch 2, Batch 11: 0.04825133457779884 loss\n","Epoch 2, Batch 12: 0.061280764639377594 loss\n","Epoch 2, Batch 13: 0.07229696959257126 loss\n","Epoch 2, Batch 14: 0.04188152775168419 loss\n","Epoch 2, Batch 15: 0.05299435928463936 loss\n","Epoch 2, Batch 16: 0.031589046120643616 loss\n","Epoch 2, Batch 17: 0.050812285393476486 loss\n","Epoch 2, Batch 18: 0.05491514876484871 loss\n","Epoch 2, Batch 19: 0.048054568469524384 loss\n","Epoch 2, Batch 20: 0.04649366810917854 loss\n","Epoch 2, Batch 21: 0.0397130623459816 loss\n","Epoch 2, Batch 22: 0.051373034715652466 loss\n","Epoch 2, Batch 23: 0.06029001623392105 loss\n","Epoch 2, Batch 24: 0.07873864471912384 loss\n","Epoch 2, Batch 25: 0.07152072340250015 loss\n","Epoch 2, Batch 26: 0.04320117458701134 loss\n","Epoch 2, Batch 27: 0.07551434636116028 loss\n","Epoch 2, Batch 28: 0.04848913475871086 loss\n","Epoch 2, Batch 29: 0.06340545415878296 loss\n","Epoch 2, Batch 30: 0.0537894181907177 loss\n","Epoch 2, Batch 31: 0.062307968735694885 loss\n","Epoch 2, Batch 32: 0.051924265921115875 loss\n","Epoch 2, Batch 33: 0.06770183145999908 loss\n","Epoch 2, Batch 34: 0.053977567702531815 loss\n","Epoch 2, Batch 35: 0.019579332321882248 loss\n","Epoch 2, Batch 36: 0.048489049077034 loss\n","Epoch 2, Batch 37: 0.06985728442668915 loss\n","Epoch 2, Batch 38: 0.09408431500196457 loss\n","Epoch 2, Batch 39: 0.056021351367235184 loss\n","Epoch 2, Batch 40: 0.04959995672106743 loss\n","Epoch 2, Batch 41: 0.08160874992609024 loss\n","Epoch 2, Batch 42: 0.0879066213965416 loss\n","Epoch 2, Batch 43: 0.06138531118631363 loss\n","Epoch 2, Batch 44: 0.06187967583537102 loss\n","Epoch 2, Batch 45: 0.04474661126732826 loss\n","Epoch 2, Batch 46: 0.052681416273117065 loss\n","Epoch 2, Batch 47: 0.06165735796093941 loss\n","Epoch 2, Batch 48: 0.05362844467163086 loss\n","Epoch 2, Batch 49: 0.052844006568193436 loss\n","Epoch 2, Batch 50: 0.08650510013103485 loss\n","Epoch 2, Batch 51: 0.06639331579208374 loss\n","Epoch 2, Batch 52: 0.056416891515254974 loss\n","Epoch 2, Batch 53: 0.02676101215183735 loss\n","Epoch 2, Batch 54: 0.029805665835738182 loss\n","Epoch 2, Batch 55: 0.0547841340303421 loss\n","Epoch 2, Batch 56: 0.03655385226011276 loss\n","Epoch 2, Batch 57: 0.07763028144836426 loss\n","Epoch 2, Batch 58: 0.05114155635237694 loss\n","Epoch 2, Batch 59: 0.0652550756931305 loss\n","Epoch 2, Batch 60: 0.047035131603479385 loss\n","Epoch 2, Batch 61: 0.06308399140834808 loss\n","Epoch 2, Batch 62: 0.04872477054595947 loss\n","Epoch 2, Batch 63: 0.05098607391119003 loss\n","Epoch 2, Batch 64: 0.02688879519701004 loss\n","Epoch 2, Batch 65: 0.05068040266633034 loss\n","Epoch 2, Batch 66: 0.0413268506526947 loss\n","Epoch 2, Batch 67: 0.025473054498434067 loss\n","Epoch 2, Batch 68: 0.08416860550642014 loss\n","Epoch 2, Batch 69: 0.03622196242213249 loss\n","Epoch 2, Batch 70: 0.07153861969709396 loss\n","Epoch 2, Batch 71: 0.046543072909116745 loss\n","Epoch 2, Batch 72: 0.07095704972743988 loss\n","Epoch 2, Batch 73: 0.05160095542669296 loss\n","Epoch 2, Batch 74: 0.07380834221839905 loss\n","Epoch 2, Batch 75: 0.0767812430858612 loss\n","Epoch 2, Batch 76: 0.022708427160978317 loss\n","Epoch 2, Batch 77: 0.0651111751794815 loss\n","Epoch 2, Batch 78: 0.02964596450328827 loss\n","Epoch 2, Batch 79: 0.05888465791940689 loss\n","Epoch 2, Batch 80: 0.05696699768304825 loss\n","Epoch 2, Batch 81: 0.03853132203221321 loss\n","Epoch 2, Batch 82: 0.056927118450403214 loss\n","Epoch 2, Batch 83: 0.045865364372730255 loss\n","Epoch 2, Batch 84: 0.041760530322790146 loss\n","Epoch 2, Batch 85: 0.03386758640408516 loss\n","Epoch 2, Batch 86: 0.01891486346721649 loss\n","Epoch 2, Batch 87: 0.0705670639872551 loss\n","Epoch 2, Batch 88: 0.03562122583389282 loss\n","Epoch 2, Batch 89: 0.030993973836302757 loss\n","Epoch 2, Batch 90: 0.07045041769742966 loss\n","Epoch 2, Batch 91: 0.0543430894613266 loss\n","Epoch 2, Batch 92: 0.03156387805938721 loss\n","Epoch 2, Batch 93: 0.08722434937953949 loss\n","Epoch 2, Batch 94: 0.047619856894016266 loss\n","Epoch 2, Batch 95: 0.0457100048661232 loss\n","Epoch 2, Batch 96: 0.06625449657440186 loss\n","Epoch 2, Batch 97: 0.03500930964946747 loss\n","Epoch 2, Batch 98: 0.047290682792663574 loss\n","Epoch 2, Batch 99: 0.025965102016925812 loss\n","Epoch 2, Batch 100: 0.11628667265176773 loss\n","Epoch 2, Batch 101: 0.04049938544631004 loss\n","Epoch 2, Batch 102: 0.060993026942014694 loss\n","Epoch 2, Batch 103: 0.0719882994890213 loss\n","Epoch 2, Batch 104: 0.039392925798892975 loss\n","Epoch 2, Batch 105: 0.036778174340724945 loss\n","Epoch 2, Batch 106: 0.055817291140556335 loss\n","Epoch 2, Batch 107: 0.04474453255534172 loss\n","Epoch 2, Batch 108: 0.1554693728685379 loss\n","Epoch 2, Batch 109: 0.0518014095723629 loss\n","Epoch 2, Batch 110: 0.043873392045497894 loss\n","Epoch 2, Batch 111: 0.034394096583127975 loss\n","Epoch 2, Batch 112: 0.036829348653554916 loss\n","Epoch 2, Batch 113: 0.04016142711043358 loss\n","Epoch 2, Batch 114: 0.03871031478047371 loss\n","Epoch 2, Batch 115: 0.042386170476675034 loss\n","Epoch 2, Batch 116: 0.046113528311252594 loss\n","Epoch 2, Batch 117: 0.046937234699726105 loss\n","Epoch 2, Batch 118: 0.010744712315499783 loss\n","Epoch 2, Batch 119: 0.10105525702238083 loss\n","Epoch 2, Batch 120: 0.07933361083269119 loss\n","Epoch 2, Batch 121: 0.023991571739315987 loss\n","Epoch 2, Batch 122: 0.057341236621141434 loss\n","Epoch 2, Batch 123: 0.02367919683456421 loss\n","Epoch 2, Batch 124: 0.0769570991396904 loss\n","Epoch 2, Batch 125: 0.019038625061511993 loss\n","Epoch 2, Batch 126: 0.0440058670938015 loss\n","Epoch 2, Batch 127: 0.05517852306365967 loss\n","Epoch 2, Batch 128: 0.053951896727085114 loss\n","Epoch 2, Batch 129: 0.03269213065505028 loss\n","Epoch 2, Batch 130: 0.06135045364499092 loss\n","Epoch 2, Batch 131: 0.0414130762219429 loss\n","Epoch 2, Batch 132: 0.030650971457362175 loss\n","Epoch 2, Batch 133: 0.08825039863586426 loss\n","Epoch 2, Batch 134: 0.09470368176698685 loss\n","Epoch 2, Batch 135: 0.03440754860639572 loss\n","Epoch 2, Batch 136: 0.04895647242665291 loss\n","Epoch 2, Batch 137: 0.041024789214134216 loss\n","Epoch 2, Batch 138: 0.018956515938043594 loss\n","Epoch 2, Batch 139: 0.03639055788516998 loss\n","Epoch 2, Batch 140: 0.04117412120103836 loss\n","Epoch 2, Batch 141: 0.04082254320383072 loss\n","Epoch 2, Batch 142: 0.02443901263177395 loss\n","Epoch 2, Batch 143: 0.046259794384241104 loss\n","Epoch 2, Batch 144: 0.04589984565973282 loss\n","Epoch 2, Batch 145: 0.049496594816446304 loss\n","Epoch 2, Batch 146: 0.12364380061626434 loss\n","Epoch 2, Batch 147: 0.05394439399242401 loss\n","Epoch 2, Batch 148: 0.10057955235242844 loss\n","Epoch 2, Batch 149: 0.030339887365698814 loss\n","Epoch 2, Batch 150: 0.08591228723526001 loss\n","Epoch 2, Batch 151: 0.04394185170531273 loss\n","Epoch 2, Batch 152: 0.03677969425916672 loss\n","Epoch 2, Batch 153: 0.04700915887951851 loss\n","Epoch 2, Batch 154: 0.04657750949263573 loss\n","Epoch 2, Batch 155: 0.02672635205090046 loss\n","Epoch 2, Batch 156: 0.03337327390909195 loss\n","Epoch 2, Batch 157: 0.038200341165065765 loss\n","Epoch 2, Batch 158: 0.08810006082057953 loss\n","Epoch 2, Batch 159: 0.11999137699604034 loss\n","Epoch 2, Batch 160: 0.03611832857131958 loss\n","Epoch 2, Batch 161: 0.054698508232831955 loss\n","Epoch 2, Batch 162: 0.04255729168653488 loss\n","Epoch 2, Batch 163: 0.06364589929580688 loss\n","Epoch 2, Batch 164: 0.03666253760457039 loss\n","Epoch 2, Batch 165: 0.05033748224377632 loss\n","Epoch 2, Batch 166: 0.07381032407283783 loss\n","Epoch 2, Batch 167: 0.04258027300238609 loss\n","Epoch 2, Batch 168: 0.09954701364040375 loss\n","Epoch 2, Batch 169: 0.0519762821495533 loss\n","Epoch 2, Batch 170: 0.05689529702067375 loss\n","Epoch 2, Batch 171: 0.030059246346354485 loss\n","Epoch 2, Batch 172: 0.059433069080114365 loss\n","Epoch 2, Batch 173: 0.07650939375162125 loss\n","Epoch 2, Batch 174: 0.054507676512002945 loss\n","Epoch 2, Batch 175: 0.0284475926309824 loss\n","Epoch 2, Batch 176: 0.029604896903038025 loss\n","Epoch 2, Batch 177: 0.05279417708516121 loss\n","Epoch 2, Batch 178: 0.04240782931447029 loss\n","Epoch 2, Batch 179: 0.05194547027349472 loss\n","Epoch 2, Batch 180: 0.056681662797927856 loss\n","Epoch 2, Batch 181: 0.025066887959837914 loss\n","Epoch 2, Batch 182: 0.03323282301425934 loss\n","Epoch 2, Batch 183: 0.04597518965601921 loss\n","Epoch 2, Batch 184: 0.07070782035589218 loss\n","Epoch 2, Batch 185: 0.08997765928506851 loss\n","Epoch 2, Batch 186: 0.029325095936655998 loss\n","Epoch 2, Batch 187: 0.04970033839344978 loss\n","Epoch 2, Batch 188: 0.11008667945861816 loss\n","Epoch 2, Batch 189: 0.06903138756752014 loss\n","Epoch 2, Batch 190: 0.09577158093452454 loss\n","Epoch 2, Batch 191: 0.04932887852191925 loss\n","Epoch 2, Batch 192: 0.10250981152057648 loss\n","Epoch 2, Batch 193: 0.05086331441998482 loss\n","Epoch 2, Batch 194: 0.050254374742507935 loss\n","Epoch 2, Batch 195: 0.06180986389517784 loss\n","Epoch 2, Batch 196: 0.04164285957813263 loss\n","Epoch 2, Batch 197: 0.04824761673808098 loss\n","Epoch 2, Batch 198: 0.060987260192632675 loss\n","Epoch 2, Batch 199: 0.02965918369591236 loss\n","Epoch 2, Batch 200: 0.0694795772433281 loss\n","Epoch 2, Batch 201: 0.05392508581280708 loss\n","Epoch 2, Batch 202: 0.04227360337972641 loss\n","Epoch 2, Batch 203: 0.015034903772175312 loss\n","Epoch 2, Batch 204: 0.0759895071387291 loss\n","Epoch 2, Batch 205: 0.02072286419570446 loss\n","Epoch 2, Batch 206: 0.063042052090168 loss\n","Epoch 2, Batch 207: 0.022294525057077408 loss\n","Epoch 2, Batch 208: 0.018928905948996544 loss\n","Epoch 2, Batch 209: 0.051697175949811935 loss\n","Epoch 2, Batch 210: 0.03489504009485245 loss\n","Epoch 2, Batch 211: 0.12268334627151489 loss\n","Epoch 2, Batch 212: 0.0798613578081131 loss\n","Epoch 2, Batch 213: 0.07412277162075043 loss\n","Epoch 2, Batch 214: 0.02627890557050705 loss\n","Epoch 2, Batch 215: 0.06235402077436447 loss\n","Epoch 2, Batch 216: 0.04716645926237106 loss\n","Epoch 2, Batch 217: 0.04869440570473671 loss\n","Epoch 2, Batch 218: 0.06562645733356476 loss\n","Epoch 2, Batch 219: 0.02539079450070858 loss\n","Epoch 2, Batch 220: 0.05441742762923241 loss\n","Epoch 2, Batch 221: 0.06969192624092102 loss\n","Epoch 2, Batch 222: 0.0552000030875206 loss\n","Epoch 2, Batch 223: 0.04521295055747032 loss\n","Epoch 2, Batch 224: 0.03255141153931618 loss\n","Epoch 2, Batch 225: 0.029009701684117317 loss\n","Epoch 2, Batch 226: 0.038890354335308075 loss\n","Epoch 2, Batch 227: 0.0611301027238369 loss\n","Epoch 2, Batch 228: 0.031041355803608894 loss\n","Epoch 2, Batch 229: 0.0647725909948349 loss\n","Epoch 2, Batch 230: 0.05109873786568642 loss\n","Epoch 2, Batch 231: 0.06037886440753937 loss\n","Epoch 2, Batch 232: 0.02618437260389328 loss\n","Epoch 2, Batch 233: 0.04743316024541855 loss\n","Epoch 2, Batch 234: 0.06827761232852936 loss\n","Epoch 2, Batch 235: 0.03249567747116089 loss\n","Epoch 2, Batch 236: 0.036211658269166946 loss\n","Epoch 2, Batch 237: 0.07624353468418121 loss\n","Epoch 2, Batch 238: 0.04175647348165512 loss\n","Epoch 2, Batch 239: 0.06939543038606644 loss\n","Epoch 2, Batch 240: 0.053284868597984314 loss\n","Epoch 2, Batch 241: 0.059711702167987823 loss\n","Epoch 2, Batch 242: 0.029211603105068207 loss\n","Epoch 2, Batch 243: 0.018512897193431854 loss\n","Epoch 2, Batch 244: 0.05329369753599167 loss\n","Epoch 2, Batch 245: 0.038351476192474365 loss\n","Epoch 2, Batch 246: 0.0671125277876854 loss\n","Epoch 2, Batch 247: 0.04877951741218567 loss\n","Epoch 2, Batch 248: 0.03971787169575691 loss\n","Epoch 2, Batch 249: 0.08804719895124435 loss\n","Epoch 2, Batch 250: 0.056880589574575424 loss\n","Epoch 2, Batch 251: 0.06799695640802383 loss\n","Epoch 2, Batch 252: 0.03483261168003082 loss\n","Epoch 2, Batch 253: 0.06629341095685959 loss\n","Epoch 2, Batch 254: 0.031903255730867386 loss\n","Epoch 2, Batch 255: 0.04353330656886101 loss\n","Epoch 2, Batch 256: 0.051978643983602524 loss\n","Epoch 2, Batch 257: 0.0358244888484478 loss\n","Epoch 2, Batch 258: 0.0349535197019577 loss\n","Epoch 2, Batch 259: 0.03477038815617561 loss\n","Epoch 2, Batch 260: 0.03741054609417915 loss\n","Epoch 2, Batch 261: 0.07107607275247574 loss\n","Epoch 2, Batch 262: 0.04105458781123161 loss\n","Epoch 2, Batch 263: 0.03700083866715431 loss\n","Epoch 2, Batch 264: 0.07619623839855194 loss\n","Epoch 2, Batch 265: 0.04284900799393654 loss\n","Epoch 2, Batch 266: 0.023785842582583427 loss\n","Epoch 2, Batch 267: 0.050205763429403305 loss\n","Epoch 2, Batch 268: 0.04319876804947853 loss\n","Epoch 2, Batch 269: 0.040043529123067856 loss\n","Epoch 2, Batch 270: 0.07445114105939865 loss\n","Epoch 2, Batch 271: 0.08068643510341644 loss\n","Epoch 2, Batch 272: 0.05971590429544449 loss\n","Epoch 2, Batch 273: 0.061454955488443375 loss\n","Epoch 2, Batch 274: 0.04167543351650238 loss\n","Epoch 2, Batch 275: 0.03613042086362839 loss\n","Epoch 2, Batch 276: 0.10741696506738663 loss\n","Epoch 2, Batch 277: 0.09790714830160141 loss\n","Epoch 2, Batch 278: 0.04777089133858681 loss\n","Epoch 2, Batch 279: 0.02652106061577797 loss\n","Epoch 2, Batch 280: 0.11201029270887375 loss\n","Epoch 2, Batch 281: 0.07505946606397629 loss\n","Epoch 2, Batch 282: 0.04637124761939049 loss\n","Epoch 2, Batch 283: 0.05434945970773697 loss\n","Epoch 2, Batch 284: 0.046207234263420105 loss\n","Epoch 2, Batch 285: 0.06312867999076843 loss\n","Epoch 2, Batch 286: 0.08146294206380844 loss\n","Epoch 2, Batch 287: 0.04585504159331322 loss\n","Epoch 2, Batch 288: 0.061404112726449966 loss\n","Epoch 2, Batch 289: 0.016531052067875862 loss\n","Epoch 2, Batch 290: 0.02366805262863636 loss\n","Epoch 2, Batch 291: 0.03290984779596329 loss\n","Epoch 2, Batch 292: 0.056538913398981094 loss\n","Epoch 2, Batch 293: 0.042770229279994965 loss\n","Epoch 2, Batch 294: 0.03933661803603172 loss\n","Epoch 2, Batch 295: 0.06385579705238342 loss\n","Epoch 2, Batch 296: 0.06676647812128067 loss\n","Epoch 2, Batch 297: 0.04489976540207863 loss\n","Epoch 2, Batch 298: 0.03187817335128784 loss\n","Epoch 2, Batch 299: 0.024828169494867325 loss\n","Epoch 2, Batch 300: 0.05650448426604271 loss\n","Epoch 2, Batch 301: 0.028747588396072388 loss\n","Epoch 2, Batch 302: 0.04599825292825699 loss\n","Epoch 2, Batch 303: 0.03405417129397392 loss\n","Epoch 2, Batch 304: 0.03314775601029396 loss\n","Epoch 2, Batch 305: 0.07484667748212814 loss\n","Epoch 2, Batch 306: 0.09267589449882507 loss\n","Epoch 2, Batch 307: 0.07214769721031189 loss\n","Epoch 2, Batch 308: 0.03831073269248009 loss\n","Epoch 2, Batch 309: 0.028349919244647026 loss\n","Epoch 2, Batch 310: 0.049469318240880966 loss\n","Epoch 2, Batch 311: 0.04538678005337715 loss\n","Epoch 2, Batch 312: 0.08268437534570694 loss\n","Epoch 2, Batch 313: 0.07121401280164719 loss\n","Epoch 2, Batch 314: 0.036333221942186356 loss\n","Epoch 2, Batch 315: 0.11649986356496811 loss\n","Epoch 2, Batch 316: 0.017994925379753113 loss\n","Epoch 2, Batch 317: 0.07880834490060806 loss\n","Epoch 2, Batch 318: 0.07153478264808655 loss\n","Epoch 2, Batch 319: 0.032198742032051086 loss\n","Epoch 2, Batch 320: 0.022622497752308846 loss\n","Epoch 2, Batch 321: 0.032607629895210266 loss\n","Epoch 2, Batch 322: 0.062480680644512177 loss\n","Epoch 2, Batch 323: 0.05540916696190834 loss\n","Epoch 2, Batch 324: 0.041759781539440155 loss\n","Epoch 2, Batch 325: 0.06101738661527634 loss\n","Epoch 2, Batch 326: 0.038377728313207626 loss\n","Epoch 2, Batch 327: 0.025052104145288467 loss\n","Epoch 2, Batch 328: 0.040150463581085205 loss\n","Epoch 2, Batch 329: 0.03156643360853195 loss\n","Epoch 2, Batch 330: 0.07786349207162857 loss\n","Epoch 2, Batch 331: 0.06169142946600914 loss\n","Epoch 2, Batch 332: 0.04459405690431595 loss\n","Epoch 2, Batch 333: 0.06048136577010155 loss\n","Epoch 2, Batch 334: 0.038944367319345474 loss\n","Epoch 2, Batch 335: 0.06846394389867783 loss\n","Epoch 2, Batch 336: 0.07564760744571686 loss\n","Epoch 2, Batch 337: 0.08217835426330566 loss\n","Epoch 2, Batch 338: 0.06498678773641586 loss\n","Epoch 2, Batch 339: 0.03157314285635948 loss\n","Epoch 2, Batch 340: 0.09127095341682434 loss\n","Epoch 2, Batch 341: 0.03087686002254486 loss\n","Epoch 2, Batch 342: 0.05666668340563774 loss\n","Epoch 2, Batch 343: 0.06160212308168411 loss\n","Epoch 2, Batch 344: 0.05077937990427017 loss\n","Epoch 2, Batch 345: 0.0684836134314537 loss\n","Epoch 2, Batch 346: 0.06366246938705444 loss\n","Epoch 2, Batch 347: 0.03301747515797615 loss\n","Epoch 2, Batch 348: 0.03802382946014404 loss\n","Epoch 2, Batch 349: 0.06387551128864288 loss\n","Epoch 2, Batch 350: 0.02807215228676796 loss\n","Epoch 2, Batch 351: 0.02271929755806923 loss\n","Epoch 2, Batch 352: 0.051757343113422394 loss\n","Epoch 2, Batch 353: 0.05733903497457504 loss\n","Epoch 2, Batch 354: 0.046872664242982864 loss\n","Epoch 2, Batch 355: 0.07050490379333496 loss\n","Epoch 2, Batch 356: 0.07842736691236496 loss\n","Epoch 2, Batch 357: 0.027472466230392456 loss\n","Epoch 2, Batch 358: 0.06657905876636505 loss\n","Epoch 2, Batch 359: 0.019817424938082695 loss\n","Epoch 2, Batch 360: 0.0696505457162857 loss\n","Epoch 2, Batch 361: 0.05404597893357277 loss\n","Epoch 2, Batch 362: 0.045042794197797775 loss\n","Epoch 2, Batch 363: 0.037068359553813934 loss\n","Epoch 2, Batch 364: 0.047003138810396194 loss\n","Epoch 2, Batch 365: 0.03240198642015457 loss\n","Epoch 2, Batch 366: 0.08035985380411148 loss\n","Epoch 2, Batch 367: 0.01948544755578041 loss\n","Epoch 2, Batch 368: 0.06138642877340317 loss\n","Epoch 2, Batch 369: 0.06951719522476196 loss\n","Epoch 2, Batch 370: 0.05728268250823021 loss\n","Epoch 2, Batch 371: 0.03179233521223068 loss\n","Epoch 2, Batch 372: 0.009609818458557129 loss\n","Epoch 2, Batch 373: 0.03130841255187988 loss\n","Epoch 2, Batch 374: 0.026325874030590057 loss\n","Epoch 2, Batch 375: 0.03654353693127632 loss\n","Epoch 2, Batch 376: 0.0251143891364336 loss\n","Epoch 2, Batch 377: 0.03498813882470131 loss\n","Epoch 2, Batch 378: 0.06036113202571869 loss\n","Epoch 2, Batch 379: 0.04218760505318642 loss\n","Epoch 2, Batch 380: 0.06073850765824318 loss\n","Epoch 2, Batch 381: 0.03880004212260246 loss\n","Epoch 2, Batch 382: 0.03210262581706047 loss\n","Epoch 2, Batch 383: 0.04594866931438446 loss\n","Epoch 2, Batch 384: 0.06248035281896591 loss\n","Epoch 2, Batch 385: 0.09861432760953903 loss\n","Epoch 2, Batch 386: 0.06856974959373474 loss\n","Epoch 2, Batch 387: 0.0450005903840065 loss\n","Epoch 2, Batch 388: 0.053231142461299896 loss\n","Epoch 2, Batch 389: 0.03946651518344879 loss\n","Epoch 2, Batch 390: 0.05254377797245979 loss\n","Epoch 2, Batch 391: 0.06628120690584183 loss\n","Epoch 2, Batch 392: 0.05233503878116608 loss\n","Epoch 2, Batch 393: 0.0483400858938694 loss\n","Epoch 2, Batch 394: 0.041699010878801346 loss\n","Epoch 2, Batch 395: 0.049725234508514404 loss\n","Epoch 2, Batch 396: 0.04595014452934265 loss\n","Epoch 2, Batch 397: 0.050871510058641434 loss\n","Epoch 2, Batch 398: 0.0388403981924057 loss\n","Epoch 2, Batch 399: 0.0788673534989357 loss\n","Epoch 2, Batch 400: 0.02965756691992283 loss\n","Epoch 2, Batch 401: 0.04940605163574219 loss\n","Epoch 2, Batch 402: 0.08956107497215271 loss\n","Epoch 2, Batch 403: 0.044453684240579605 loss\n","Epoch 2, Batch 404: 0.03492086008191109 loss\n","Epoch 2, Batch 405: 0.05596761032938957 loss\n","Epoch 2, Batch 406: 0.02249704860150814 loss\n","Epoch 2, Batch 407: 0.04768385365605354 loss\n","Epoch 2, Batch 408: 0.028114182874560356 loss\n","Epoch 2, Batch 409: 0.04231952875852585 loss\n","Epoch 2, Batch 410: 0.11250440031290054 loss\n","Epoch 2, Batch 411: 0.03580782562494278 loss\n","Epoch 2, Batch 412: 0.057774145156145096 loss\n","Epoch 2, Batch 413: 0.0385807603597641 loss\n","Epoch 2, Batch 414: 0.03390645235776901 loss\n","Epoch 2, Batch 415: 0.02931569516658783 loss\n","Epoch 2, Batch 416: 0.05521820858120918 loss\n","Epoch 2, Batch 417: 0.022421948611736298 loss\n","Epoch 2, Batch 418: 0.03547978028655052 loss\n","Epoch 2, Batch 419: 0.023502783849835396 loss\n","Epoch 2, Batch 420: 0.024868028238415718 loss\n","Epoch 2, Batch 421: 0.0599578358232975 loss\n","Epoch 2, Batch 422: 0.021344125270843506 loss\n","Epoch 2, Batch 423: 0.027512991800904274 loss\n","Epoch 2, Batch 424: 0.05809821933507919 loss\n","Epoch 2, Batch 425: 0.055058207362890244 loss\n","Epoch 2, Batch 426: 0.0398569218814373 loss\n","Epoch 2, Batch 427: 0.05507250502705574 loss\n","Epoch 2, Batch 428: 0.043568190187215805 loss\n","Epoch 2, Batch 429: 0.06026845797896385 loss\n","Epoch 2, Batch 430: 0.051003050059080124 loss\n","Epoch 2, Batch 431: 0.04657552391290665 loss\n","Epoch 2, Batch 432: 0.0837915688753128 loss\n","Epoch 2, Batch 433: 0.08509540557861328 loss\n","Epoch 2, Batch 434: 0.05792878568172455 loss\n","Epoch 2, Batch 435: 0.061466146260499954 loss\n","Epoch 2, Batch 436: 0.04494957625865936 loss\n","Epoch 2, Batch 437: 0.03838582709431648 loss\n","Epoch 2, Batch 438: 0.030015313997864723 loss\n","Epoch 2, Batch 439: 0.04628545418381691 loss\n","Epoch 2, Batch 440: 0.15467165410518646 loss\n","Epoch 2, Batch 441: 0.048014409840106964 loss\n","Epoch 2, Batch 442: 0.04084645211696625 loss\n","Epoch 2, Batch 443: 0.038864217698574066 loss\n","Epoch 2, Batch 444: 0.04791216179728508 loss\n","Epoch 2, Batch 445: 0.029337454587221146 loss\n","Epoch 2, Batch 446: 0.05280953273177147 loss\n","Epoch 2, Batch 447: 0.1041460782289505 loss\n","Epoch 2, Batch 448: 0.052181828767061234 loss\n","Epoch 2, Batch 449: 0.06045595556497574 loss\n","Epoch 2, Batch 450: 0.025252733379602432 loss\n","Epoch 2, Batch 451: 0.03628147765994072 loss\n","Epoch 2, Batch 452: 0.038656722754240036 loss\n","Epoch 2, Batch 453: 0.04464782774448395 loss\n","Epoch 2, Batch 454: 0.036683615297079086 loss\n","Epoch 2, Batch 455: 0.057345498353242874 loss\n","Epoch 2, Batch 456: 0.032972343266010284 loss\n","Epoch 2, Batch 457: 0.049769919365644455 loss\n","Epoch 2, Batch 458: 0.02995801344513893 loss\n","Epoch 2, Batch 459: 0.06816346198320389 loss\n","Epoch 2, Batch 460: 0.07394502311944962 loss\n","Epoch 2, Batch 461: 0.06669697910547256 loss\n","Epoch 2, Batch 462: 0.06565150618553162 loss\n","Epoch 2, Batch 463: 0.08367276936769485 loss\n","Epoch 2, Batch 464: 0.04483358934521675 loss\n","Epoch 2, Batch 465: 0.07077249139547348 loss\n","Epoch 2, Batch 466: 0.04420211911201477 loss\n","Epoch 2, Batch 467: 0.2268480509519577 loss\n","Epoch 2, Batch 468: 0.057677268981933594 loss\n","Epoch 2, Batch 469: 0.04982397332787514 loss\n","Epoch 2, Batch 470: 0.02814285270869732 loss\n","Epoch 2, Batch 471: 0.03646785765886307 loss\n","Epoch 2, Batch 472: 0.022047579288482666 loss\n","Epoch 2, Batch 473: 0.024488504976034164 loss\n","Epoch 2, Batch 474: 0.06718403846025467 loss\n","Epoch 2, Batch 475: 0.05085914209485054 loss\n","Epoch 2, Batch 476: 0.03349507972598076 loss\n","Epoch 2, Batch 477: 0.045131783932447433 loss\n","Epoch 2, Batch 478: 0.02894747629761696 loss\n","Epoch 2, Batch 479: 0.04952927678823471 loss\n","Epoch 2, Batch 480: 0.03713561221957207 loss\n","Epoch 2, Batch 481: 0.030102726072072983 loss\n","Epoch 2, Batch 482: 0.018745670095086098 loss\n","Epoch 2, Batch 483: 0.10842464864253998 loss\n","Epoch 2, Batch 484: 0.027439283207058907 loss\n","Epoch 2, Batch 485: 0.02997840754687786 loss\n","Epoch 2, Batch 486: 0.0352218858897686 loss\n","Epoch 2, Batch 487: 0.04375586286187172 loss\n","Epoch 2, Batch 488: 0.04593443125486374 loss\n","Epoch 2, Batch 489: 0.06015613302588463 loss\n","Epoch 2, Batch 490: 0.031906578689813614 loss\n","Epoch 2, Batch 491: 0.04763622209429741 loss\n","Epoch 2, Batch 492: 0.07017478346824646 loss\n","Epoch 2, Batch 493: 0.03006659261882305 loss\n","Epoch 2, Batch 494: 0.04158017784357071 loss\n","Epoch 2, Batch 495: 0.08997691422700882 loss\n","Epoch 2, Batch 496: 0.05657247453927994 loss\n","Epoch 2, Batch 497: 0.05800842493772507 loss\n","Epoch 2, Batch 498: 0.04623386636376381 loss\n","Epoch 2, Batch 499: 0.05387498810887337 loss\n","Epoch 2, Batch 500: 0.06262687593698502 loss\n","Epoch 2, Batch 501: 0.030579810962080956 loss\n","Epoch 2, Batch 502: 0.060274988412857056 loss\n","Epoch 2, Batch 503: 0.02975073643028736 loss\n","Epoch 2, Batch 504: 0.05050157010555267 loss\n","Epoch 2, Batch 505: 0.04141773283481598 loss\n","Epoch 2, Batch 506: 0.0570644736289978 loss\n","Epoch 2, Batch 507: 0.052927106618881226 loss\n","Epoch 2, Batch 508: 0.05838222801685333 loss\n","Epoch 2, Batch 509: 0.06545761972665787 loss\n","Epoch 2, Batch 510: 0.028135163709521294 loss\n","Epoch 2, Batch 511: 0.04757286235690117 loss\n","Epoch 2, Batch 512: 0.02794436551630497 loss\n","Epoch 2, Batch 513: 0.050209153443574905 loss\n","Epoch 2, Batch 514: 0.020014343783259392 loss\n","Epoch 2, Batch 515: 0.013397542759776115 loss\n","Epoch 2, Batch 516: 0.045146722346544266 loss\n","Epoch 2, Batch 517: 0.02363596111536026 loss\n","Epoch 2, Batch 518: 0.06300853937864304 loss\n","Epoch 2, Batch 519: 0.053366269916296005 loss\n","Epoch 2, Batch 520: 0.05399934574961662 loss\n","Epoch 2, Batch 521: 0.061753351241350174 loss\n","Epoch 2, Batch 522: 0.04746028035879135 loss\n","Epoch 2, Batch 523: 0.0827995166182518 loss\n","Epoch 2, Batch 524: 0.02199511043727398 loss\n","Epoch 2, Batch 525: 0.04872261360287666 loss\n","Epoch 2, Batch 526: 0.028077296912670135 loss\n","Epoch 2, Batch 527: 0.032352644950151443 loss\n","Epoch 2, Batch 528: 0.07656912505626678 loss\n","Epoch 2, Batch 529: 0.038469210267066956 loss\n","Epoch 2, Batch 530: 0.06303297728300095 loss\n","Epoch 2, Batch 531: 0.04021764546632767 loss\n","Epoch 2, Batch 532: 0.04517912119626999 loss\n","Epoch 2, Batch 533: 0.04233109951019287 loss\n","Epoch 2, Batch 534: 0.06136288121342659 loss\n","Epoch 2, Batch 535: 0.05309564247727394 loss\n","Epoch 2, Batch 536: 0.04514171928167343 loss\n","Epoch 2, Batch 537: 0.03303152695298195 loss\n","Epoch 2, Batch 538: 0.03723699972033501 loss\n","Epoch 2, Batch 539: 0.031109925359487534 loss\n","Epoch 2, Batch 540: 0.061266954988241196 loss\n","Epoch 2, Batch 541: 0.06538096815347672 loss\n","Epoch 2, Batch 542: 0.07404404133558273 loss\n","Epoch 2, Batch 543: 0.0482950434088707 loss\n","Epoch 2, Batch 544: 0.04875722900032997 loss\n","Epoch 2, Batch 545: 0.05419478937983513 loss\n","Epoch 2, Batch 546: 0.05472160875797272 loss\n","Epoch 2, Batch 547: 0.024607481434941292 loss\n","Epoch 2, Batch 548: 0.051257357001304626 loss\n","Epoch 2, Batch 549: 0.051568277180194855 loss\n","Epoch 2, Batch 550: 0.04962865263223648 loss\n","Epoch 2, Batch 551: 0.04272232949733734 loss\n","Epoch 2, Batch 552: 0.015213419683277607 loss\n","Epoch 2, Batch 553: 0.053049709647893906 loss\n","Epoch 2, Batch 554: 0.1493677794933319 loss\n","Epoch 2, Batch 555: 0.039610136300325394 loss\n","Epoch 2, Batch 556: 0.04298117011785507 loss\n","Epoch 2, Batch 557: 0.035485077649354935 loss\n","Epoch 2, Batch 558: 0.049895092844963074 loss\n","Epoch 2, Batch 559: 0.0625152662396431 loss\n","Epoch 2, Batch 560: 0.05065681412816048 loss\n","Epoch 2, Batch 561: 0.09214852750301361 loss\n","Epoch 2, Batch 562: 0.042739272117614746 loss\n","Epoch 2, Batch 563: 0.04589637368917465 loss\n","Epoch 2, Batch 564: 0.06829123198986053 loss\n","Epoch 2, Batch 565: 0.05425698682665825 loss\n","Epoch 2, Batch 566: 0.02468854933977127 loss\n","Epoch 2, Batch 567: 0.033815786242485046 loss\n","Epoch 2, Batch 568: 0.1087171733379364 loss\n","Epoch 2, Batch 569: 0.0638585239648819 loss\n","Epoch 2, Batch 570: 0.06476365774869919 loss\n","Epoch 2, Batch 571: 0.04127321019768715 loss\n","Epoch 2, Batch 572: 0.047229547053575516 loss\n","Epoch 2, Batch 573: 0.043385956436395645 loss\n","Epoch 2, Batch 574: 0.07508707791566849 loss\n","Epoch 2, Batch 575: 0.036615040153265 loss\n","Epoch 2, Batch 576: 0.1026875227689743 loss\n","Epoch 2, Batch 577: 0.07279496639966965 loss\n","Epoch 2, Batch 578: 0.050576772540807724 loss\n","Epoch 2, Batch 579: 0.05561060830950737 loss\n","Epoch 2, Batch 580: 0.049839578568935394 loss\n","Epoch 2, Batch 581: 0.04037584736943245 loss\n","Epoch 2, Batch 582: 0.02034967578947544 loss\n","Epoch 2, Batch 583: 0.018029147759079933 loss\n","Epoch 2, Batch 584: 0.018903004005551338 loss\n","Epoch 2, Batch 585: 0.039280932396650314 loss\n","Epoch 2, Batch 586: 0.04949381947517395 loss\n","Epoch 2, Batch 587: 0.05216255038976669 loss\n","Epoch 2, Batch 588: 0.01547849178314209 loss\n","Epoch 2, Batch 589: 0.04055887833237648 loss\n","Epoch 2, Batch 590: 0.07027153670787811 loss\n","Epoch 2, Batch 591: 0.024326566606760025 loss\n","Epoch 2, Batch 592: 0.13022851943969727 loss\n","Epoch 2, Batch 593: 0.027920695021748543 loss\n","Epoch 2, Batch 594: 0.03520369529724121 loss\n","Epoch 2, Batch 595: 0.023481078445911407 loss\n","Epoch 2, Batch 596: 0.03951577469706535 loss\n","Epoch 2, Batch 597: 0.0440499372780323 loss\n","Epoch 2, Batch 598: 0.03907962515950203 loss\n","Epoch 2, Batch 599: 0.03598109632730484 loss\n","Epoch 2, Batch 600: 0.03619954362511635 loss\n","Epoch 2, Batch 601: 0.03616844117641449 loss\n","Epoch 2, Batch 602: 0.061602964997291565 loss\n","Epoch 2, Batch 603: 0.028156651183962822 loss\n","Epoch 2, Batch 604: 0.06521456688642502 loss\n","Epoch 2, Batch 605: 0.025890210643410683 loss\n","Epoch 2, Batch 606: 0.07281789928674698 loss\n","Epoch 2, Batch 607: 0.07585463672876358 loss\n","Epoch 2, Batch 608: 0.056753870099782944 loss\n","Epoch 2, Batch 609: 0.04942678287625313 loss\n","Epoch 2, Batch 610: 0.08731724321842194 loss\n","Epoch 2, Batch 611: 0.03970910981297493 loss\n","Epoch 2, Batch 612: 0.052596647292375565 loss\n","Epoch 2, Batch 613: 0.028807658702135086 loss\n","Epoch 2, Batch 614: 0.054775141179561615 loss\n","Epoch 2, Batch 615: 0.09107759594917297 loss\n","Epoch 2, Batch 616: 0.048750996589660645 loss\n","Epoch 2, Batch 617: 0.06630030274391174 loss\n","Epoch 2, Batch 618: 0.03835408762097359 loss\n","Epoch 2, Batch 619: 0.04172193631529808 loss\n","Epoch 2, Batch 620: 0.04437252879142761 loss\n","Epoch 2, Batch 621: 0.028755076229572296 loss\n","Epoch 2, Batch 622: 0.03488938510417938 loss\n","Epoch 2, Batch 623: 0.036599673330783844 loss\n","Epoch 2, Batch 624: 0.041558533906936646 loss\n","Epoch 2, Batch 625: 0.024068158119916916 loss\n","Epoch 2, Batch 626: 0.08928778767585754 loss\n","Epoch 2, Batch 627: 0.02365030348300934 loss\n","Epoch 2, Batch 628: 0.09195343405008316 loss\n","Epoch 2, Batch 629: 0.029941286891698837 loss\n","Epoch 2, Batch 630: 0.06724950671195984 loss\n","Epoch 2, Batch 631: 0.03134814277291298 loss\n","Epoch 2, Batch 632: 0.03775330260396004 loss\n","Epoch 2, Batch 633: 0.0213908813893795 loss\n","Epoch 2, Batch 634: 0.0453609824180603 loss\n","Epoch 2, Batch 635: 0.06518284976482391 loss\n","Epoch 2, Batch 636: 0.04802718386054039 loss\n","Epoch 2, Batch 637: 0.024058902636170387 loss\n","Epoch 2, Batch 638: 0.24692562222480774 loss\n","Predicting batch 1\n","Predicting batch 2\n","Predicting batch 3\n","Predicting batch 4\n","Predicting batch 5\n","Predicting batch 6\n","Predicting batch 7\n","Predicting batch 8\n","Predicting batch 9\n","Predicting batch 10\n","Predicting batch 11\n","Predicting batch 12\n","Predicting batch 13\n","Predicting batch 14\n","Predicting batch 15\n","Predicting batch 16\n","Predicting batch 17\n","Predicting batch 18\n","Predicting batch 19\n","Predicting batch 20\n","Predicting batch 21\n","Predicting batch 22\n","Predicting batch 23\n","Predicting batch 24\n","Predicting batch 25\n","Predicting batch 26\n","Predicting batch 27\n","Predicting batch 28\n","Predicting batch 29\n","Predicting batch 30\n","Predicting batch 31\n","Predicting batch 32\n","Predicting batch 33\n","Predicting batch 34\n","Predicting batch 35\n","Predicting batch 36\n","Predicting batch 37\n","Predicting batch 38\n","Predicting batch 39\n","Predicting batch 40\n","Predicting batch 41\n","Predicting batch 42\n","Predicting batch 43\n","Predicting batch 44\n","Predicting batch 45\n","Predicting batch 46\n","Predicting batch 47\n","Predicting batch 48\n","Predicting batch 49\n","Predicting batch 50\n","Predicting batch 51\n","Predicting batch 52\n","Predicting batch 53\n","Predicting batch 54\n","Predicting batch 55\n","Predicting batch 56\n","Predicting batch 57\n","Predicting batch 58\n","Predicting batch 59\n","Predicting batch 60\n","Predicting batch 61\n","Predicting batch 62\n","Predicting batch 63\n","Predicting batch 64\n","Predicting batch 65\n","Predicting batch 66\n","Predicting batch 67\n","Predicting batch 68\n","Predicting batch 69\n","Predicting batch 70\n","Predicting batch 71\n","Predicting batch 72\n","Predicting batch 73\n","Predicting batch 74\n","Predicting batch 75\n","Predicting batch 76\n","Predicting batch 77\n","Predicting batch 78\n","Predicting batch 79\n","Predicting batch 80\n","Predicting batch 81\n","Predicting batch 82\n","Predicting batch 83\n","Predicting batch 84\n","Predicting batch 85\n","Predicting batch 86\n","Predicting batch 87\n","Predicting batch 88\n","Predicting batch 89\n","Predicting batch 90\n","Predicting batch 91\n","Predicting batch 92\n","Predicting batch 93\n","Predicting batch 94\n","Predicting batch 95\n","Predicting batch 96\n","Predicting batch 97\n","Predicting batch 98\n","Predicting batch 99\n","Predicting batch 100\n","Predicting batch 101\n","Predicting batch 102\n","Predicting batch 103\n","Predicting batch 104\n","Predicting batch 105\n","Predicting batch 106\n","Predicting batch 107\n","Predicting batch 108\n","Predicting batch 109\n","Predicting batch 110\n","Predicting batch 111\n","Predicting batch 112\n","Predicting batch 113\n","Predicting batch 114\n","Predicting batch 115\n","Predicting batch 116\n","Predicting batch 117\n","Predicting batch 118\n","Predicting batch 119\n","Predicting batch 120\n","Predicting batch 121\n","Predicting batch 122\n","Predicting batch 123\n","Predicting batch 124\n","Predicting batch 125\n","Predicting batch 126\n","Predicting batch 127\n","Predicting batch 128\n","Predicting batch 129\n","Predicting batch 130\n","Predicting batch 131\n","Predicting batch 132\n","Predicting batch 133\n","Predicting batch 134\n","Predicting batch 135\n","Predicting batch 136\n","Predicting batch 137\n","Predicting batch 138\n","Predicting batch 139\n","Predicting batch 140\n","Predicting batch 141\n","Predicting batch 142\n","Predicting batch 143\n","Predicting batch 144\n","Predicting batch 145\n","Predicting batch 146\n","\n","---- Epoch 2 ----\n","Accuracy: 0.014642549526270457\n","\n","\n","Saving model to /content/drive/MyDrive/PPL/trocr/model...\n"]}]},{"cell_type":"code","source":["model = TrocrPredictor(use_local_model=True)\n","predictions = model.predict_images(images)\n","predictions = list(predictions)\n","\n","# print results\n","for i, file_name in enumerate(image_names):\n","    print(f'Prediction for {file_name}:\\nPredict: {predictions[i][0]}\\nConfidence Scores: {predictions[i][1]}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQj4ccJ5V_mp","executionInfo":{"status":"ok","timestamp":1719976520941,"user_tz":-420,"elapsed":10433,"user":{"displayName":"Thắng Nguyễn Duy","userId":"02307271049299451893"}},"outputId":"4c2b20b6-5b0d-41f7-b387-af9a4c956f79"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded local model from /content/drive/MyDrive/PPL/trocr/model\n","Using device cuda.\n","Predicting batch 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Prediction for 20160504_0112_25849_2_tg_7_5.png:\n","Predict: nguy hiểm vì cua gắt n\n","Confidence Scores: 0.9840937256813049\n","\n","Prediction for Screenshot 2024-06-29 115458.png:\n","Predict: LLICENSEcence OF MCCDONALD'S\n","Confidence Scores: 0.45057791471481323\n","\n","Prediction for Screenshot 2024-06-29 122655.png:\n","Predict: How You Benefit - Spreads\n","Confidence Scores: 0.904974102973938\n","\n"]}]},{"cell_type":"code","source":["main_train(use_local_model=True)"],"metadata":{"id":"F_aEwjOPkwLu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TrocrPredictor(use_local_model=True)\n","predictions = model.predict_images(images)\n","predictions = list(predictions)\n","\n","# print results\n","for i, file_name in enumerate(image_names):\n","    print(f'Prediction for {file_name}:\\nPredict: {predictions[i][0]}\\nConfidence Scores: {predictions[i][1]}\\n')"],"metadata":{"id":"iVuTJSKrkyJC"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"375e0ec956d441cebd791750cd2a5651":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f4d3f9cd7f54e6aa185965f2c75cb80","IPY_MODEL_750825f565874d4c838c6ef5774d7f7d","IPY_MODEL_ffee772ce2e94321a6fce38f7d574f4b"],"layout":"IPY_MODEL_d4bf4548b05545c4aa700b165912ff09"}},"4f4d3f9cd7f54e6aa185965f2c75cb80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32ece0fadefa47fc9d8971e27a461c52","placeholder":"​","style":"IPY_MODEL_b8e429e19540490990af7f71d03c6887","value":"preprocessor_config.json: 100%"}},"750825f565874d4c838c6ef5774d7f7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ba2cd171a834ab599cc3522bf5e199b","max":224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9883a884f2a4084a46e560c546c2e16","value":224}},"ffee772ce2e94321a6fce38f7d574f4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1b615f64f86419793fcaef2953d19ab","placeholder":"​","style":"IPY_MODEL_2985999870dd4b87ac68ada65b051907","value":" 224/224 [00:00&lt;00:00, 8.03kB/s]"}},"d4bf4548b05545c4aa700b165912ff09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32ece0fadefa47fc9d8971e27a461c52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8e429e19540490990af7f71d03c6887":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ba2cd171a834ab599cc3522bf5e199b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9883a884f2a4084a46e560c546c2e16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1b615f64f86419793fcaef2953d19ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2985999870dd4b87ac68ada65b051907":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b36ebf5d807f4a7e8f94abdb130b9b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7395531976724632bca7c22e9fb0651b","IPY_MODEL_9c5fdd2d8d714cbba92063caf2390ac6","IPY_MODEL_3c9849b306c347ccbdfa2515dd1614a0"],"layout":"IPY_MODEL_9447568140cb4ded833fca812045fb38"}},"7395531976724632bca7c22e9fb0651b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10961110c91e4ee7ab7ef7795b6ef502","placeholder":"​","style":"IPY_MODEL_7f7b274ca877432e8ac6ff8ca2723b33","value":"tokenizer_config.json: 100%"}},"9c5fdd2d8d714cbba92063caf2390ac6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af0832f488c24f38908ad9ad71a7a8b7","max":1118,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb02232a2b814724b62134ef80794e0e","value":1118}},"3c9849b306c347ccbdfa2515dd1614a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c6d5703ec5b4fe79e31814206130a85","placeholder":"​","style":"IPY_MODEL_c3e7879dc8984ff4988e457145b6fd9a","value":" 1.12k/1.12k [00:00&lt;00:00, 47.5kB/s]"}},"9447568140cb4ded833fca812045fb38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10961110c91e4ee7ab7ef7795b6ef502":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f7b274ca877432e8ac6ff8ca2723b33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af0832f488c24f38908ad9ad71a7a8b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb02232a2b814724b62134ef80794e0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c6d5703ec5b4fe79e31814206130a85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e7879dc8984ff4988e457145b6fd9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f9292d170314ababd923a5d26b0f65d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0f43229012a413ab7ff09f9e8294651","IPY_MODEL_673a013eae174a89819222684fbe7546","IPY_MODEL_c9598d8e950847d1ac8d847e316866c3"],"layout":"IPY_MODEL_b92347860d51416f88e24750cd2c2fef"}},"d0f43229012a413ab7ff09f9e8294651":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4eabfd1cef664e98bf8060bb13b1bf43","placeholder":"​","style":"IPY_MODEL_564f58fabae84feabd23c74007078b10","value":"vocab.json: 100%"}},"673a013eae174a89819222684fbe7546":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_805ae7fdb82440a9a4503eed6297fe18","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc3e034f5c104b9d95b24719635a110b","value":898822}},"c9598d8e950847d1ac8d847e316866c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b134f0c878124f5e921a2f6226c73b8d","placeholder":"​","style":"IPY_MODEL_127bf9c5bce6419a9e9aba860097808d","value":" 899k/899k [00:00&lt;00:00, 4.19MB/s]"}},"b92347860d51416f88e24750cd2c2fef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eabfd1cef664e98bf8060bb13b1bf43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"564f58fabae84feabd23c74007078b10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"805ae7fdb82440a9a4503eed6297fe18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc3e034f5c104b9d95b24719635a110b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b134f0c878124f5e921a2f6226c73b8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"127bf9c5bce6419a9e9aba860097808d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42e2b54f7f984eb3b68ef9bd889df7c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19676238d69a40f2b92455304d99e056","IPY_MODEL_a3bb000ae9a5484196c9c634d4d6105b","IPY_MODEL_f5cfb7462e534593b70ff55d6455e9ea"],"layout":"IPY_MODEL_e7532716d481439f90540b08fa8dd977"}},"19676238d69a40f2b92455304d99e056":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3c3fc9015a54a3eae5bfb3eb0278ec1","placeholder":"​","style":"IPY_MODEL_2121f2865d154f13b6ddba5704c39607","value":"merges.txt: 100%"}},"a3bb000ae9a5484196c9c634d4d6105b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dc2dce9926e4d96a7ad01bcd49d0d0b","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab753f406b6f4bbf8bd74b264d56949f","value":456318}},"f5cfb7462e534593b70ff55d6455e9ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a727dd7a6cd4153933a663af53b8b16","placeholder":"​","style":"IPY_MODEL_625073abeb364229a53ec6e108fa348a","value":" 456k/456k [00:00&lt;00:00, 24.8MB/s]"}},"e7532716d481439f90540b08fa8dd977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3c3fc9015a54a3eae5bfb3eb0278ec1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2121f2865d154f13b6ddba5704c39607":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dc2dce9926e4d96a7ad01bcd49d0d0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab753f406b6f4bbf8bd74b264d56949f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a727dd7a6cd4153933a663af53b8b16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"625073abeb364229a53ec6e108fa348a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05f3f35042fa4f15824188e3328ffdce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de6947f19f00429d960a24a300d18ac6","IPY_MODEL_63a0acb1318e4d79aff0eafff72c2571","IPY_MODEL_6693163788c149f2ba721d52ff56bcee"],"layout":"IPY_MODEL_9d3912afe9344697add2dd1f3f0c7599"}},"de6947f19f00429d960a24a300d18ac6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1479ebf21ea74808af8f50548e315d05","placeholder":"​","style":"IPY_MODEL_bb565ee6b74a41b2ba6dc29f46cfee12","value":"special_tokens_map.json: 100%"}},"63a0acb1318e4d79aff0eafff72c2571":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13a4805611ac4795b6d30bf969f2a203","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c7da75a9e8f4be0a61bdb8516a62dbb","value":772}},"6693163788c149f2ba721d52ff56bcee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88befa6e566c407aa077aa5becc646f6","placeholder":"​","style":"IPY_MODEL_10947c8ba4bc4ac38a6687fcd624ea2f","value":" 772/772 [00:00&lt;00:00, 50.4kB/s]"}},"9d3912afe9344697add2dd1f3f0c7599":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1479ebf21ea74808af8f50548e315d05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb565ee6b74a41b2ba6dc29f46cfee12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13a4805611ac4795b6d30bf969f2a203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c7da75a9e8f4be0a61bdb8516a62dbb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88befa6e566c407aa077aa5becc646f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10947c8ba4bc4ac38a6687fcd624ea2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98029c0aa3ff47bc82df5733d89ab85a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1db473b29224481da69b16cdbd11f593","IPY_MODEL_d28e74d0decc49aaa910d5377fa3898f","IPY_MODEL_321b5f2e8bbc4565946bd6887e039d80"],"layout":"IPY_MODEL_b5c18f4e37fb4ca9b1610fc90f3749a4"}},"1db473b29224481da69b16cdbd11f593":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd03f5f041a04dde946fc0b41a6364ac","placeholder":"​","style":"IPY_MODEL_756502b63a074bea97cf5d62e79788fd","value":"config.json: 100%"}},"d28e74d0decc49aaa910d5377fa3898f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_624a5d61f93e474d85460c58b7c45f42","max":4165,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e390c4446ac140d19e4f301b0b441c37","value":4165}},"321b5f2e8bbc4565946bd6887e039d80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca5a0b9333e64e7499bb6cc33de6f22f","placeholder":"​","style":"IPY_MODEL_e0e81790572546cea6321f3bbfbc36d7","value":" 4.17k/4.17k [00:00&lt;00:00, 306kB/s]"}},"b5c18f4e37fb4ca9b1610fc90f3749a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd03f5f041a04dde946fc0b41a6364ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"756502b63a074bea97cf5d62e79788fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"624a5d61f93e474d85460c58b7c45f42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e390c4446ac140d19e4f301b0b441c37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca5a0b9333e64e7499bb6cc33de6f22f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0e81790572546cea6321f3bbfbc36d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cfd1f22e80b4963b4523dca292b84b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ab39036bef548f798f50beab16eb2b9","IPY_MODEL_3a8a004dff894bf2a976bb026052659a","IPY_MODEL_3985400d872b475cae4bf7caa7d37582"],"layout":"IPY_MODEL_3fbd33214d194b3bbece17b5083529cd"}},"1ab39036bef548f798f50beab16eb2b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0992685a59d2430d92e7da244045beae","placeholder":"​","style":"IPY_MODEL_3c0724c6644a4ffdb834ac5bcae130b4","value":"model.safetensors: 100%"}},"3a8a004dff894bf2a976bb026052659a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d51a15ba8b24e4b9136fa87cd7fe97e","max":1333384464,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b6400a1d20e4ce1a47addf4cbaac557","value":1333384464}},"3985400d872b475cae4bf7caa7d37582":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a7e6b6ebde428cb415a230301cb1c7","placeholder":"​","style":"IPY_MODEL_d336aef199094629ad320a71ccebc076","value":" 1.33G/1.33G [00:05&lt;00:00, 262MB/s]"}},"3fbd33214d194b3bbece17b5083529cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0992685a59d2430d92e7da244045beae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c0724c6644a4ffdb834ac5bcae130b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d51a15ba8b24e4b9136fa87cd7fe97e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b6400a1d20e4ce1a47addf4cbaac557":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79a7e6b6ebde428cb415a230301cb1c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d336aef199094629ad320a71ccebc076":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f89b8aaccd4f4aa59ee025bc65d657b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_204e21aef1f24ac39c66962d51b2afb1","IPY_MODEL_b0524c08a3154e58a9bd5de2127838dc","IPY_MODEL_8fb667a010fa4bc39365a27529bf56a9"],"layout":"IPY_MODEL_4da84f7f113d4364bb455a9065b5fa56"}},"204e21aef1f24ac39c66962d51b2afb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_419486956dcc4f209dbbafd570db540f","placeholder":"​","style":"IPY_MODEL_e6cb18888b9345858c11c20334f5fdb6","value":"generation_config.json: 100%"}},"b0524c08a3154e58a9bd5de2127838dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e9b44c8c07b44738348dc3a9bae25c8","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d08fd1d6538a4dac9ddafdcfd95c389f","value":190}},"8fb667a010fa4bc39365a27529bf56a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e5291ee47674a3c8ce76dc14fff9cfe","placeholder":"​","style":"IPY_MODEL_c6a59060cc8c4a8c83a1cf10c29ab2d9","value":" 190/190 [00:00&lt;00:00, 15.1kB/s]"}},"4da84f7f113d4364bb455a9065b5fa56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"419486956dcc4f209dbbafd570db540f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6cb18888b9345858c11c20334f5fdb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e9b44c8c07b44738348dc3a9bae25c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d08fd1d6538a4dac9ddafdcfd95c389f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e5291ee47674a3c8ce76dc14fff9cfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6a59060cc8c4a8c83a1cf10c29ab2d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"488555cd3d26401ab65c320e2b7014ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8df2181811224380a99754353bb907a1","IPY_MODEL_f6fe572efe664eed8ee3d161b01379c1","IPY_MODEL_179f3aae5c29446fa1116ae777594572"],"layout":"IPY_MODEL_4cb219be48044d43ad4acb51b3cd913d"}},"8df2181811224380a99754353bb907a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bee0789a6ea84465afe2d09a78106f08","placeholder":"​","style":"IPY_MODEL_cfd93b6773094b75af797cacd081070e","value":"preprocessor_config.json: 100%"}},"f6fe572efe664eed8ee3d161b01379c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a2c8e8bdd92438db9380d610244df1c","max":224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcf0886edb2a4cf4ba77e5e909cd292c","value":224}},"179f3aae5c29446fa1116ae777594572":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19d9688b2e2a435f9627523554da8bbd","placeholder":"​","style":"IPY_MODEL_52f81de3c9b14f37baaafe7335223827","value":" 224/224 [00:00&lt;00:00, 11.6kB/s]"}},"4cb219be48044d43ad4acb51b3cd913d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee0789a6ea84465afe2d09a78106f08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfd93b6773094b75af797cacd081070e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a2c8e8bdd92438db9380d610244df1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcf0886edb2a4cf4ba77e5e909cd292c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19d9688b2e2a435f9627523554da8bbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52f81de3c9b14f37baaafe7335223827":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e173f2e8451407cb347689e0d59c4e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b87f88ac7965456aaa93f51ad74f8431","IPY_MODEL_194e38b050744a7584d5bb0e555c3ba6","IPY_MODEL_26d8265afa7c4311944574228e7fc268"],"layout":"IPY_MODEL_888423c3eb8c4f1ab10eff7eb561259a"}},"b87f88ac7965456aaa93f51ad74f8431":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f77986a4e47841da81bd0e533be3c0e1","placeholder":"​","style":"IPY_MODEL_12b7f91dddd64fbcbd3f8e7bcacb06d8","value":"tokenizer_config.json: 100%"}},"194e38b050744a7584d5bb0e555c3ba6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42218c281eb2422a85736f0f306a80bc","max":1118,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16fef1a9ba5942158c362c780152470a","value":1118}},"26d8265afa7c4311944574228e7fc268":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_111699e5be0a4e8a97d851d81ce88448","placeholder":"​","style":"IPY_MODEL_4c9d57f55214478d948f3045be3c8906","value":" 1.12k/1.12k [00:00&lt;00:00, 67.6kB/s]"}},"888423c3eb8c4f1ab10eff7eb561259a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f77986a4e47841da81bd0e533be3c0e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12b7f91dddd64fbcbd3f8e7bcacb06d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42218c281eb2422a85736f0f306a80bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16fef1a9ba5942158c362c780152470a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"111699e5be0a4e8a97d851d81ce88448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c9d57f55214478d948f3045be3c8906":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ff9c6c6f5a4498da6ef6036ca1501a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82a45c556056415dbdaf4e3668d57b2b","IPY_MODEL_a45fc53d041242ef875544fcf3f6e9b2","IPY_MODEL_c5550874936448b2afecab4fba1bf2e7"],"layout":"IPY_MODEL_9e1b8e56d32548a1b446006437f1607e"}},"82a45c556056415dbdaf4e3668d57b2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95d3fa3cad6543049aa941392f5f04e9","placeholder":"​","style":"IPY_MODEL_0c7bcb5bb7714b7fa9536cf3bedc56a6","value":"vocab.json: 100%"}},"a45fc53d041242ef875544fcf3f6e9b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a79869bfa0c48f68a7231be125125fb","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4fc3229fc4eb4d3d9d580aef90197ff9","value":898822}},"c5550874936448b2afecab4fba1bf2e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_795b51b90d3d4cb19c916893f581efab","placeholder":"​","style":"IPY_MODEL_47dc047f0581435ea12f5b6b23eb7b94","value":" 899k/899k [00:00&lt;00:00, 8.53MB/s]"}},"9e1b8e56d32548a1b446006437f1607e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95d3fa3cad6543049aa941392f5f04e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c7bcb5bb7714b7fa9536cf3bedc56a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a79869bfa0c48f68a7231be125125fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fc3229fc4eb4d3d9d580aef90197ff9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"795b51b90d3d4cb19c916893f581efab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47dc047f0581435ea12f5b6b23eb7b94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9464d3e9033a4945a21d2b8d7069c686":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff1371a623a745a3b171bdc5ee6f33cd","IPY_MODEL_1cbd313a8a75471ea6eacff6f98129f7","IPY_MODEL_4ab32c8ace524a43976c792388adfa35"],"layout":"IPY_MODEL_5efb3aeaf1ae415282a85faf832691a8"}},"ff1371a623a745a3b171bdc5ee6f33cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48d99b7e1c6c4fd2870ac6f410501268","placeholder":"​","style":"IPY_MODEL_691337026232409a8c0d8a0a30acfe4b","value":"merges.txt: 100%"}},"1cbd313a8a75471ea6eacff6f98129f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed651974f2464cd08db22fdebb1f5061","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_702bd76da265420ba98134c0abbc7ebf","value":456318}},"4ab32c8ace524a43976c792388adfa35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6ef52f8616f424bae9c22e688e7c261","placeholder":"​","style":"IPY_MODEL_4e3208b4a50747a388266727d94ddcea","value":" 456k/456k [00:00&lt;00:00, 3.37MB/s]"}},"5efb3aeaf1ae415282a85faf832691a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48d99b7e1c6c4fd2870ac6f410501268":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"691337026232409a8c0d8a0a30acfe4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed651974f2464cd08db22fdebb1f5061":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"702bd76da265420ba98134c0abbc7ebf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6ef52f8616f424bae9c22e688e7c261":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e3208b4a50747a388266727d94ddcea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b66d816f25e43c0819abce1f7e96246":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a2dcd94f0b84ba286d6ae57f8bf9c1e","IPY_MODEL_c14a0dc9de3d4e4c827df1c41541b79b","IPY_MODEL_3b94792a6be147099564d1897807d55e"],"layout":"IPY_MODEL_a5a140b685be48ff86541c307c319569"}},"6a2dcd94f0b84ba286d6ae57f8bf9c1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cbf0e0ce2ce46d980c64bad212001ff","placeholder":"​","style":"IPY_MODEL_7f6480d6761941ba8089a5c6fc50293b","value":"special_tokens_map.json: 100%"}},"c14a0dc9de3d4e4c827df1c41541b79b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0eb94f83ee149aa93234d7438bfce5a","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b98a0198bb84c4e92d00f2d3417e7e4","value":772}},"3b94792a6be147099564d1897807d55e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1098aab794944885a361f08fd80259c5","placeholder":"​","style":"IPY_MODEL_0836a42ef2b249a1b7a086fac39f51e3","value":" 772/772 [00:00&lt;00:00, 49.0kB/s]"}},"a5a140b685be48ff86541c307c319569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cbf0e0ce2ce46d980c64bad212001ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f6480d6761941ba8089a5c6fc50293b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0eb94f83ee149aa93234d7438bfce5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b98a0198bb84c4e92d00f2d3417e7e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1098aab794944885a361f08fd80259c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0836a42ef2b249a1b7a086fac39f51e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}